#!/usr/bin/env python3
"""
Wrappers to facilitate running `olfsysm` MB models, mainly:
- `model_mb_responses`: highest-level function. takes multiple-fly ORN dF/F data and
  runs multiple parameterizations of the model (as well as saving plots and other
  outputs to subdirs).

- `fit_and_plot_mb_model`: takes mean ORN data (already scaled into units of spike rate
  deltas), and runs one parameterization of the model (making multiple `fit_mb_model`
  calls only when multiple seeds are needed), saving plots/etc in a created directory

- `fit_mb_model`: the loosest wrapper around `olfsysm`. returns model outputs, but
  typically does not make any plots (though there is some debug code for that).
  when needed, it:
  - fills glomeruli to intersection of those in hemibrain and Task et al. 2022
  - imputes mean Hallem SFR

See also docstring for `connectome_wPNKC` below.repo_root
"""

import filecmp
import itertools
import os
from os.path import getmtime
from pathlib import Path
from pprint import pprint, pformat
import re
import sys
import shutil
from tempfile import NamedTemporaryFile
import time
import traceback
from typing import Any, Dict, List, Literal, Optional, Set, Tuple, Union

# TODO delete
import warnings
# TODO TODO restore
#warnings.filterwarnings('error', category=FutureWarning)
# (doesn't work to catch numpy percentile interpolation= warning anyway,
# at least from pytest w/ or w/o pytest ignoring warnings...)
# TODO TODO restore
#warnings.filterwarnings('error', category=DeprecationWarning)
# also doesn't seem to work
# warnings.filterwarnings('error', message='the `interpolation=` argument.*')
#

import numpy as np
import pandas as pd
import xarray as xr
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.patches import Patch
from matplotlib.figure import Figure
from matplotlib.axes import Axes
from matplotlib.ticker import MaxNLocator
from matplotlib.colors import to_rgba
import matplotlib as mpl
mpl.use('Agg')
from sklearn.cluster import DBSCAN
from scipy.stats import spearmanr, pearsonr, f_oneway
from sklearn.preprocessing import maxabs_scale as sk_maxabs_scale
from sklearn.preprocessing import minmax_scale as sk_minmax_scale
import statsmodels.api as sm
import seaborn as sns
import colorcet as cc
from tqdm import tqdm
from termcolor import cprint
# for type hinting
from statsmodels.regression.linear_model import RegressionResultsWrapper
from rastermap import Rastermap

from hong2p import olf, util, viz
from hong2p.olf import solvent_str
from hong2p.viz import dff_latex, no_constrained_layout
from hong2p.util import num_notnull, num_null, pd_allclose, format_date, date_fmt_str
from hong2p.types import Pathlike
import olfsysm as osm
from drosolf import orns

import faulthandler, sys
faulthandler.enable(file=sys.stderr, all_threads=True)


# NOTE: can't import from al_analysis w/o causing circular import issues, so need to
# factor shared stuff to al_util
from al_util import (savefig, abbrev_hallem_odor_index, sort_odors, panel2name_order,
    diag_panel_str, warn, should_ignore_existing, to_csv, to_pickle, read_pickle,
    produces_output, makedirs, corr_triangular, invert_corr_triangular, n_choose_2,
    diverging_cmap, diverging_cmap_kwargs, bootstrap_seed, mean_of_fly_corrs, plot_corr,
    plot_responses_and_corr, rotate_xticklabels, cluster_rois, odor_is_megamat,
    megamat_odor_names, remy_data_dir, remy_binary_response_dir, remy_megamat_sparsity,
    remy_date_col, remy_fly_cols, remy_fly_id, remy_fly_binary_response_fname,
    load_remy_fly_binary_responses, load_remy_megamat_kc_binary_responses,
    n_final_megamat_kc_flies, MultipleSavesPerRunException
)
import al_util


# TODO TODO add fn to load megamat fixed_thr / wAPLKC params used for model in paper?
# (-> try using in some other contexts, like for yang's diagnostic mixture model)
# TODO + include test checking output against params currently loaded but not used in
# hemibrain repro test? or don't, if i load from there in the first place... then would
# be a tautology

repo_root = Path(__file__).parent

# e.g. before calculating correlations across model KC populations.
#
# Remy generally DOES drop "bad" cells, which are largely silent cells, but that isn't
# controlled by this flag. my analysis of her data generally also drops the same cells
# she does.
drop_silent_model_kcs: bool = True

KC_ID: str = 'kc_id'
# TODO use (+ in test_mb_model.py and elsewhere) (replacing hardcoded str w/ same value)
KC_TYPE: str = 'kc_type'

# TODO rename to hemibrain or something? presumably this is specfic to that?
# TODO move into the one place that uses it (tianpei's part of connectome_wPNKC)
# (or keep module level and share w/ his script PNKC_claw_plots_dif_color.py?)
PIXEL_TO_UM = 8/1000

def read_series_csv(csv: Pathlike, **kwargs) -> pd.Series:
    # TODO doc

    df = pd.read_csv(csv, header=None, index_col=0, **kwargs)
    assert df.shape[1] == 1
    ser = df.iloc[:, 0].copy()

    # these should both be autogenerated, and not actually in CSV
    assert ser.index.name == 0
    assert ser.name == 1
    ser.index.name = None
    ser.name = None

    return ser


def handle_multiglomerular_receptors(df: pd.DataFrame, *, drop: bool = True,
    verbose: bool = False) -> pd.DataFrame:

    # TODO if this is false, could add to each glomerulus? doubt it would matter much at
    # all. this fn should only be handling 'DM3+DM5' (where 'DM3' and 'DM5' are also in
    # hallem data)
    if not drop:
        raise NotImplementedError

    assert df.index.name == 'glomerulus'
    # glomeruli should only contain '+' delimiter (e.g. 'DM3+DM5') if the
    # measurement was originally from a receptor that is expressed in each
    # of the glomeruli in the string.
    multiglomerular_receptors = df.index.str.contains('+', regex=False)
    if multiglomerular_receptors.any():
        # 'DM3+DM5' should correspond to Or33b coreceptor Hallem adata
        expected_mg_receptors = {'DM3+DM5'}
        mg_receptors = set(df.index[multiglomerular_receptors])
        # in case some of my weird names for uncertain glomeruli have slipped thru to
        # here by accident (none of the calls to this use my glom names tho...)
        assert mg_receptors == expected_mg_receptors, (
            'had unexpected multiglomerular receptors:\n'
            f'{pformat(mg_receptors - expected_mg_receptors)}'
        )

        # defaulting to verbose=False, b/c it seems all calls to this are not on my
        # input data (just on hallem, or in an unused path where my input is given w/
        # receptor names, which are then converted to glomeruli names)
        if verbose:
            warn(f'dropping multiglomerular receptors: {mg_receptors}')

        df = df.loc[~multiglomerular_receptors, :].copy()

    return df


def _print_response_rates(responses: pd.DataFrame) -> None:
    """Prints mean response rates for bool responded/not data of shape (# KCs, # odors)

    If input index has a `KC_TYPE` level, also prints response rate within each KC
    subtype, and how many cells of each type.
    """
    # TODO refactor sparsity float formatting?
    print(f'mean response rate: {responses.mean().mean():.4f}', end='')

    if KC_TYPE not in responses.index.names:
        # TODO still breakdown by odor when we don't have KC type?
        # (should have a plot for that, so idk...)
        print()
        return

    # ab         802
    # g          612
    # a'b'       336
    # unknown     80
    n_kcs_by_type = responses.index.get_level_values(KC_TYPE).value_counts()

    response_rate_by_type = responses.groupby(KC_TYPE).sum().T / n_kcs_by_type

    print('. by KC type:')
    avg_response_rate_by_type = response_rate_by_type.mean(
        ).to_frame(name='avg_response_rate')

    avg_response_rate_by_type['n_kcs_of_type'] = n_kcs_by_type

    # mean response rate: 0.1074. by KC type:
    #          avg_response_rate  n_kcs_of_type
    # a'b'              0.074230            336
    # ab                0.106718            802
    # g                 0.131200            612
    # unknown           0.072059             80
    print(avg_response_rate_by_type.to_string())

    # TODO don't print this last one by default, but add flag for extra verbosity?
    # (and print if CLI -v?)
    print()
    print('mean response rate by odor and KC type:')
    print(response_rate_by_type.to_string())


# TODO factor to hong2p.util?
def delim_sep_part(ser: pd.Series, *, sep: str = '_', i: int = 0) -> pd.Series:
    return ser.str.split(sep).apply(lambda x: x[i])

def first_delim_sep_part(ser, *, sep: str = '_') -> pd.Series:
    return delim_sep_part(ser, sep=sep, i=0)
#


# TODO move 'unknown' into this set?
expected_kc_types = {'g', 'ab', "a'b'"}
#
kc_type_hue_order = sorted(expected_kc_types) + ['unknown']

def add_kc_type_col(df: pd.DataFrame, type_col: str) -> pd.DataFrame:
    # TODO replace NaN w/ 'unknown' here, instead of adding it after the fact
    # potentially inconsistently
    """Modifies `df` inplace, adding a 'kc_type' column (vals={'g', 'ab', "a'b'"", NaN})
    """
    # TODO also use for fafb inputs? or need diff processing there?

    sep_count = df[type_col].dropna().str.count('-')
    multiple_sep = sep_count > 1
    assert not multiple_sep.any()
    missing_sep = sep_count == 0
    assert not missing_sep.any()

    kc_types = first_delim_sep_part(df[type_col].dropna(), sep='-')

    # after this, should all be one of {"g", "ab", "a'b'"}
    # (or NaN after assigning back into `df`)
    kc_types = kc_types.str.strip('KC')

    assert set(kc_types) == expected_kc_types

    assert KC_TYPE not in df.columns
    # from hemibrain wPNKC input:
    # ipdb> df[KC_TYPE].str.strip('KC').value_counts(dropna=False)
    # g       4639
    # ab      3759
    # a'b'    1469
    # NaN      238
    df[KC_TYPE] = kc_types

    # important this happens after line above, which will often be what introduces the
    # NaN (by assigning back into df)
    # TODO add separate module-level variable for 'unknown'?
    df[KC_TYPE] = df[KC_TYPE].fillna('unknown')

    return df


# def _plot_connectome_raw_weight_hist(weights: Union[pd.Series, pd.DataFrame],
#     **kwargs) -> Tuple[Figure, Axes]:

#     if isinstance(weights, pd.DataFrame):
#         assert 'x' in kwargs, 'must pass x= if weights are a DataFrame'
#         weight_ser = weights[kwargs['x']]
#     else:
#         weight_ser = weights

#     # discrete=True wouldn't make sense otherwise, right?
#     assert (weight_ser.astype(int) == weight_ser.astype(float)).all()

#     fig, ax = plt.subplots()
#     sns.histplot(weights, discrete=True, ax=ax, **kwargs)
#     return fig, ax

# Should be the same performance as the previous version of def _plot_connectome_raw_weight_hist
# Fixed some small issues.
def _plot_connectome_raw_weight_hist(
    weights: Union[pd.Series, pd.DataFrame],
    **kwargs
) -> Tuple[Figure, Axes]:
    """
    If `weights` is a DataFrame, call with x='<col>' (and optional hue='<col>').
    If `weights` is a Series, call without hue-by-column-name.
    """
    fig, ax = plt.subplots()

    # keep your “discrete” sanity check, but compute it from the actual x series
    if isinstance(weights, pd.DataFrame):
        if 'x' not in kwargs:
            raise ValueError("must pass x='<column>' if weights is a DataFrame")
        xcol = kwargs['x']
        if xcol not in weights.columns:
            raise KeyError(f"x column '{xcol}' not in DataFrame")
        ser = pd.to_numeric(weights[xcol], errors='coerce').dropna()
    else:
        ser = pd.to_numeric(pd.Series(weights), errors='coerce').dropna()

    # same intent as your assert: values should be integers for discrete=True


    # assert ser.eq(ser.round()).all(), "values are not integer-like; remove discrete=True"


    # Discrete would be too hard to achieve in _wPNKC_one_row_per_claw, I am scared that the weight would lose precision
    if isinstance(weights, pd.DataFrame):
        # MAIN FIX: let seaborn find x/hue by name
        # sns.histplot(data=weights, discrete=True, ax=ax, **kwargs)
        sns.histplot(data=weights, ax=ax, **kwargs)

    else:
        # Series path: reject hue='colname' because there is no DataFrame to look up
        if isinstance(kwargs.get('hue'), str):
            raise ValueError("hue='<col>' requires DataFrame input; pass a DataFrame.")
        # sns.histplot(x=ser, discrete=True, ax=ax, **{k:v for k,v in kwargs.items() if k!='x'})
        sns.histplot(x=ser,  ax=ax, **{k:v for k,v in kwargs.items() if k!='x'})

    return fig, ax


variable_n_claw_options: Set[str] = {'uniform', 'caron', 'hemidraw'}

# TODO add 'hemibrain-matt' here, and replace _use_matt_wPNKC w/ that?
# NOTE: FAFB = FlyWire
connectome_options: Set[str] = {'hemibrain', 'fafb-left', 'fafb-right'}

pn2kc_connections_options: Set[str] = set(variable_n_claw_options)
pn2kc_connections_options.update(connectome_options)

from_prat = repo_root / 'data/from_pratyush'

_connectome2glomset = dict()
# TODO compare to what ann had been using (does she have her own fully formed connectome
# based PN->KC matrix, or is it all random draws with certain connectome inspired
# probabilities?)
# TODO (delete?) add parameter for thresholding PN-KC pairs above the existing cutoffs
# of >=4 (which was enforced by neuprint query that produced the hemibrain data we have,
# or we do manually here for the fafb datasets) (-> try to get total # of claws closer
# to reported ~5.[2-6?] mean claws in Davi Bock paper, through varying both this and
# weight_divisor. currently weight_divisor=20 brings us way above their reported mean #
# of claws, given threshold of >4 we are stuck w/ in hemibrain case. maybe Bock # of
# claws is partially just b/c that brain is abnormal [i.e. many more KCs, etc]?)
#
# TODO TODO TODO load and provide options to use from_pratyush/2025-08-20 contents
# (hemibrain PN synapses he has grouped into claws for us)
# TODO experiment w/ my own scaling factors on his tree distances, or just use his
# scaled versions?
# TODO TODO get his code he used to produce those outputs
# TODO make prat_claws default to true later?
def connectome_wPNKC(connectome: str = 'hemibrain', *, prat_claws: bool = False,
    weight_divisor: Optional[float] = None, plot_dir: Optional[Path] = None,
    _use_matt_wPNKC: bool = False, _drop_glom_with_plus: bool = True,
    # TODO reconsider handling of synapse_*_path kwargs, and DBSCAN related param kws
    synapse_con_path: Optional[Path] = None, synapse_loc_path: Optional[Path] = None,
    cluster_eps: float = 1.9, cluster_min_samples: int = 3) -> pd.DataFrame:
    # TODO doc possible contents of row/column index in returned wPNKC dataframe
    """
    Args:
        connectome: which connectome of hemibrain/fafb-left/fafb-right to use.
            should be one of `connectome_options`.

        weight_divisor: if None, one model claw is added for each PN-KC pair exceeding
            minimum total number of unitary synapses (currently de facto >=4 for
            hemibrain, b/c of query that pulled hemibrain data, and also hardcoded to
            that in this function for FAFB datasets).

            If float, each PN-KC pair gets `ceil(total_synapses / weight_divisor)`
            claws.

            Note that glomeruli have different numbers of cognate PNs, and that only in
            the `weight_divisor=<float>` case can there be multiple claws assigned to
            one particular PN (for a given KC).

        plot_dir: if passed, saves plots histograms of: 1) PN-KC connectome weights, and
            2) #-claws-per-model-KC (#2 depends on `weight_divisor`)

    Returns dataframe of shape (#-KCs [in selected connectome], #-glomeruli).
    """
    assert connectome in connectome_options
    if _use_matt_wPNKC:
        assert connectome == 'hemibrain'

    # TODO refactor to share w/ calling code (also defined there...) (/cache?)?
    glomerulus2receptors = orns.task_glomerulus2receptors()
    task_gloms = set(glomerulus2receptors.keys())
    del glomerulus2receptors

    glomerulus_renames = {'VC3l': 'VC3', 'VC3m': 'VC3'}
    assert all(x in task_gloms for x in glomerulus_renames.values())
    # wouldn't necessarily need to be true, if we were shuffling names around, but we
    # currently aren't...
    assert not any(x in task_gloms for x in glomerulus_renames.keys())

    glomerulus_col = 'glomerulus'

    def _underscore_part(ser, i=0):
        return ser.str.split('_').apply(lambda x: x[i])

    def _first_underscore_part(ser):
        return _underscore_part(ser, i=0)

    claw_coord_cols = ['claw_x', 'claw_y', 'claw_z']
    def add_compartment_index(wPNKC: pd.DataFrame, shape: int) -> pd.DataFrame:
        """
        Compute compartment IDs and attach them as an INDEX LEVEL named 'compartment'.
        Returns a new DataFrame with the same rows, same glomerulus columns, and
        an extra index level 'compartment'.
        """
        # to ensure we don't accidentally changed input dataframe
        wPNKC = wPNKC.copy()

        # Coordinates must be present as index levels
        idx_names = list(wPNKC.index.names)
        need = claw_coord_cols
        missing = [n for n in need if n not in idx_names]
        assert not missing, f"Index missing levels required for compartments: {missing}"

        coords = wPNKC.index.to_frame(index=False)[need]

        if shape == 0:
            # shell over sphere
            center = coords.mean().to_numpy()
            distances = np.linalg.norm(coords.to_numpy() - center, axis=1)
            shell_r = distances.max()
            sphere_r = 0.5 * shell_r
            compartment_ids = np.where(distances <= sphere_r, 0, 1).astype(np.int32)
            # TODO delete (/ put behind verbose)
            print("shell over sphere")
        else:
            # TODO refactor to loop over claw_coord_cols?
            # 3×3×3 grid
            x_edges = np.linspace(coords['claw_x'].min(), coords['claw_x'].max(), 4)
            y_edges = np.linspace(coords['claw_y'].min(), coords['claw_y'].max(), 4)
            z_edges = np.linspace(coords['claw_z'].min(), coords['claw_z'].max(), 4)
            for edges in (x_edges, y_edges, z_edges):
                edges[0]  -= 1e-6
                edges[-1] += 1e-6
            ix = np.digitize(coords['claw_x'], x_edges) - 1
            iy = np.digitize(coords['claw_y'], y_edges) - 1
            iz = np.digitize(coords['claw_z'], z_edges) - 1
            compartment_ids = (ix * 9 + iy * 3 + iz).astype(np.int32)

            if (compartment_ids > 26).any():
                print("Some compartment_ids > 26 detected!")
                print(wPNKC.index[(compartment_ids > 26)])
            elif (compartment_ids < 0).any():
                print("Some compartment_ids < 0 detected!")
                print(wPNKC.index[(compartment_ids < 0)])
            else:
                print("All compartment_ids normal")

        # Safety: length match
        assert len(compartment_ids) == len(wPNKC), "compartment id length mismatch"

        # Remove any existing compartment column/level to avoid duplicates
        if 'compartment' in wPNKC.columns:
            wPNKC = wPNKC.drop(columns=['compartment'])

        # TODO delete. should never trigger
        assert 'compartment' not in wPNKC.index.names
        #

        # Attach as an index level (appended at the end)
        tmp = pd.Series(compartment_ids, index=wPNKC.index, name='compartment')
        wPNKC = wPNKC.set_index(tmp, append=True)
        assert wPNKC.index.names[-1] == 'compartment'

        # Reorder so 'compartment' sits right after 'claw_z' if those exist
        names = list(wPNKC.index.names)
        if set(claw_coord_cols).issubset(names):
            names_no_comp = [n for n in names if n != 'compartment']
            insert_pos = names_no_comp.index('claw_z') + 1
            new_order = (
                names_no_comp[:insert_pos] + ['compartment'] +
                names_no_comp[insert_pos:]
            )
            wPNKC = wPNKC.reorder_levels(new_order)

        return wPNKC


    # TODO also expose _drop_glom_with_plus in here? (and just default to value from
    # outer fn?)
    def _add_glomerulus_col_from_hemibrain_type(df: pd.DataFrame, pn_type_col: str,
        # TODO doc what kc_id_col is even used for. why not optional?
        # TODO double check doc about kc_id_col (that those are only two cases where
        # KCs would be dropped) is true
        kc_id_col: str, *, check_no_multi_underscores: bool = False) -> pd.DataFrame:
        """Returns `df` with added glomerulus_col column, and certain glomeruli dropped.

        Glomerulus parsed from `df[pn_type_col]`.

        kc_id_col should only ever be used to summarize how many KCs were dropped (if
        any) b/c of check_no_multi_underscores=True / _drop_glom_with_plus=True
        """
        assert glomerulus_col not in df.columns

        df = df.copy()

        assert not df[kc_id_col].isna().any()
        n_kcs_initial = df[kc_id_col].nunique()
        def _kc_drop_message(n_kcs_dropped):
            return (f'(also means that {n_kcs_dropped}/{n_kcs_initial} KCs only '
                'connected to these "glomeruli" dropped)'
            )

        assert not df[pn_type_col].isna().any()
        # askprat: are there specific PN types (RHS after '_') that i should
        # categorically be dropping? (prob not. what are prefixes anyway? all lineage
        # info, or anything closer to what i actually care about?).
        # Prat: no. keep all.
        #
        # a.type should all be roughly of form: <glomerulus-str>_<PN-group>, where
        # PN-group are distributed as follows (w/ connectome='hemibrain' data):
        # adPN       6927
        # lPN        2367
        # ilPN        296
        # lvPN        262
        # l2PN1       250
        # l2PN        137
        # adPNm4       85
        # ivPN         76
        # il2PN        49
        # lPNm11D      42
        # vPN          23
        # lvPN2        10
        # l2PNm16       7
        # adPNm5        5
        # lPNm13        2
        # adPNm7        1
        # lvPN1         1
        try:
            assert (df[pn_type_col].str.count('_') == 1).all()

        except AssertionError:
            # can do this for hemibrain input, but not fafb (b/c this type column in
            # fafb comes from aligning to hemibrain types, which are better annotated,
            # and i believe this multiple-underscore cases are all from a small number
            # of instances where this alignment process is ambiguous
            if check_no_multi_underscores:
                raise
            # debug: show all type_pre values missing the underscore
            no_us = df.loc[df['a.type'].str.count('_') == 0, 'a.type'].unique()
            print("type_pre values with NO underscore:", no_us)
            assert (df[pn_type_col].str.count('_') >= 1).all()

            # askprat: are any of below MG PNs, or something i want to include? what
            # are these weird glomeruli names? trailing +?
            # Prat: their alignment produced duplicates. not MG PNs. he thinks 'M' is to
            # indicate multiglomerular (or at least that it goes to multiple areas,
            # perhaps including things other than glomeruli), but not easy to get info
            # on which they are, without more work. he was saying if we really cared, we
            # could use the previously defined glomerular boundaries to count and figure
            # out which.
            #
            # connectome='hemibrain' has no rows w/ multiple '_'
            #
            # connectome='fafb-left'
            # M_adPNm4,M_adPNm5                120
            # VP1m+VP2_lvPN1,VP1m+VP2_lvPN2     23
            # M_lPNm12,M_lPNm13                 20
            # M_ilPNm90,M_ilPN8t91               4
            #
            # connectome='fafb-right'
            # M_adPNm4,M_adPNm5                86
            # M_lPNm12,M_lPNm13                12
            # VP1m+VP2_lvPN1,VP1m+VP2_lvPN2    12
            # M_ilPNm90,M_ilPN8t91              5
            multi_rows = df[pn_type_col].str.count('_') >= 2
            n_multi_rows = multi_rows.sum()
            assert n_multi_rows > 0

            df_no_multi = df[~multi_rows].copy()
            n_kcs_dropped = n_kcs_initial - df_no_multi[kc_id_col].nunique()

            warn(f'{connectome=} dropping {n_multi_rows} rows w/ multiple underscores '
                'in PN type:\n' +
                df[pn_type_col][multi_rows].value_counts().to_string() + '\n' +
                _kc_drop_message(n_kcs_dropped) + '\n'
            )
            df = df_no_multi

        # TODO replace this kwarg w/ one talking about dropping glomeruli w/ no
        # task-glomeruli inputs instead? could it be equiv, or no? or otherwise rename
        # it to be more clear about what it's currently dropping (multiglomerular PNs?
        # anything else?)?
        if _drop_glom_with_plus:
            has_plus = df[pn_type_col].str.contains('+', regex=False)
            if has_plus.any():
                # askprat: what is meaning when it finishes w/ '+', w/o that
                # being a separator between two glomerulus names?
                # Prat: (re: VP3+ does go somewhere else, but either "not dense enough
                # (in other place(s) it goes to)" or not going to somewhere in hemibrain
                # volume, but that could still be in AL...)
                #
                # what is 'Z'? (Prat: Z=SEZ. it also goes there.)
                #
                # connectome='hemibrain'
                # VP1d+VP4_l2PN1    250
                # VP3+VP1l_ivPN      76
                # VP1m+VP5_ilPN      64
                # VP5+Z_adPN         17
                # VP3+_vPN           17
                # VP1m+VP2_lvPN2     10
                # VP1m+VP2_lvPN1      1
                #
                # connectome='fafb-left'
                # VP1d+VP4_l2PN1                   285
                # VP3+VP1l_ivPN                    117
                # VP1m+VP5_ilPN                     92
                # VP5+Z_adPN                        47
                # VP1m+VP2_lvPN1,VP1m+VP2_lvPN2     23
                # VP3+_vPN                          20
                # VP1m+_lvPN                         6
                # VP1l+VP3_ilPN                      2
                # VP2+_adPN                          1
                #
                # connectome='fafb-right'
                # VP1d+VP4_l2PN1                   303
                # VP3+VP1l_ivPN                    112
                # VP1m+VP5_ilPN                    106
                # VP5+Z_adPN                        42
                # VP3+_vPN                          20
                # VP1m+VP2_lvPN1,VP1m+VP2_lvPN2     12
                # VP2+_adPN                          5
                # VP1m+_lvPN                         4
                # VP1l+VP3_ilPN                      3
                df_no_plus = df[~has_plus].copy()
                n_kcs_dropped = n_kcs_initial - df_no_plus[kc_id_col].nunique()
                warn(f'{connectome=} dropping {has_plus.sum()} rows w/ "+" in PN type:'
                    '\n' + df[pn_type_col][has_plus].value_counts().to_string() + '\n' +
                    _kc_drop_message(n_kcs_dropped) + '\n'
                )
                df = df_no_plus
            else:
                warn(f"not dropping glomeruli with '+' in their name, because "
                    f'{_drop_glom_with_plus=}. this preserves old hemibrain model '
                    'behavior exactly, but should probably be removed moving forward.'
                )
            # TODO delete (figuring out explanation for why i'm dropping these for
            # tianpei / to give this flag a better name)
            '''
            print()
            print(f'{_drop_glom_with_plus=}')
            print(f'{has_plus.sum()=}')
            import ipdb; ipdb.set_trace()
            '''
            #

        # TODO also print count of unique PN bodyids within each glom_strs value?
        # (here might not be the place anymore, if i even still care about this...)

        glom_strs = first_delim_sep_part(df[pn_type_col], sep='_')
        glom_str_set = set(glom_strs)

        # only doing if _drop_glom_with_plus, so i don't have to also add that flag to
        # dict key (cause it will change set of glomeruli, e.g. w/ hemibrain)
        if _drop_glom_with_plus:
            print("drop_glom_with_pluse reached? ")
            # (ran after end of first loop over model_kw_list, in model_mb_responses)
            # ipdb> {k: len(v) for k, v in _connectome2glomset.items()}
            # {'fafb-left': 57, 'fafb-right': 56, 'hemibrain': 56}
            # ipdb> sh = _connectome2glomset['hemibrain']
            # ipdb> sl = _connectome2glomset['fafb-left']
            # ipdb> sr = _connectome2glomset['fafb-right']
            #
            # ipdb> sl - sr
            # {'MZ'}
            # ipdb> sr - sl
            # set()
            #
            # ipdb> sr == sh
            # True
            glom_str_set = set(glom_strs)
            if connectome not in _connectome2glomset:
                _connectome2glomset[connectome] = glom_str_set
            else:
                # TODO TODO fix (prob just have to delete tho? could warn?)
                try:
                    assert _connectome2glomset[connectome] == glom_str_set
                except AssertionError:
                    # ipdb> len(glom_str_set)
                    # 56
                    # ipdb> len(_connectome2glomset[connectome])
                    # 58
                    # TODO TODO TODO prob drop these:
                    # ipdb> _connectome2glomset[connectome] - glom_str_set
                    # {'MZ', 'WED'}

                    # TODO delete
                    #breakpoint()
                    #
                    pass

        # glom_strs.value_counts() (w/ connectome='hemibrain' data):
        # DP1m         481
        # DM1          377
        # DC1          342
        # DL1          327
        # DM2          312
        # VM5d         310
        # DP1l         309
        # VC3l         301
        # DM6          297
        # DA1          290
        # DM4          283
        # VA2          280
        # VL2p         270
        # VC3m         255
        # VP1d+VP4     250
        # VA4          237
        # VA7m         231
        # DC2          231
        # VA3          228
        # DC3          226
        # VA6          217
        # VC4          207
        # DM3          207
        # DM5          205
        # VL2a         203
        # DL2d         197
        # V            195
        # D            179
        # VA5          168
        # VC2          159
        # VM3          154
        # VM2          150
        # DA2          147
        # VC5          142
        # M            142
        # VP1m         137
        # DL2v         137
        # DL5          136
        # VM5v         133
        # VA1d         131
        # VA7l         129
        # VC1          125
        # VM7d         109
        # VM7v          99
        # VM4           98
        # VA1v          93
        # DA4l          83
        # VM1           78
        # VP3+VP1l      76
        # VP2           71
        # VP1m+VP5      64
        # DC4           55
        # VP1d          49
        # DL4           38
        # DL3           38
        # VL1           37
        # DA3           35
        # DA4m          29
        # VP3+          17
        # VP5+Z         17
        # VP1m+VP2      11
        # VP4            6
        df[glomerulus_col] = glom_strs

        return df


    if connectome == 'hemibrain':
        if _use_matt_wPNKC:
            assert weight_divisor is None, \
                'weight_divisor must be None when _use_matt_wPNKC=True'

            matt_data_dir = repo_root / 'data/from_matt/hemibrain'

            # TODO which was that other CSV (that maybe derived these?) that was full
            # PN->KC connectome matrix?
            #
            # NOTE: gkc-halfmat[-wide].csv have 22 columns for glomeruli (/receptors).
            # This should be the number excluding 2a and 33b.
            gkc_wide = pd.read_csv(matt_data_dir / 'halfmat/gkc-halfmat-wide.csv')

            # TODO see if above include more than hallem glomeruli (and find
            # scripts that generated these -> figure out how to regen w/ more than
            # hallem glomeruli)
            # TODO process gkc_wide to have consistent glomerulus/receptor labels
            # where possible (consistent w/ what i hope to also return in random
            # connectivity cases, etc) (presumbly if it's already a subset, should be
            # possible for all of that subset?)

            # All other columns are glomerulus names.
            assert gkc_wide.columns[0] == 'bodyid'

            wPNKC = gkc_wide.set_index('bodyid', verify_integrity=True)
            wPNKC.columns.name = glomerulus_col
            assert wPNKC.columns.isin(task_gloms).all()

            # TODO TODO where are values >1 coming from in here:
            # ipdb> mdf.w.value_counts()
            # 1    9218
            # 2     359
            # 3      15
            # 4       1
            mdf = pd.read_csv(matt_data_dir / 'glom-kc-cxns.csv')

            mdf.glom = mdf.glom.replace(glomerulus_renames)

            # NOTE: if we do this, mdf_wide.max() is only >1 for VC3 (and it's 2 there,
            # from merging VC3l and VC3m)
            #mdf.loc[mdf.w > 1, 'w'] = 1

            # TODO are all >1 weights below coming from 'w' values that are already >1
            # before this sum? set all to 1, recompute, and see? (seems so?)
            # TODO replace groupby->pivot w/ pivot_table (aggfunc='count'/'sum')?
            # seemed possible w/ pratyush input (but 'weight' input there was max 1...)
            # TODO factor out similar pivoting (w/ pivot_table) below -> share w/ here?
            mcounts = mdf.groupby(['glom', 'bodyid']).sum('w').reset_index()
            mdf_wide = mcounts.pivot(columns='glom', index='bodyid', values='w').fillna(
                0).astype(int)
            # TODO uncomment
            #del mcounts

            # TODO try to remove need for orns.orns + handle_multiglomerular_receptors
            # in here?
            # TODO refactor to share w/ code calling connectome_wPNKC? or get from a
            # module level const in drosolf (maybe add one)?
            hallem_orn_deltas = orns.orns(add_sfr=False, drop_sfr=False,
                columns=glomerulus_col).T

            hallem_glomeruli = handle_multiglomerular_receptors(hallem_orn_deltas,
                drop=True
            ).index
            del hallem_orn_deltas

            mdf_wide = mdf_wide[[x for x in hallem_glomeruli if x != 'DA4m']].copy()
            del hallem_glomeruli

            mdf_wide = mdf_wide[mdf_wide.sum(axis='columns') > 0].copy()

            # TODO move creation of mdf_wide + checking against wPNKC to model_test.py /
            # similar
            assert wPNKC.columns.equals(mdf_wide.columns)
            assert set(mdf_wide.index) == set(wPNKC.index)
            mdf_wide = mdf_wide.loc[wPNKC.index].copy()
            assert mdf_wide.equals(wPNKC)
            del mdf_wide

            # TODO TODO still define one of these as df (+ any other variables i need
            # to define? some column names?), so i can make the same histograms below?
            # or never want them in the _use_matt_wPNKC case?

            # from matt-hemibrain/docs/data-loading.html
            # pn_gloms <- read_csv("data/misc/pn-major-gloms.csv")
            # pn_kc_cxns <- read_csv("data/cxns/pn-kc-cxns.csv")
            # glom_kc_cxns <- pn_kc_cxns %>%
            #   filter(weight >= 3) %>%
            #   inner_join(pn_gloms, by=c("bodyid_pre" = "bodyid")) %>%
            #   group_by(major_glom, bodyid_post) %>%
            #   summarize(w = n(), .groups = "drop") %>%
            #   rename(bodyid = bodyid_post, glom = major_glom)
            # write_csv(glom_kc_cxns, "data/cxns/glom-kc-cxns.csv")

            # inspecting some of the files from above:
            # tom@atlas:~/src/matt/matt-hemibrain/data/misc$ head pn-major-gloms.csv
            # bodyid,major_glom
            # 294792184,DC1
            # 480927537,DC1
            # 541632990,DC1
            # 542311358,DC2
            # 542634818,DM1
            # ...
            # tom@atlas:~/src/matt/matt-hemibrain/data$ head cxns/pn-kc-cxns.csv
            # bodyid_pre,bodyid_post,weight,weight_hp
            # 542634818,487489028,17,9
            # 542634818,548885313,1,0
            # 542634818,549222167,1,1
            # 542634818,5813021736,6,4
            # ...
            # NOTE: pn-kc-cxns.csv above should also be what matt uses to generate
            # distribution of # claws per KC (in matt-hemibrain/docs/mb-claws.html)

            n_kcs = len(wPNKC)

            kc_id_col = 'bodyid'

        elif synapse_con_path is not None and synapse_loc_path is not None:
            # used in title of histograms later
            # TODO or does the other one contain more of the important info? use both?
            # just list the containing dir here?
            data_path = synapse_con_path

            #  load & clean connectivity CSV
            df = pd.read_csv(synapse_con_path)

            df['type_pre'] = df['type_pre'].str.replace(
                r'(WED)(PN\d+)', r'\1_\2', regex=True
            )
            df = df.rename(columns={
                'bodyId_pre': 'a.bodyId',
                'bodyId_post':'b.bodyId',
                'weight':     'c.weight',
                'type_pre':   'a.type',
                'type_post':  'b.type'
            })
            pn_id_col         = 'a.bodyId'
            kc_id_col         = 'b.bodyId'
            weight_col        = 'c.weight'
            hemibrain_pn_type = 'a.type'
            claw_col          = 'claw'

            # drop funky '+' / multi-underscore types & extract glomerulus
            df = _add_glomerulus_col_from_hemibrain_type(
                df, hemibrain_pn_type, kc_id_col, check_no_multi_underscores=False
            )
            df = add_kc_type_col(df, 'b.type')

            # keep only task-et-al glomeruli so no empty claws later.
            df = df[df[glomerulus_col].isin(task_gloms)].copy()
            if isinstance(task_gloms, (list, tuple, pd.Index)):
                glom_order = list(task_gloms)          # preserve caller’s order if it’s ordered
            else:
                glom_order = sorted(set(task_gloms))   # fallback to deterministic order

            loc = pd.read_csv(synapse_loc_path)
            loc = loc.rename(columns={
                'bodyId_pre':'a.bodyId',
                'bodyId_post':'b.bodyId'
            })
            df = df.merge(loc, on=[pn_id_col, kc_id_col], how='inner')

            input_coord_cols = ['x_pre', 'y_pre', 'z_pre']
            for ax in input_coord_cols:
                df[ax] *= PIXEL_TO_UM

            # DBSCAN cluster into pre_claw
            clustered = []
            for kc, grp in df.groupby(kc_id_col, sort=False):
                pts = grp[input_coord_cols].values

                labels = DBSCAN(eps=cluster_eps, min_samples=cluster_min_samples
                    ).fit_predict(pts)

                g = grp.copy()
                g['pre_claw'] = labels
                clustered.append(g)

            df = pd.concat(clustered, ignore_index=True)
            # TODO refactor to share 'pre_claw' throughout
            df = df[df.pre_claw != -1]   # drop noise

            column_order = (
                [kc_id_col, claw_col, 'n_syn', glomerulus_col] + claw_coord_cols +
                ['pre_cell_ids']
            )

            # For each (KC,claw), pick the single glomerulus with most synapses
            claws = []
            grouped = df.groupby([kc_id_col,'pre_claw'], sort=False)
            for (kc, claw), grp in grouped:
                # find the PNs in this cluster
                pre_cells = grp[pn_id_col].unique().tolist()

                # count synapses per glomerulus
                counts    = grp[glomerulus_col].value_counts()
                chosen_gl = counts.idxmax()

                # compute centroid of the kept synapses
                centroid  = grp[input_coord_cols].mean()

                assert list(centroid.index) == input_coord_cols
                # e.g. 'x_pre' -> 'claw_x'
                centroid = centroid.rename(lambda x: f"claw_{x.split('_')[0]}")
                assert list(centroid.index) == claw_coord_cols

                claw_dict = {
                    kc_id_col: kc,
                    claw_col: claw,
                    'n_syn': len(grp),
                    glomerulus_col: chosen_gl,
                    'pre_cell_ids': pre_cells,
                }
                claw_dict.update(centroid.to_dict())

                claws.append(claw_dict)

            claw_df = pd.DataFrame(claws)
            assert set(claw_df.columns) == set(column_order)
            claw_df = claw_df[column_order]

            min_synapses = 3
            claw_df = claw_df[claw_df['n_syn'] >= min_synapses]

            # build & save the UN-MERGED wPNKC
            wPNKC_unmerged_counts = claw_df.pivot_table(
                index=[kc_id_col, claw_col] + claw_coord_cols,
                columns=glomerulus_col,
                values='n_syn',
                fill_value=0
            ).astype(int)
            wPNKC_unmerged = (wPNKC_unmerged_counts > 0).astype(int)

            if plot_dir is not None:
                # TODO need to handle multiple writes to same path? (wrapper will err by
                # default, in that case)
                to_csv(wPNKC_unmerged.reset_index(),
                    plot_dir / 'wPNKC_clustered_unmerged.csv', index=True
                )

            avg_claws = claw_df.groupby(kc_id_col)[claw_col].nunique().mean()
            print(f"Average claws per KC before merging: {avg_claws:.2f}")

            merge_thresh = 3  # µm
            merged_claws = []

            for kc, grp in claw_df.groupby(kc_id_col, sort=False):
                # grab the 3D centroids
                coords = grp[claw_coord_cols].values

                # cluster centroids within merge_thresh; min_samples=1 => every point
                # belongs
                merge_labels = DBSCAN(eps=merge_thresh, min_samples=1
                    ).fit_predict(coords)

                grp = grp.assign(merge_id=merge_labels)

                # now collapse each merge-cluster into one “super-claw”
                for merge_id, sub in grp.groupby('merge_id', sort=False):
                    total_n_syn = sub['n_syn'].sum()

                    # pick the glomerulus with the most synapses (sum over sub-claws)
                    gl_counts   = sub.groupby(glomerulus_col)['n_syn'].sum()
                    chosen_gl   = gl_counts.idxmax()

                    # union of all pre_cell_ids
                    all_pre_ids = sorted(
                        {pid for lst in sub['pre_cell_ids'] for pid in lst}
                    )

                    # centroid weighted by n_syn
                    weighted = (sub[claw_coord_cols].multiply(sub['n_syn'], axis=0)
                                    .sum(axis=0) / total_n_syn)

                    claw_dict = {
                        kc_id_col: kc,
                        claw_col: merge_id,
                        'n_syn': total_n_syn,
                        glomerulus_col: chosen_gl,
                        'pre_cell_ids': all_pre_ids,
                    }
                    assert set(weighted.keys()) == set(claw_coord_cols)
                    claw_dict.update(weighted)

                    merged_claws.append(claw_dict)

            # overwrite claw_df with the merged result
            claw_df = pd.DataFrame(merged_claws)
            assert set(claw_df.columns) == set(column_order)
            claw_df = claw_df[column_order]

            avg_claws = claw_df.groupby(kc_id_col)[claw_col].nunique().mean()
            print(f"Average claws per KC after merging: {avg_claws:.2f}")

            claw_levels = [kc_id_col, claw_col] + claw_coord_cols
            # pivot to a (KC,claw,x,y,z)×glomerulus matrix, values = 1
            wPNKC_counts = claw_df.pivot_table(
                index=claw_levels,
                columns=glomerulus_col,
                values = 'n_syn',
                fill_value=0
            ).astype(int)

            present = [g for g in glom_order if g in wPNKC_counts.columns]
            wPNKC_counts = wPNKC_counts.loc[:, present]
            wPNKC = (wPNKC_counts > 0).astype(int)

            # TODO factor out pre_cell_ids to shared var
            meta = claw_df.set_index(claw_levels)['pre_cell_ids']
            wPNKC['pre_cell_ids'] = meta

            # TODO why using claw_id here and not 'claw' as before? just change to
            # claw_id above (assuming we do want output to be claw_id. prob also
            # factor common CLAW_ID up top)?
            wPNKC = wPNKC.rename_axis(index={claw_col: 'claw_id'})

            # record how many claws total for your downstream sanity checks
            n_kcs = wPNKC.shape[0]
            wPNKC = add_compartment_index(wPNKC, shape=0)

            # TODO still need? redundant w/ wPNKC that will be saved later
            # automatically?
            if plot_dir is not None:
                # TODO need to handle multiple writes to same path? (wrapper will err by
                # default, in that case)
                to_csv(wPNKC.reset_index(),
                    plot_dir / 'wPNKC_clustered_merged.csv', index=True
                )

        else:
            data_path = repo_root / 'data/PNtoKC_connections_raw.xlsx'
            df = pd.read_excel(data_path)

            pn_id_col = 'a.bodyId'
            kc_id_col = 'b.bodyId'
            weight_col = 'c.weight'

            hemibrain_pn_type = 'a.type'

            # TODO move this call into `not _use_matt_wPNKC` case below (to share w/
            # connectome='fafb-[left|right]' cases below)?
            df = _add_glomerulus_col_from_hemibrain_type(df, hemibrain_pn_type,
                kc_id_col, check_no_multi_underscores=True
            )
            df = add_kc_type_col(df, 'b.type')

    else:
        fafb_dir = from_prat / '2024-09-13'

        if connectome == 'fafb-left':
            data_path = fafb_dir / 'FlyWire_PNKC_Left.csv'
        else:
            assert connectome == 'fafb-right'
            data_path = fafb_dir / 'FlyWire_PNKC_Right.csv'

        df = pd.read_csv(data_path)

        cols_with_nan = df.isna().any()
        assert set(cols_with_nan[cols_with_nan].index) == {
            'source_cell_type', 'target_cell_type'
        }

        assert (df.source_cell_class == 'ALPN').all()
        assert (df.target_cell_class == 'Kenyon_Cell').all()

        if connectome == 'fafb-left':
            assert (df.source_side == 'left').all()

            # askprat: drop those w/ target side == 'right'?
            # Prat: eh, any of these options could work. up to me.
            # (prob doesn't matter much anyway, looking at which glomeruli it is...)
            #
            # TODO or just use them too? could turn to be roughly equiv to using values
            # from other csv (appending two w/ same 'target_side' together)?
            # TODO TODO or load both csvs and add both together, based on target
            # side (prob doesn't matter hugely w/ how many fewer connections there are)?
            # TODO is there anything else special about these PNs that cross midline?
            # (maybe we'd exclude already anyway, for some other reason?)
            #
            # ipdb> df.target_side.value_counts()
            # left     13774
            # right      275
            #
            # Prat: below mostly/all the bilateral PNs he was excited about before, that
            # i had helped him image
            #
            # ipdb> df.loc[df.target_side == 'right', 'source_hemibrain_type'].value_counts()
            # V_ilPN                  87
            # VP3+VP1l_ivPN           65
            # VP1m+VP5_ilPN           45
            # VP1d_il2PN              42
            # VL1_ilPN                29
            # M_ilPNm90,M_ilPN8t91     3
            # VP1l+VP3_ilPN            2
            # M_smPNm1                 1
            # M_smPN6t2                1
        else:
            assert (df.source_side == 'right').all()
            # ipdb> df.target_side.value_counts()
            # right    13485
            # left       314
            #
            # ipdb> df.loc[df.target_side == 'left', 'source_hemibrain_type'].value_counts()
            # V_ilPN                  145
            # VP1m+VP5_ilPN            60
            # VP3+VP1l_ivPN            48
            # VP1d_il2PN               30
            # VL1_ilPN                 25
            # M_ilPNm90,M_ilPN8t91      3
            # M_smPN6t2                 2
            # VP1l+VP3_ilPN             1

        pn_id_col = 'source'
        kc_id_col = 'target'
        weight_col = 'weight'

        hemibrain_pn_type = 'source_hemibrain_type'
        df = _add_glomerulus_col_from_hemibrain_type(df, hemibrain_pn_type, kc_id_col)

        # this should be the same as the min_weight from hemibrain, where in that case
        # prat's query is what filtered stuff w/ smaller weight
        df = df[df[weight_col] >= 4].copy()

        # TODO delete
        # fafb_types = df.source_cell_type.dropna()
        # # true for at least fafb-left
        # assert (fafb_types.str.count('_') == 1).all()
        # fafb_gloms = first_delim_sep_part(fafb_types, sep='_')
        # odf = df.dropna(subset=['source_cell_type'])
        # assert odf.index.equals(fafb_gloms.index)
        # print(pd.concat([fafb_gloms, odf.glomerulus], axis=1).drop_duplicates())
        #
        # (askprat) want to change handling of any of these? have been
        # merging VC3l and VC3m into "VC3" (w/ old hemibrain stuff, at least). should
        # glomerulus_renames reflect this?
        # Prat: just completely ignore the source_cell_type values. almost certainly not
        # meaningful corrections made by the flywire people.
        #
        # why does task not split them? same receptor or something?
        # (task doesn't refer to VC3l/m, but does list diff receptors/etc for VC3 and
        # VC5. they also split VM6 into VM6v/m/l [all w/ at least mostly same
        # receptors]. they might also be saying that the "canonical" VM6 was VM6v?)
        #
        # (same combinations for both left/right)
        #       source_cell_type glomerulus
        # 630                VC3       VC3l
        # 9868               VC5       VC3m
        # 10678              VM6        VC5
        #
        # ipdb> 'VM6' in set(df.glomerulus)
        # False

        # askprat: do anything w/ 'target_hemibrain_type'? e.g. 'KCab-s', 'KCg-m',
        # etc (prob not, at least not categorically filtering out any of them)
        # Prat: final part after dash is from clustering on connectome. no reason to
        # exclude any of this.
        #
        # connectome='fafb-left'
        # ipdb> df.target_hemibrain_type.value_counts()
        # KCg-m         6463
        # KCab-m        1893
        # KCab-s        1874
        # KCab-c        1221
        # KCa'b'-m       765
        # KCa'b'-ap2     553
        # KCa'b'-ap1     421
        # KCg-d           66
        # KCab-p          44
        # KCg-s2           6
        # KCg-s3           4
        # KCg-s1           2
        #
        # connectome='fafb-right'
        # ipdb> df.target_hemibrain_type.value_counts()
        # KCg-m         6555
        # KCab-s        1800
        # KCab-m        1542
        # KCab-c        1357
        # KCa'b'-m       745
        # KCa'b'-ap2     613
        # KCa'b'-ap1     346
        # KCg-d           73
        # KCab-p          51
        # KCg-s2           5
        # KCg-s3           1
        # KCg-s1           1


    # TODO replace `glomerulus` w/ `glomerulus_col` below? or revert to hardcode above?

    kc_types = None
    # TODO TODO also need to exclude path loading pratyush's new 2025-08-20 outputs?
    if not _use_matt_wPNKC:
        # TODO delete

        # TODO TODO TODO finish + move up into appropriate place in this fn

        # TODO TODO csv contents all same as parquet ones? (suffix='Synapses' only
        # exists for CSV, and suffix='Claws' only exists as parquet. anything in 'Claws'
        # one i need?)
        prat_hemibrain_PNKC_claw_dir = from_prat / '2025-08-20'

        prefix = 'PN-KC_Connectivity_'

        # columns:
        # bodyId_pre, bodyId_post, node_id_post, connector_id_post, connector_type,
        # anatomical_claw, dist_to_root, weight, type_post, instance_post, instance_pre,
        # type_pre, dist_influence
        #
        # can ignore: node_id_post, connector_id_post, connector_type
        syns = pd.read_csv(prat_hemibrain_PNKC_claw_dir / f'{prefix}Synapses.csv')

        assert (syns['weight'] == 1).all()

        syns = syns.drop(columns=['node_id_post', 'connector_id_post', 'connector_type',
            'weight'
        ])

        # ipdb> syns.bodyId_pre.unique().shape
        # (158,)
        # ipdb> syns.bodyId_post.unique().shape
        # (1786,)

        assert (len(syns[['type_pre', 'instance_pre']].drop_duplicates()) ==
            syns.type_pre.nunique() == syns.instance_pre.nunique()
        )

        prior_kc_ids = df[kc_id_col].unique()
        curr_kc_ids = syns.bodyId_post.unique()
        # so there are 94 KC IDs we had before that are not here.
        # and 50 of new set of IDs were not in the old set of IDs (how did that happen?)
        #
        # ipdb> len(set(prior_kc_ids) - set(curr_kc_ids))
        # 94
        # ipdb> len(set(curr_kc_ids) - set(prior_kc_ids))
        # 50
        #
        # ipdb> np.isin(curr_kc_ids, prior_kc_ids).sum()
        # 1736

        # TODO check PN IDs too?


        # TODO delete
        print(f'{syns.anatomical_claw.isna().sum()=}')
        #

        assert syns.anatomical_claw.dropna().min() == -1
        # TODO delete
        # ipdb> (syns.anatomical_claw == -1).sum()
        # 12225
        # ipdb> (syns.anatomical_claw == -1).sum() / len(syns)
        # 0.06579124397922664
        #
        # only lost 13 KC IDs doing this
        # ipdb> syns[syns.anatomical_claw != -1].bodyId_post.unique().shape
        # (1773,)
        #
        # len(syns)=185815
        #
        # TODO warn about this dropping, w/ breakdown of NaN vs -1
        syns = syns[(syns.anatomical_claw != -1) & syns.anatomical_claw.notna()].copy()
        # (will actually be less now that we are also dropping NaN claw IDs)
        # len(syns)=173590

        # TODO TODO TODO ok maybe it actually was numbered within each (KC, PN) pair?
        # change all comments saying numbered per-KC back. getting duplicates when
        # trying to set index on claw means below (w/o using PN ID)
        #
        # should be numbered within each KC, from 0. -1 for synapses not assigned to any
        # claw.
        # TODO check numbered sequentially w/in each KC (and again after all
        # dropping? or do we only ever drop all/no synapses per claw?) (matter?)
        claw_ids = syns['anatomical_claw']

        assert not claw_ids.isna().any()

        assert pd_allclose(claw_ids, claw_ids.astype(int))
        # max is 19! probably one of those weird KCs he was showing me? may not be real
        # claws
        # TODO TODO want to experiment w/ dropping claws w/o some threshold number of
        # synapses? does that change upper end of #-claws-per-KC much?
        syns['anatomical_claw'] = claw_ids.astype(int)
        del claw_ids

        # TODO TODO other things to drop? certain [type|instance]_[post|pre] (no other
        # columns worth dropping from)

        # TODO TODO use these for types later, instead of just the coarser ones? provide
        # both?
        # ipdb> syns.instance_post.unique()
        # array(['KCab-m', 'KCg-m', 'KCab-c', 'KCab-s', "KCa'b'-m", "KCa'b'-ap2",
        #        'KCg-d', 'KCg-t', "KCa'b'-ap1", 'KCy(half)', 'KCg-s4',
        #        'KCg-s2(super)', 'KCab-p', 'KC(incomplete?)', 'KCg-s1(super)',
        #        'KCg-s3'], dtype=object)
        #
        # ipdb> syns.type_post.unique()
        # array(['KCab', 'KCg', "KCa'b'", 'KCy(half)', 'KC(incomplete?)'],
        #       dtype=object)

        # (this was before dropping anatomical_claw == -1)
        # ipdb> syns.type_post.value_counts()
        # KCg                99193
        # KCab               61270
        # KCa'b'             24969
        # KCy(half)            242
        # KC(incomplete?)      141
        #
        # TODO try with and without this?
        # TODO any justification for keeping one or the other of these?
        # TODO warn about these
        kc_types_to_drop = ('KCy(half)', 'KC(incomplete?)')
        syns = syns[~ syns.type_post.isin(kc_types_to_drop)].copy()
        # (will actually be less now that we are also dropping NaN claw IDs)
        # len(syns)=173222

        # TODO delete (check again after _add_glom... which also will drop some KCs)
        # 150 PNs here, after two steps dropping KCs above

        # TODO what glomeruli even do they correspond to? (they don't. wedge. yes, drop)
        # just drop? and it's only 4 rows in all of df, so def feel safe dropping
        #
        # only 4 rows in df here (/ 173222) should have these values (2 each, with all
        # having suffix of '_R' in instance_pre column. these should be the only rows
        # that would cause check_no_multi_underscores=True to fail.
        pn_types_to_drop = ('WEDPN12', 'WEDPN4')
        syns = syns[~ syns['type_pre'].isin(pn_types_to_drop)].copy()

        # TODO TODO OK with all this? (from _drop_glom_with_plus=True)
        # Warning: connectome='hemibrain' dropping 7309 rows w/ "+" in PN type:
        # VP1d+VP4_l2PN1    4093
        # VP3+VP1l_ivPN     1571
        # VP1m+VP5_ilPN      818
        # VP3+_vPN           539
        # VP5+Z_adPN         176
        # VP1m+VP2_lvPN2      80
        # VP1m+_lvPN          16
        # VP2+_adPN           10
        # VP1m+VP2_lvPN1       5
        # VP1l+VP3_ilPN        1
        # (also means that 11/1768 KCs only connected to these "glomeruli" dropped)
        # TODO TODO factor out these ID cols (+ PN ID one), as needed (esp after
        # factoring all this new code to an appropriate home)
        syns = _add_glomerulus_col_from_hemibrain_type(syns, 'type_pre', 'bodyId_post',
            check_no_multi_underscores=True
        )
        # TODO TODO assert glomerulus 1:1 w/ type (or after all dropping below, if it's
        # only then that it becomes true. it is currently true after all the dropping,
        # where syn is len 164986). (_add_glomerulus_col* already do something like
        # that?)
        # (will actually be less now that we are also dropping NaN claw IDs)
        # len after: 165909 (w/ _drop_glom_with_plus=True)

        # TODO TODO how to interpret these?
        # ipdb> (~ np.isfinite(syns.dist_to_root)).sum()
        # 923
        #
        # ipdb> syns[(~ np.isfinite(syns.dist_to_root))]
        #        bodyId_pre  bodyId_post  node_id_post  ...  type_pre dist_influence  glomerulus
        # 3836   542634818   5812982192           NaN  ...   DM1_lPN            NaN         DM1
        #
        # ipdb> s1 = set(syns.loc[(~ np.isfinite(syns.dist_to_root))]['bodyId_post'])
        # ipdb> s2 = set(syns.loc[(np.isfinite(syns.dist_to_root))]['bodyId_post'])
        # ipdb> len(s1)
        # 152
        # ipdb> len(s2)
        # 1733
        # ipdb> len(s1 & s2)
        # 128
        # ipdb> syns.bodyId_post.nunique()
        # 1757
        #
        # ipdb> s1 = set(syns.loc[(~ np.isfinite(syns.dist_to_root))]['bodyId_pre'])
        # ipdb> s2 = set(syns.loc[(np.isfinite(syns.dist_to_root))]['bodyId_pre'])
        # ipdb> len(s1)
        # 63
        # ipdb> len(s2)
        # 131
        # ipdb> len(s1 & s2)
        # 61
        # ipdb> len(s1 | s2)
        # 133
        #
        # ipdb> syns.loc[~ np.isfinite(syns.dist_to_root)]['dist_to_root'
        #    ].value_counts(dropna=False)
        # NaN    869
        # inf     54
        # Name: dist_to_root, dtype: int64
        # TODO TODO need to reset_index() before this? or use .loc? why still have some
        # (~ np.isfinite(syns.dist_to_root)) values after?
        syns = syns[np.isfinite(syns.dist_to_root)].copy()
        #
        # probably reasonable (in nm, so ~20uM max, and mostly much less)
        # ipdb> syns.loc[np.isfinite(syns.dist_to_root)]['dist_to_root'].max()
        # 19690.82444190979
        # ipdb> syns.loc[np.isfinite(syns.dist_to_root)]['dist_to_root'].quantile(q=.99)
        # 14128.878774452205
        # ipdb> syns.loc[np.isfinite(syns.dist_to_root)]['dist_to_root'].quantile(q=.9)
        # 10384.66800403595

        assert pd_allclose(1 / syns.dist_to_root, syns.dist_influence)

        # from Prat:
        # dist_influence is sum of 1 / dist_to_root (nm), for each (PN, KC) pair
        # total_weight is sum of dist_influence, per KC
        # scaled_weight is dist_influence / total_weight

        # hack to remove the inf values causing issues in groupby mean
        #
        # ipdb> (syns.dist_to_root == 0).sum()
        # 53
        #
        # 14.0 (nm)
        min_nonzero_dist = syns.dist_to_root[syns.dist_to_root > 0].min()
        # TODO warn about this (/ avoid need for it somehow? prob can't w/o prat doing
        # something diff, and that may not make sense)
        # TODO assert this doesn't change max dist_influence (barring float issues?)?
        # TODO TODO maybe take mean of dist_to_root and then take inverse of that (might
        # give us a bit more dynamic range for stuff we are currently just clipping?)
        syns.loc[syns.dist_to_root == 0, 'dist_influence'] = 1 / min_nonzero_dist
        assert np.isfinite(syns.dist_influence).all()

        # TODO check normalized outputs for cases where KCs include one of these really
        # high finite dist_influence values?
        # ipdb> syns.dist_influence[(syns.dist_to_root > 0)].quantile(q=0.95)
        # 0.0006495464542001794
        # ipdb> syns.dist_influence[(syns.dist_to_root > 0)].quantile(q=0.999)
        # 0.007494860294504738
        # ipdb> syns.dist_influence[(syns.dist_to_root > 0)].max()
        # 0.0714285714285714
        #
        # ipdb> syns.dist_influence[(syns.dist_to_root > 0)].sort_values().tail(n=20)
        # 41421     0.044194
        # 37379     0.044194
        # 80148     0.044194
        # 24389     0.044194
        # 167281    0.044194
        # 77341     0.055556
        # 98631     0.055556
        # 70127     0.055556
        # 141742    0.055556
        # 40985     0.055556
        # 63845     0.055556
        # 168557    0.062500
        # 130844    0.062500
        # 85544     0.062500
        # 184048    0.062500
        # 178763    0.062500
        # 75959     0.062500
        # 69110     0.062500
        # 171826    0.062500
        # 132006    0.071429
        # TODO TODO can i still clearly see the effect of these outliers if i average
        # within claws?
        # TODO are some claws outliers themselves, with many synapses consistently
        # above? i assume so... everything should be within a small number of microns,
        # right?


        # TODO reset_index() on syns somewhere after all the dropping above? prob
        # doesn't matter...

        # TODO TODO count how many synapses per claw (+ plot dist(s), maybe per subtype)

        # TODO want any other columns in output?
        claw_cols = ['bodyId_pre', 'bodyId_post', 'anatomical_claw']
        extra_cols_to_keep = [glomerulus_col, 'type_post', 'instance_post']
        # TODO maybe also dist_to_root (then rename to include '_nm' suffix)?
        # (may also want to ONLY compute using that, then take inverse after mean w/in
        # claw)
        cols_to_avg = ['dist_influence']
        assert (
            len(syns[claw_cols].drop_duplicates()) ==
            len(syns[claw_cols + extra_cols_to_keep].drop_duplicates())
        )
        claw_dist_influences = syns.groupby(claw_cols + extra_cols_to_keep)[cols_to_avg
            ].mean()

        # should be redundant w/ drop_duplicates check w/ same cols above
        assert claw_dist_influences.droplevel(extra_cols_to_keep).equals(
            syns.groupby(claw_cols)[cols_to_avg].mean()
        )

        # ipdb> claw_dist_influences.groupby(['bodyId_pre','bodyId_post']).size().mean()
        # 1.1184173603965952
        # ipdb> claw_dist_influences.groupby(['bodyId_pre','bodyId_post']).size().max()
        # 15

        claw_dist_influences = claw_dist_influences.reset_index().rename(columns={
            'bodyId_post': KC_ID,
            'type_post': KC_TYPE,

            # more fine grained than the 3 values for KC_TYPE we wil have here
            'instance_post': 'kc_subtype',

            'bodyId_pre': 'pn_id',
        })

        # ipdb> qs = [0, 0.0005, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 0.999, 0.9995, 1]
        # ipdb> claw_dist_influences.dist_influence.quantile(q=qs)
        # 0.0000    0.000051
        # 0.0005    0.000057
        # 0.0010    0.000059
        # 0.0100    0.000071
        # 0.1000    0.000096
        # 0.2500    0.000125
        # 0.5000    0.000191
        # 0.7500    0.000299
        # 0.9000    0.000469
        # 0.9900    0.002861
        # 0.9990    0.008632
        # 0.9995    0.010624
        # 1.0000    0.037253
        #
        # TODO TODO are these not just getting swamped by large ones frequently tho?
        # since they will often vary over orders of magnitude (and presumably within
        # many individual KCs, not just across them).
        # TODO TODO TODO matter? want to normalize in some way other than straight
        # average of this?
        # ipdb> claw_dist_influences.groupby(KC_ID).dist_influence.sum().quantile(q=qs)
        # 0.0000    0.000061
        # 0.0005    0.000064
        # 0.0010    0.000065
        # 0.0100    0.000264
        # 0.1000    0.000556
        # 0.2500    0.000860
        # 0.5000    0.001633
        # 0.7500    0.002802
        # 0.9000    0.004127
        # 0.9900    0.009087
        # 0.9990    0.017528
        # 0.9995    0.022459
        # 1.0000    0.039409
        #
        # TODO TODO plot subtype distributions of these diff quantities? per claw and
        # per KC at least

        # TODO delete if doesn't matter, with how i end up computing+assigning new
        # labels
        #
        # to group things a tad nicer before we assign new claw IDs within each group
        claw_dist_influences = claw_dist_influences.sort_values(
            [KC_ID, glomerulus_col, 'pn_id']
        )
        #

        # OK now it should actually be numbered (w/ consecutive integers from 0) within
        # each KC
        claw_dist_influences['claw_id'] = claw_dist_influences.groupby(KC_ID).cumcount()
        claw_dist_influences = claw_dist_influences.drop(columns='anatomical_claw')
        claw_dist_influences = claw_dist_influences.set_index(['kc_id', 'claw_id'],
            verify_integrity=True
        )

        # TODO TODO check against what pratyush had (was his not a bit lower?
        # differences in dropping account for it?)
        #
        # ok this seems somewhat reasonable
        # ipdb> claw_dist_influences.groupby(KC_ID).size().mean()
        # 6.899596076168494

        # TODO TODO before returning, rename anatomical_claw -> claw/claw_id
        # (will just add new column from renumbering, then drop anatomical_claw col
        # probably)

        # TODO TODO does it actually make sense to normalize dist_influence w/in each
        # KC? if all the claws are far away, shouldn't that behave different from if
        # they are all close? and how much does this inverse quantity swing around at
        # the upper end (bunch of small values i assume?)?

        # TODO move this to a good spot later, once i factor out rest of this loading
        # into separate paths
        # TODO TODO move this after dropping based on isfinite(dist_to_root) below?
        # still true there? (prob)
        #
        # len of old set is 62 if connectome='hemibrain' and _drop_glom_with_plus=False
        # (more than the 56 we have on these new outputs, seemingly regardless of
        # _drop_glom_with_plus)
        # TODO look into why _drop_glom_with_plus is behaving differently on
        # old/new outputs? some filter imposed by prat's query?
        if (connectome == 'hemibrain' and _drop_glom_with_plus and
            synapse_con_path is None):

            # same 56 in each case, even after all the dropping on syns
            assert set(df[glomerulus_col].unique()) == set(syns[glomerulus_col].unique())

            # TODO assert count fractions are within some margin (more work, perhaps not
            # worth)?

        # TODO look at rows for one KC to sanity check my understanding of the
        # values (both in syns and in claw means)


        # TODO TODO does this also have NaN claw IDs like syns does? no! but does it
        # have same number of claws after dropping? may need to compute before i drop
        # other things from syns, for comparison?
        #
        # ipdb> claws[['bodyId_pre','bodyId_post','anatomical_claw']].drop_duplicates().shape
        # (17313, 3)
        #
        # TODO delete
        # ipdb> claws
        #        bodyId_pre instance_pre type_pre  bodyId_post instance_post type_post  anatomical_claw  weight
        # 0       542634818    DM1_lPN_R  DM1_lPN    301314208        KCab-c      KCab              0.0       6
        # 1       542634818    DM1_lPN_R  DM1_lPN    331999156        KCab-c      KCab              3.0       1
        # 2       542634818    DM1_lPN_R  DM1_lPN    332344592        KCab-c      KCab             -1.0       2
        # 3       542634818    DM1_lPN_R  DM1_lPN    332344908        KCab-m      KCab              2.0       9
        # 4       542634818    DM1_lPN_R  DM1_lPN    332353106        KCab-m      KCab             -1.0       1
        # ...           ...          ...      ...          ...           ...       ...              ...     ...
        # 17308  5901222910    DM2_lPN_R  DM2_lPN   5813109913        KCab-s      KCab             -1.0       3
        # 17309  5901222910    DM2_lPN_R  DM2_lPN   5813110928        KCab-s      KCab             -1.0       2
        # 17310  5901222910    DM2_lPN_R  DM2_lPN   5813110928        KCab-s      KCab              0.0       8
        # 17311  5901222910    DM2_lPN_R  DM2_lPN   5901207528        KCab-c      KCab              0.0      34
        # 17312  5901222910    DM2_lPN_R  DM2_lPN   5901225361         KCg-m       KCg              4.0       2
        #
        # [17313 rows x 8 columns]
        # ipdb> claws.dtypes
        # bodyId_pre           int64
        # instance_pre        object

        # type_pre            object
        # bodyId_post          int64
        # instance_post       object
        # type_post           object
        # anatomical_claw    float64
        # weight               int64
        #
        claws = pd.read_parquet(
            prat_hemibrain_PNKC_claw_dir / f'{prefix}Claws.parquet'
        )


        # TODO pick one (also including potentially one of above)? or provide a way
        # to configure which one to use (prob default to pre-scaled, but maybe check i
        # can recompute it) (will be computing from syns, but may check against some of
        # other things)
        for suffix in ('UnScaled', 'SynDist-Scaled'):
            d1 = pd.read_csv(prat_hemibrain_PNKC_claw_dir / f'{prefix}{suffix}.csv')
            d2 = pd.read_parquet(
                prat_hemibrain_PNKC_claw_dir / f'{prefix}{suffix}.parquet'
            )
            # would use pd_allclose but it has error now w/ dtype('O') input
            # (see comment in hong2p, if i haven't fixed it yet)
            assert d1.columns.equals(d2.columns)
            assert d1.index.equals(d2.index)
            assert d1.dtypes.equals(d2.dtypes)
            for c in d1.columns:
                if d1.dtypes[c] == np.dtype('O'):
                    assert not d1[c].isna().any()
                    assert not d2[c].isna().any()
                    assert d1[c].equals(d2[c])

                else:
                    # all but scaled_weight (at least in UnScaled case) are also exactly
                    # equal.
                    # TODO why does suffix=unscaled one have a scaled weight col?
                    # TODO what do NaN scaled weights in suffix=scaled case mean?
                    assert pd_allclose(d1[c], d2[c], equal_nan=True)

            if suffix == 'UnScaled':
                unscaled = d1
            else:
                assert suffix == 'SynDist-Scaled'
                scaled = d1

            # TODO delete
            print(f'{suffix=}')
            print(f'{d1.columns=}')
            #breakpoint()
            print()
            #

        # TODO TODO check i can recreate both unscaled and scaled values
        # TODO TODO TODO then average scaled weights within each claw (will need to do
        # myself)
        # TODO TODO + check prat thinks how i'm normalizing weights (w/in diff units;
        # KCs/claws/etc) makes sense

        # TODO TODO assert set of IDs are same as in my previous hemibrain stuff, or
        # summarize differences?

        # TODO TODO TODO finish integrating prat's new outputs, w/ options to load them
        # instead
        #breakpoint()
        #

        # this is only for non-spatial code thatbexpects unique PN-KC rows
        if synapse_con_path is None and synapse_loc_path is None:

            # TODO also get working in _use_matt_wPNKC case?
            assert len(df[[pn_id_col, kc_id_col]].drop_duplicates()) == len(df)

            # askprat: so does this mean prat has already excluded multiglomeruli PNs
            # (intentionally or not), or are they all contained w/in stuff dropped
            # above?
            #
            # Prat: doesn't think it's likely any of his queries would have missed MG
            # PNs (and as other comments say 'M' in PN type str probably means
            # multiglomerular, or at least includes them)
            #
            # seems True for both hemibrain and fafb (at least as long as we are
            # dropping stuff w/ multiple '_' or '+' in PN types above...)
            assert (
                len(df[[pn_id_col, glomerulus_col]].drop_duplicates()) ==
                df[pn_id_col].nunique()
            )
            assert not df[kc_id_col].isna().any()
            n_kcs = df[kc_id_col].nunique()

            # TODO also get working in _use_matt_wPNKC case?
            assert len(df[[pn_id_col, kc_id_col]].drop_duplicates()) == len(df)
        else:
            pass
            # TODO fix? (/delete) (why was adding pre_claw not enough?)
            #assert (
            #    len(df[[pn_id_col, kc_id_col, 'pre_claw']].drop_duplicates()) == len(df)
            #)

        assert not df[weight_col].isna().any()
        min_weight = df[weight_col].min()
        assert min_weight > 0
        # TODO delete
        # was true b/c Prat's query in hemibrain case, and b/c subsetting above in
        # fafb cases
        #assert min_weight == 4

        to_rename = df.glomerulus.isin(glomerulus_renames)
        if to_rename.any():
            old_names = df.glomerulus[to_rename]
            warn(f'{connectome=} renaming glomeruli as {glomerulus_renames}:\n' +
                old_names.value_counts().to_string() + '\n'
            )

        glom_set = set(df.glomerulus)

        # skip requiring the old names here, since we might have filtered them out.
        # missing_old_names = set(glomerulus_renames.keys()) - glom_set
        # assert len(missing_old_names) == 0
        # TODO print which if this assertion ever fails

        # TODO actually check it doesn't matter whether i do this before vs after pivot?
        # (or at least, that i intend for current behavior)
        df.glomerulus = df.glomerulus.replace(glomerulus_renames)

        if not (synapse_loc_path is not None and synapse_con_path is not None):
            if weight_divisor is None:
                # TODO refactor pivoting to share across branches of this conditional,
                # and with above processing of matt's CSVs
                wPNKC = pd.pivot_table(df, values=weight_col, index=kc_id_col,
                    columns=glomerulus_col, aggfunc='count').fillna(0).astype(int)

                # TODO delete? (/ move to unit test)
                df_bin = df.copy()
                assert (df[weight_col] > 0).all()
                df_bin[weight_col] = (df_bin[weight_col] > 0).astype(int)
                assert (df_bin[weight_col] == 1).all()
                wb = pd.pivot_table(df_bin, values=weight_col, index=kc_id_col,
                    columns=glomerulus_col, aggfunc='sum').fillna(0).astype(int)
                assert wb.equals(wPNKC)
                del df_bin, wb
                #
            else:
                assert weight_divisor > 0

                using_count = pd.pivot_table(df, values=weight_col, index=kc_id_col,
                    columns=glomerulus_col, aggfunc='count').fillna(0).astype(int)

                wdf = df.copy()
                wdf[weight_col] = np.ceil(wdf[weight_col] / weight_divisor)

                wPNKC = pd.pivot_table(wdf, values=weight_col, index=kc_id_col,
                    columns=glomerulus_col, aggfunc='sum').fillna(0).astype(int)
                del wdf

                assert (wPNKC >= using_count).all().all()
                # if weight_divisor is too large, this could fail
                # TODO maybe check it does (i.e. that wPNKC.equals(using_count), for
                # high enough weight_divisor)?
                assert (wPNKC > using_count).any().any()
                del using_count

        # TODO also implement for fafb inputs?
        if KC_TYPE in df.columns:
            # TODO delete?
            kc_ids_and_types = wPNKC.index.to_frame(index=False).merge(
                df[[kc_id_col, KC_TYPE]].drop_duplicates(), left_on=kc_id_col,
                right_on=kc_id_col
            )
            # TODO what is this checking? kinda seems like a merge above isn't getting
            # us anything...
            if synapse_loc_path is None and synapse_con_path is None:
                assert np.array_equal(kc_ids_and_types[kc_id_col], wPNKC.index)

            kc_types = kc_ids_and_types[KC_TYPE]
        #

    # TODO also check it's < ~3000?
    # sanity check
    assert n_kcs > 1000

    if kc_types is not None:
        # row-aligned kc_types (same length/order as current wPNKC rows)
        assert len(kc_types) == len(wPNKC), "kc_types length mismatch"

        if 'compartment' in wPNKC.index.names:
            for_index = wPNKC.index.to_frame(index=False)
            for_index[KC_TYPE] = kc_types
            kc_index = pd.MultiIndex.from_frame(for_index)
        else:
            assert len(wPNKC.index.names) == 1, 'otherwise, also need from_frame here'
            kc_index = pd.MultiIndex.from_arrays([wPNKC.index, kc_types])

        assert kc_index.to_frame(index=False).equals(kc_ids_and_types)
    else:
        kc_index = wPNKC.index.copy()

    if isinstance(kc_index, pd.MultiIndex):
        # .rename seemed to have same effect with dict in 1.5.0, but docs don't seem to
        # mention it, and never seem to mention [MultIndex|Index].rename accepts
        # dict-like as one option
        kc_index = kc_index.set_names({kc_id_col: KC_ID})
    else:
        assert kc_index.name == kc_id_col
        kc_index = kc_index.set_names(KC_ID)

    # (for hemibrain)
    # ipdb> kc_index.get_level_values(KC_TYPE).value_counts(dropna=False)
    # ab      802
    # g       612
    # a'b'    336
    # NaN      80
    wPNKC.index = kc_index

    non_task_gloms = set(wPNKC.columns) - task_gloms
    if len(non_task_gloms) > 0:
        # connectome='hemibrain'|'fafb-right'
        # ['M']
        #
        # connectome='fafb-left'
        # ['M', 'MZ']
        warn(f'dropping glomeruli in {connectome=} but NOT task: '
            f'{sorted(non_task_gloms)}'
        )

    non_connectome_gloms = task_gloms - set(wPNKC.columns)
    if len(non_connectome_gloms) > 0:
        # connectome='hemibrain'|'fafb-left'|'fafb-right'
        # ['VM6l', 'VM6m', 'VM6v', 'VP1l', 'VP3', 'VP5']
        warn(f'glomeruli in Task but NOT {connectome=}: {sorted(non_connectome_gloms)}')

    def _get_kcs_without_input(wPNKC):
        kcs_without_input = (wPNKC == 0).T.all()
        n_kcs_without_input = kcs_without_input.sum()
        return kcs_without_input, n_kcs_without_input

    # these KC ids are already gone from df before pivot-ing into wPNKC
    # (dropped by _add_glom...)
    _, n_without_input_before = _get_kcs_without_input(wPNKC)
    assert n_without_input_before == 0

    # more recent versions of pandas (>1.3.1, certainly by 1.5.0) complain about
    # indexing w/ set, via FutureWarning (hence conversion to list)
    wPNKC = wPNKC[list(task_gloms & set(wPNKC.columns))].copy()
    assert not (wPNKC == 0).all().any(), 'had Task glomeruli providing no input to KCs'

    kcs_without_input, n_kcs_without_input = _get_kcs_without_input(wPNKC)
    if n_kcs_without_input > 0:
        warn(f'{n_kcs_without_input}/{len(wPNKC)} KCs without input, after dropping '
            f'non-Task glomeruli:\n{sorted(kcs_without_input[kcs_without_input].index)}'
        )

    # see comment above in _use_matt_wPNKC=True section, about getting this branch
    # working there too (not sure i care to though)
    if plot_dir is not None and not _use_matt_wPNKC:
        # at least in connectome='hemibrain' & _drop_glom_with_plus=True, wPNKC here has
        # two KCs with no input connections, which are not in reprocessed df.
        # doesn't matter tho.
        df = df[df.glomerulus.isin(wPNKC.columns)]

        fig, ax = _plot_connectome_raw_weight_hist(df[weight_col])
        ax.set_title(f'{connectome} PN->KC weights\n{min_weight=}\n{data_path.name}'
            f'\n{n_kcs=}'
        )
        # bbox_inches='tight' necessary for title to not be cut off
        savefig(fig, plot_dir, f'wPNKC_hist_{connectome}', bbox_inches='tight')

        # temporarily comment out (come back to check later)
        fig, ax = _plot_connectome_raw_weight_hist(df, x=weight_col, hue=KC_TYPE,
            hue_order=kc_type_hue_order
        )
        ax.set_title(f'{connectome} PN->KC weights\n{min_weight=}\n{data_path.name}'
            f'\n{n_kcs=}'
        )
        savefig(fig, plot_dir, f'wPNKC_hist_{connectome}_by-kc-type',
            bbox_inches='tight'
        )

        # NOTE: mean of this w/ connectome='hemibrain' is 5.44 (NOT n_claws=7 used
        # by uniform)
        n_inputs_per_kc = wPNKC.T.sum()
        # Reset the index, ensuring to fill NaNs in the kc_type level
        df_to_plot = n_inputs_per_kc.reset_index(name='n_claws')

        # Now, use .fillna() on the 'kc_type' column to replace any NaNs
        df_to_plot[KC_TYPE].fillna('unknown', inplace=True)

        # relevant for picking appropriate n_claws for uniform/hemidraw cases, or for
        # picking weight_divisor that produces closest avg to the n_claws=7 we had
        # already been using
        avg_n_inputs_per_kc = df_to_plot.mean()

        # so that the value column has a name after reset_index()
        df_to_plot.name = 'n_claws'
        # TODO label y-axis for two below (and *differently* for those above)?

        fig, ax = plt.subplots()
        sns.histplot(n_inputs_per_kc, discrete=True, ax=ax)
        ax.set_xlabel('# "claws" per KC\n(after processing connectome weights)')

        ax.set_title(f'total inputs per KC\n{connectome=}\n{weight_divisor=}\n{n_kcs=}'
             f'\nmean inputs per KC: {avg_n_inputs_per_kc.iloc[1]:.2f}'
        )
        # TODO why these look so different for fafb inputs (vs hemibrain)? for similar
        # avg_n_inputs_per_kc (adjusting fafb weight_divisor to roughly match the value
        # for hemibrain w/ weight_divisor=20), we get much more of the right lobe in the
        # fafb plots. are there less (PN, KC) pairs for some reason (what should be the
        # only lobe w/ weight_divisor=None, or the left lobe in others)?
        savefig(fig, plot_dir, f'wPNKC_nclaws-sum-per-KC_hist_{connectome}',
            bbox_inches='tight'
        )

        # TODO refactor to share w/ above?
        fig, ax = plt.subplots()
        sns.histplot(data=df_to_plot, discrete=True, ax=ax, x='n_claws',
            hue=KC_TYPE, hue_order=kc_type_hue_order
        )
        ax.set_xlabel('# "claws" per KC\n(after processing connectome weights)')
        ax.set_title(f'total inputs per KC\n{connectome=}\n{weight_divisor=}\n{n_kcs=}'
            f'\nmean inputs per KC: {avg_n_inputs_per_kc.iloc[1]:.2f}'
        )
        savefig(fig, plot_dir, f'wPNKC_nclaws-sum-per-KC_hist_{connectome}_by-kc-type',
            bbox_inches='tight'
        )

        #
        # TODO also plot sums within glomeruli?

        # TODO also plot (hierarchichally clustered) wPNKC (w/ plot+colorscale as in
        # natmix_data/analysis.py?)?

    assert len(wPNKC) == n_kcs

    # TODO see if i can also sort output in uniform case (b/c if not, might suggest
    # there is other order-of-glomeruli dependence in fit_mb_model THAT THERE SHOULD NOT
    # BE)
    # TODO (still true? test described actually relevant? delete?) i can not seem to
    # recreate uniform output (by sorting wPNKC post-hoc), but i'm not sure that's
    # actually a problem. maybe input *should* always just be in a particular order, and
    # shouldn't necessarily matter that it's this one...
    wPNKC = wPNKC.sort_index(axis='columns')

    # TODO option to also return a version of (long-form) df, so i can use for a test
    # comparing old + new hemibrain version, as i'm currently doing w/ sloppy code
    # above?
    return wPNKC


# TODO TODO TODO make sure this is only loading connections from calyx (might be
# already? i assume lobe[/other? are there other?] connections not relevant for calyx /
# soma activity?
def connectome_APL_weights(connectome: str = 'hemibrain', *,
    wPNKC: Optional[pd.DataFrame] = None, kc_types: Optional[pd.Series] = None,
    kc_to_claws: Optional[List[List[int]]] = None,
    plot_dir: Optional[Path] = None) -> Tuple[pd.Series, pd.Series]:
    # TODO add param to support imputing something non-zero (min_weight?) for KC IDs in
    # wPNKC but not APL-KC data
    # TODO actually want to support weight_divisor (prob not, especially if i'm
    # scaling everything anyway? and prob wouldn't same to be same as for PN->KC data
    # anyway...)?
    # TODO param for min_weight? maybe add smilar one for connectome_wPNKC, and share
    # min_weight value across these two fns? (even if doesn't make sense to share
    # weight_divisor)?
    # TODO why do i need both wPNKC and kc_types? just always pass index (which may
    # or may not include kc_types, but don't otherwise pass wPNKC?)
    """Returns wAPLKC, wKCAPL (each a `Series` with KC IDs in index, and weight values)

    Args:
        connectome: same as for `connectome_wPNKC`

        wPNKC: dataframe of shape (# KCs, # glomeruli), with index being KC body IDs
            from same connectome as requested. If passed, KCs with IDs not in this index
            will be dropped from output, and KC IDs in `wPNKC.index` but not in APL-KC
            data will have weight set to 0.

        plot_dir: same as for `connectome_wPNKC`
    """
    assert connectome in connectome_options

    if connectome != 'hemibrain':
        raise NotImplementedError('currently only have data for APL-KC connections'
            " for connectome='hemibrain'"
        )

    apl_data_dir = from_prat / '2025-04-03'

    apl2kc_csv = apl_data_dir / 'APL2KC_Connectivity.csv'
    # columns: bodyId_pre, type_pre, instance_pre, bodyId_post, type_post,
    # instance_post, roi, weight
    apl2kc_df = pd.read_csv(apl2kc_csv)
    # ipdb> apl2kc_df.instance_pre.unique()
    # array(['APL_R', 'APL fragment?', 'APL or DPM', 'APL fragment_L'],

    # unique roi values before filtering:
    # [gL(R), CA(R), b'L(R), a'L(R), aL(R), bL(R), PED(R), SLP(R), PLP(R), SCL(R),
    # b'L(L), NotPrimary, ICL(R), SIP(R), CRE(R)]
    assert {'CA(R)'} == set(
        apl2kc_df.roi[apl2kc_df.roi.str.contains('CA')].unique()
    )
    # TODO TODO TODO what fraction of rows are 'CA(R)'? what are other big components,
    # if any? (and same for kc2apl. put in comment if don't already have)
    apl2kc_df = apl2kc_df[apl2kc_df.roi == 'CA(R)'].copy()

    # filtering pratyush recommended. he doesn't think the other fragments (which
    # may or may not have been from the right APL as well, but may also have been
    # DPM, left APL, or something else) represent much of the data, or are worth
    # using.
    # TODO actually see what fraction of calyx connections are excluded by this
    # filtering?
    apl2kc_df = apl2kc_df[apl2kc_df.instance_pre == 'APL_R'].copy()

    # TODO why are there NaN in type post (how many? 80/1951 rows) (seems they are
    # all for uncertain / fragment KCs)? just drop those i assume?
    #
    # ipdb> apl2kc_df[apl2kc_df.type_post.isna()].instance_post.unique()
    # array(['KCy(half)', 'KC part due to gap', 'KC(incomplete?)'], dtype=object)
    #
    # ipdb> apl2kc_df[~ apl2kc_df.type_post.isna()].instance_post.unique()
    # array(['KCg-m_R', 'KCg-t_R', 'KCg-d_R', 'KCab-m_R', 'KCab-c_R',
    #        "KCa'b'-m_R", "KCa'b'-ap2_R", 'KCg-s3_R', 'KCab-s_R',
    #        'KCg-s2(super)_R', 'KCab-p_R', "KCa'b'-ap1_R", 'KCg-s4_R'],
    #       dtype=object)
    apl2kc_df = apl2kc_df[apl2kc_df.type_post.notna()].copy()
    assert not apl2kc_df.isna().any().any()

    apl2kc_df = add_kc_type_col(apl2kc_df, 'instance_post')
    assert not apl2kc_df[KC_TYPE].isna().any()
    # I guess inputs are missing what I would need to independently define type for
    # these (or that this is the reality / this data is not available)
    assert not (apl2kc_df[KC_TYPE] == 'unknown').any()

    # ipdb> apl2kc_df.weight.value_counts().sort_index()
    # 1      60
    # 2      49
    # 3      42
    # 4      42
    # 5      53
    # 6      93
    # 7     104
    # 8     116
    # 9     124
    # 10    144
    # 11    112
    # 12    103
    # 13     64
    # 14     74
    # 15     50
    # 16     43
    # 17     35
    # 18     40
    # 19     35
    # 20     39
    # 21     56
    # 22     54
    # 23     53
    # 24     48
    # 25     34
    # 26     45
    # 27     40
    # 28     39
    # 29     26
    # 30      9
    # 31     11
    # 32     11
    # 33      9
    # 34      4
    # 35      5
    # 36      1
    # 37      2
    # 38      2

    kc2apl_csv = apl_data_dir / 'KC2APL_Connectivity.csv'
    # columns same as above
    kc2apl_df = pd.read_csv(kc2apl_csv)

    # TODO refactor to share most filtering w/ above (almost exactly the same)
    assert {'CA(R)'} == set(
        kc2apl_df.roi[kc2apl_df.roi.str.contains('CA')].unique()
    )
    kc2apl_df = kc2apl_df[kc2apl_df.roi == 'CA(R)'].copy()

    # NOTE: using instance_post here instead of instance_pre above
    kc2apl_df = kc2apl_df[kc2apl_df.instance_post == 'APL_R'].copy()
    # NOTE: seems like only 79 NaN here, despite seemingly 80 at this point in
    # filtering for apl2kc_df above. almost certainly doesn't matter.
    # NOTE: using type_pre, instead of type_post for apl2kc_df above
    kc2apl_df = kc2apl_df[kc2apl_df.type_pre.notna()].copy()
    assert not kc2apl_df.isna().any().any()

    kc2apl_df = add_kc_type_col(kc2apl_df, 'instance_pre')
    assert not kc2apl_df[KC_TYPE].isna().any()
    # I guess inputs are missing what I would need to independently define type for
    # these (or that this is the reality / this data is not available)
    assert not (kc2apl_df[KC_TYPE] == 'unknown').any()

    # ipdb> kc2apl_df.weight.value_counts().sort_index()
    # 1      65
    # 2      69
    # 3      87
    # 4     104
    # 5     116
    # 6     131
    # 7     105
    # 8      98
    # 9      70
    # 10    101
    # 11     84
    # 12    104
    # 13    112
    # 14    127
    # 15    132
    # 16    110
    # 17     75
    # 18     64
    # 19     38
    # 20     23
    # 21      9
    # 22      7
    # 23      2
    # 24      3
    # 26      1
    # 27      1
    # Name: weight, dtype: int64

    # KC IDs in each of these sets
    apl2kc_ids = set(apl2kc_df.bodyId_post)
    kc2apl_ids = set(kc2apl_df.bodyId_pre)

    if plot_dir is not None:
        min_weight = apl2kc_df['weight'].min()
        assert min_weight > 0
        fig, ax = _plot_connectome_raw_weight_hist(apl2kc_df['weight'])
        ax.set_title(f'{connectome} APL->KC weights\n{min_weight=}\n{apl2kc_csv.name}\n'
            f'n_kcs={len(apl2kc_ids)}'
        )
        savefig(fig, plot_dir, f'wAPLKC_hist_{connectome}', bbox_inches='tight')

        min_weight = kc2apl_df['weight'].min()
        assert min_weight > 0
        fig, ax = _plot_connectome_raw_weight_hist(kc2apl_df['weight'])
        ax.set_title(f'{connectome} KC->APL weights\n{min_weight=}\n{kc2apl_csv.name}\n'
            f'n_kcs={len(kc2apl_ids)}'
        )
        savefig(fig, plot_dir, f'wKCAPL_hist_{connectome}', bbox_inches='tight')

    # TODO test/delete (`wPNKC is None` currently unused)
    if wPNKC is None:
        # TODO assert not kc_to_claws here? or add/check/test support for that case?

        # TODO test filling below works w/ this branch. expecting to mainly use branch
        # below (where wPNKC is passed in)
        index = pd.Index((apl2kc_ids | kc2apl_ids), name=KC_ID)
    #
    else:
        index = wPNKC.index.copy()
        pn2kc_ids = set(index.get_level_values(KC_ID))
        # ipdb> len(pn2kc_ids)
        # 1837
        # ipdb> len(apl2kc_ids)
        # 1871
        # ipdb> len(kc2apl_ids)
        # 1838
        #
        # ipdb> len(apl2kc_ids | kc2apl_ids)
        # 1887
        # ipdb> len((apl2kc_ids | kc2apl_ids) & pn2kc_ids)
        # 1749
        # ipdb> len((apl2kc_ids | kc2apl_ids) - pn2kc_ids)
        # 138
        #
        # ipdb> len(apl2kc_ids - pn2kc_ids)
        # 117
        # ipdb> len(pn2kc_ids - apl2kc_ids)
        # 83
        #
        # ipdb> len(kc2apl_ids - pn2kc_ids)
        # 94
        # ipdb> len(pn2kc_ids - kc2apl_ids)
        # 93

        # NOTE: if any KC IDs are "dropped" below, it will be because they are not in
        # index, which is used below to define wAPLKC/wKCAPL indices

        n_kcs_dropped_apl2kc = len(apl2kc_ids - pn2kc_ids)
        if n_kcs_dropped_apl2kc > 0:
            warn(f'{connectome=} dropping {n_kcs_dropped_apl2kc}/{len(apl2kc_ids)} '
                'KCs in APL->KC data, but not in wPNKC'
            )

        n_kcs_dropped_kc2apl = len(kc2apl_ids - pn2kc_ids)
        if n_kcs_dropped_kc2apl > 0:
            warn(f'{connectome=} dropping {n_kcs_dropped_kc2apl}/{len(kc2apl_ids)} '
                'KCs in KC->APL data, but not in wPNKC'
            )

    assert not apl2kc_df.bodyId_post.duplicated().any()
    apl2kc_weights = apl2kc_df[['bodyId_post','weight']].set_index('bodyId_post'
        ).squeeze()

    assert not kc2apl_df.bodyId_pre.duplicated().any()
    kc2apl_weights = kc2apl_df[['bodyId_pre','weight']].set_index('bodyId_pre'
        ).squeeze()

    if kc_to_claws is not None:
        wAPLKC = pd.Series(index=index, dtype=float)
        wKCAPL = pd.Series(index=index, dtype=float)

        # TODO TODO use pandas vectorized filling instead of looping overr all kc_id
        # values. replace this loop w/ more idiomatic code.
        # Iterate through each KC to distribute the weights to its claws
        for kc_id in index.get_level_values(KC_ID).unique():

            # Get the original weights for the current KC
            apl_weight = apl2kc_weights.get(kc_id, 0)
            kca_weight = kc2apl_weights.get(kc_id, 0)

            # Get the sub-index for all claws belonging to this KC
            kc_claws_index = wPNKC.loc[kc_id].index

            if len(kc_claws_index) > 0:
                num_claws = len(kc_claws_index)
                distributed_apl_weight = apl_weight / num_claws
                distributed_kca_weight = kca_weight / num_claws

                # Assign the distributed weight to the appropriate rows in the Series
                wAPLKC.loc[kc_id] = distributed_apl_weight
                wKCAPL.loc[kc_id] = distributed_kca_weight

        # TODO is this not duplicated below now? refactor to share?
        # Fill any remaining NaNs (for KCs with no claws in the data)
        wAPLKC = wAPLKC.fillna(0)
        wKCAPL = wKCAPL.fillna(0)

        n_kcs = len(index.get_level_values(KC_ID).unique())

        assert wAPLKC.sum() > 0
        assert (wAPLKC >= 0).all()
        # TODO TODO TODO this actually make sense?
        wAPLKC = wAPLKC * (n_kcs / wAPLKC.sum())
        # TODO TODO is this actually a property we want to enforce tho?
        assert np.isclose(wAPLKC.sum() / n_kcs, 1)

        assert wKCAPL.sum() > 0
        assert (wKCAPL >= 0).all()
        # TODO TODO TODO this actually make sense?
        wKCAPL = wKCAPL * (n_kcs / wKCAPL.sum())
        # TODO TODO is this actually a property we want to enforce tho?
        assert np.isclose(wKCAPL.sum() / n_kcs, 1)
    else:
        wAPLKC = pd.Series(index=index, data=apl2kc_weights)
        wKCAPL = pd.Series(index=index, data=kc2apl_weights)

    wAPLKC.name = 'weight'
    wKCAPL.name = 'weight'

    # TODO would it be better to impute some non-zero min value, so those cells activity
    # could still be scaled (add param for that?)?
    fill_weight = 0

    n_filled_apl2kc = wAPLKC.isna().sum()
    if n_filled_apl2kc > 0:
        warn(f'{connectome=} filling weight (={fill_weight}) for {n_filled_apl2kc}'
            f'/{len(index)} KCs in wPNKC (or in wKCAPL) but not in APL->KC data'
        )
        wAPLKC = wAPLKC.fillna(fill_weight)

    n_filled_kc2apl = wKCAPL.isna().sum()
    if n_filled_kc2apl > 0:
        warn(f'{connectome=} filling weight (={fill_weight}) for {n_filled_kc2apl}'
            f'/{len(index)} KCs in wPNKC (or in wAPLKC) but not in KC->APL data'
        )
        wKCAPL = wKCAPL.fillna(fill_weight)

    assert not wAPLKC.isna().any()
    assert not wKCAPL.isna().any()

    # TODO TODO test in both old and new code paths
    # TODO delete? seems to have only been in tianpei's code, at least as of my initial
    # merging in of his code
    # TODO need to drop levels in some cases?
    assert wAPLKC.index.equals(index)
    assert wKCAPL.index.equals(index)
    #

    if kc_types is not None:
        # explore whether subtypes have diff weights in either (esp a'/b' vs others),
        # along lines of inada/kazama paper (they don't, but can i force them to, so
        # that effect is similar? presumably?). anything else to look at?

        # index should be same as wAPLKC and wKCAPL indices
        assert len(kc_types) == len(index)

        # is it consistent w/ expectation that a/b (802) are more numerous than gamma
        # (612)? (betty thought they counts across all 3 seemed reasonable)
        type2count = kc_types.value_counts()
        old_type_index = type2count.index.copy()
        type2count.index = type2count.index + ' (' + type2count.astype(str).values + ')'

        # converting to Series since Index doesn't have a .replace method
        kc_types = pd.Series(kc_types)

        type2type_with_count = dict(zip(old_type_index, type2count.index))
        kc_types = kc_types.replace(type2type_with_count)

        # do need this for some reason, or else adding kc_type col to
        # w[APLKC|KCAPL]_with_types will only add an all-NaN kc_type column
        kc_types = pd.Index(kc_types)

        wAPLKC_with_types = wAPLKC.to_frame()
        wKCAPL_with_types = wKCAPL.to_frame()

        # TODO delete? can i avoid need for this by fixing some code duplication
        # earlier? still need to pass in kc_types now? just use something based on
        # existing KC_TYPE level we seem to have here in index now?
        if KC_TYPE in wAPLKC_with_types.index.names:
            assert KC_TYPE in wKCAPL_with_types.index.names
            # TODO assert values in index level are all same as prefix
            # (stripping ' (<n>' suffixes) in kc_types values we are about to assign in?

            # NOTE: not changing wAPLKC/wKCAPL that get returned
            wAPLKC_with_types = wAPLKC_with_types.droplevel(KC_TYPE)
            wKCAPL_with_types = wKCAPL_with_types.droplevel(KC_TYPE)
        #

        wAPLKC_with_types[KC_TYPE] = kc_types
        wKCAPL_with_types[KC_TYPE] = kc_types

        wAPLKC_max_weight_by_type = wAPLKC_with_types.groupby(KC_TYPE).weight.max()
        wKCAPL_max_weight_by_type = wKCAPL_with_types.groupby(KC_TYPE).weight.max()

        # TODO prob delete
        # TODO TODO at least would need to actually check unknown type here, rather
        # than just checking if any type has 0 weight
        wAPLKC_0weight_types = wAPLKC_max_weight_by_type == 0
        wAPLKC_unknown_type_has_0weight  = False
        if wAPLKC_0weight_types.any():
            assert len(wAPLKC_max_weight_by_type.index[wAPLKC_0weight_types]) == 1
            assert wAPLKC_max_weight_by_type.index[wAPLKC_0weight_types].str.startswith(
                'unknown (').all()
            wAPLKC_unknown_type_has_0weight = True

        wKCAPL_0weight_types = wKCAPL_max_weight_by_type == 0
        wKCAPL_unknown_type_has_0weight  = False
        if wKCAPL_0weight_types.any():
            assert len(wKCAPL_max_weight_by_type.index[wKCAPL_0weight_types]) == 1
            assert wKCAPL_max_weight_by_type.index[wKCAPL_0weight_types].str.startswith(
                'unknown (').all()
            wKCAPL_unknown_type_has_0weight = True

        n_unknown_type = None
        if wAPLKC_unknown_type_has_0weight and wKCAPL_unknown_type_has_0weight:
            wAPLKC_unknown_type = wAPLKC_with_types[KC_TYPE].str.startswith('unknown (')
            wAPLKC_with_types = wAPLKC_with_types[~wAPLKC_unknown_type]

            wKCAPL_unknown_type = wKCAPL_with_types[KC_TYPE].str.startswith('unknown (')
            wKCAPL_with_types = wKCAPL_with_types[~wKCAPL_unknown_type]

            n_unknown_type = wAPLKC_unknown_type.sum()
            assert n_unknown_type == wKCAPL_unknown_type.sum()
        #

        # TODO TODO TODO don't do this. allow missing 'unknown' type altogether
        # TODO TODO but maybe still assert no NaN type?
        else:
            assert False
        #

        if plot_dir is not None:
            # otherwise type='unknown' will show up in legend, without a correponding
            # histogram element (b/c no rows have that type here, and they should also
            # all be of weight 0 anyway, unless there was a bug w/ how I was getting the
            # types from wPNKC...), which is confusing
            hue_order = [
                type2type_with_count[x] for x in kc_type_hue_order if x != 'unknown'
            ]

            fig, ax = _plot_connectome_raw_weight_hist(wAPLKC_with_types, x='weight',
                hue=KC_TYPE, hue_order=hue_order
            )
            ax.set_title(f'{connectome} APL->KC weights\nn_kcs={len(wAPLKC)}'
                # TODO delete this part of title (or at least make conditional)
                f'\n{n_unknown_type} KCs with unknown type (all with 0 APL->KC weight)'
            )
            savefig(fig, plot_dir, f'wAPLKC_hist_{connectome}_by-kc-type',
                bbox_inches='tight'
            )

            fig, ax = _plot_connectome_raw_weight_hist(wKCAPL_with_types, x='weight',
                hue=KC_TYPE, hue_order=hue_order
            )
            ax.set_title(f'{connectome} KC->APL weights\nn_kcs={len(wKCAPL)}'
                f'\n{n_unknown_type} KCs with unknown type (all with 0 KC->APL weight)'
            )
            savefig(fig, plot_dir, f'wKCAPL_hist_{connectome}_by-kc-type',
                bbox_inches='tight'
            )

    # TODO TODO fill in unknown KC type (NaN here) w/ mean weight of other type? or
    # drop? (and prob do one by default) (at least its' just 80/1830 cells)

    return wAPLKC, wKCAPL


# TODO doc expected input format (i.e. what are rows / cols)
def drop_silent_model_cells(responses: pd.DataFrame) -> pd.DataFrame:
    # .any() checks for any non-zero, so should also work for spike counts
    # (or 1.0/0.0, instead of True/False)
    nonsilent_cells = responses.T.any()

    # TODO maybe restore as warning, or behind a checks flag or something.
    # (now that i should be using KC_ID='kc_id' everywhere, rather than a mix of
    # 'model_kc' and 'bodyid'/similar connectome stuff, might be more realistic)
    #
    # (also works if index.name == KC_ID)
    # (commented cause was failing b/c index name was diff in natmix_data/analysis.py
    # script, though i could have changed that...)
    #assert KC_ID in nonsilent_cells.index.names

    return responses.loc[nonsilent_cells].copy()


def _get_silent_cell_suffix(responses_including_silent, responses_without_silent=None
    ) -> str:
    if responses_without_silent is None:
        responses_without_silent = drop_silent_model_cells(responses_including_silent)

    assert responses_without_silent.shape[1] == responses_including_silent.shape[1]
    n_total_cells = len(responses_including_silent)
    n_silent_cells = n_total_cells - len(responses_without_silent)

    # TODO could relax to assert >=, if ever fails
    # (same as asserting len(responses_without_silent) > 0)
    assert n_total_cells > n_silent_cells

    # titles these will be appended to should already end w/ '\n'
    title_suffix = f'(dropped {n_silent_cells}/{n_total_cells} silent cells)'
    # TODO also return n_[total|silent]_cells? only if useful in some existing calling
    # code
    return title_suffix


# TODO move to hong2p.util?
def _single_unique_val(arr: Union[np.ndarray, pd.Series], *, exact: bool = True
    ) -> float:
    """Returns single unique value from array.

    Raises AssertionError if array has more than one unique value (including NaNs).
    """
    unique_vals = set(np.unique(arr))
    if exact:
        assert len(unique_vals) == 1
        return unique_vals.pop()
    else:
        # TODO support NaN in this branch? (prob not...)
        v0 = unique_vals.pop()
        for v in unique_vals:
            assert np.isclose(v, v0)

        return v0


def plot_spike_rasters(spks: pd.DataFrame, *, n_PCs: int = 100, n_clusters: int = 5,
    ax: Optional[Axes] = None, verbose: bool = False, **kwargs) -> Optional[Figure]:
    # TODO also silence warnings about not finding enough clusters, at least when
    # verbose=False?
    """
    Args:
        spks: of shape (#-neurons, #-timepoints), with values all 0 or 1

        **kwargs: passed to `Rastermap(...)` initialization (not the `Rastermap.fit`
            call)
    """
    xlim = None

    time_index = spks.columns
    if time_index.dtype == float:
        assert time_index.is_monotonic_increasing
        assert not time_index.isna().any()
        xlim = (time_index.min(), time_index.max())

    # ipdb> spks.shape
    # (1830, 5500)
    # ipdb> set(spks.flat)
    # {0.0, 1.0}
    # rastermap call below gets unhappy if we omit .values (leaving spks a DataFrame)
    spks = spks.values.astype('float32')
    # TODO maybe try converting to spike times in seconds, and using
    # `rastermap.io.load_spike_times(<spike-time-npy>, <spike-cluster-npy>,
    # st_bin=100)` (or whatever it does)?
    # TODO TODO or just try re-binning my spike time matrix into one with a bin of
    # 100ms (from st_bin above)? do we ever have two spikes within one of those
    # bins? how does rastermap fn handle that? add? is output binary or not?
    assert not np.isnan(spks).any()

    # getting responders only. leaves 214 of the initial 1830 cells.
    # seems to help avoid some rastermap errors.
    spks = spks[(spks == 1).any(axis=1)]
    if len(spks) == 0:
        raise ValueError('no responders in input!')

    # TODO does time lag actually matter? not clearly better w/ it set vs default, when
    # using n_clusters=5, n_PCs=100 (and locality default/0, which i think are same)
    # TODO how does this compare to version w/ locality + time_lag_window set above?
    # (should be pretty much the same) prefer either? try diff (lower?)
    # n_PCs/n_clusters?
    #
    # remy came up with this calculation. not immediately clear to me (from rastermap
    # docs) that this is the appropriate value.
    # dt=0.0005 is from the olfsysm time_dt setting.
    #dt = 0.0005
    #time_lag_window_seconds = 0.1
    #time_lag_window = int(time_lag_window_seconds / dt)

    # TODO try smoothing parameters / diff binning?
    #
    # works after dropping non-responders (see scripts/test_rastermap.py for some
    # discussion on choice of parameters, including kwarg defaults in plot_spike_rasters
    # def)
    try:
        # TODO need to seed this? can i?
        model = Rastermap(n_PCs=n_PCs, n_clusters=n_clusters, verbose=verbose, **kwargs
            ).fit(spks)

    # TODO fix (just find new n_PCs / n_cluster?). getting again in hemibrain test.
    # may or may not be related to upgrading rastermap to 1.0 we did recently.
    # having trouble reproducing now though... not deterministic?
    #
    # before dropping non-responders and also changing some other rastermap config
    # (decrease n_PCs and n_clusters, tho maybe both not needed?) was getting this
    # error:
    #   File "./mb_model.py", line 3296, in fit_mb_model
    #     model = Rastermap(n_PCs=200, n_clusters=100, locality=0.75,
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/rastermap/rastermap.py", line 327, in fit
    #     Usv_valid = SVD(X[igood][:, itrain] if itrain is not None else X[igood],
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/rastermap/svd.py", line 33, in SVD
    #     U = TruncatedSVD(n_components=nmin,
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    #     data_to_wrap = f(self, X, *args, **kwargs)
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/sklearn/base.py", line 1151, in wrapper
    #     return fit_method(estimator, *args, **kwargs)
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/sklearn/decomposition/_truncated_svd.py", line 246, in fit_transform
    #     U, Sigma, VT = randomized_svd(
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 450, in randomized_svd
    #     Q = randomized_range_finder(
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 279, in randomized_range_finder
    #     Q, _ = linalg.lu(safe_sparse_dot(A.T, Q), permute_l=True)
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/scipy/linalg/_decomp_lu.py", line 213, in lu
    #     a1 = asarray_chkfinite(a)
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    #     raise ValueError(
    # ValueError: array must not contain infs or NaNs
    except ValueError as err:
        msg = str(err)
        if msg != 'array must not contain infs or NaNs':
            raise

        warn(f'Rastermap() failed with: ValueError: {msg}\n'
            '...try decreasing n_PCs or n_clusters?'
        )
        return None

    # TODO fix! under what circumstances is this triggered? how to fix? input just empty
    # or something trivial?
    except np.linalg.LinAlgError as err:
        # TODO warn with more error context
        warn(str(err))
        #
        return None

    y = model.embedding # neurons x 1
    isort = model.isort

    # visualize binning over neurons
    X_embedding = model.X_embedding

    if ax is None:
        fig = plt.figure(figsize=(12,5))
        ax = fig.add_subplot(111)
    else:
        # TODO this what i want? just don't return anything (either in general, or in
        # this case)? just getting this so i can consistently return the relevant Figure
        # object [whether we created it or not]
        fig = ax.figure

    extent = None
    if xlim is not None:
        # TODO need to swap top and bottom? (seems fine as is)
        top = len(spks) + 0.5
        bottom = -0.5

        # TODO what to add/subtract, (if anything and) if not -0.5 (half of dt?)?
        left, right = xlim

        # https://matplotlib.org/stable/users/explain/artists/imshow_extent.html
        # exent: (left, right, bottom, top)
        # TODO use a colormap w/o white=0 to test this?
        extent = (left, right, bottom, top)

    # TODO why vmax=1.5? are values not 0/1?
    ax.imshow(X_embedding, vmin=0, vmax=1.5, cmap='gray_r', aspect='auto',
        extent=extent
    )

    return fig


# TODO delete all these? or re-organize? want to minimize how much mb_model stuff
# assumes a certain output folder structure
#
# TODO also use for wPNKC(s)? anything else?
data_outputs_root = Path('data')
hallem_csv_root = data_outputs_root / 'preprocessed_hallem'
hallem_delta_csv = hallem_csv_root / 'hallem_orn_deltas.csv'
hallem_sfr_csv = hallem_csv_root / 'hallem_sfr.csv'
#

# TODO delete
#_seen_plot_dirs = set()
#
_seen_olfsysm_logs = set()
# TODO delete Optional in RHS of return Tuple after implementing in other cases
# TODO if orn_deltas is passed, should we assume we should tune on hallem? or assume we
# should tune on that input?
# TODO rename drop_receptors_not_in_hallem -> glomeruli
# TODO some kind of enum instead of str for pn2kc_connections?
# TODO accept sparsities argument (or scalar avg probably?), for target when tuning
# TODO delete _use_matt_wPNKC after resolving differences wrt Prat's? maybe won't be
# possible though, and still want to be able to reproduce matt's stuff...
# TODO doc that sim_odors is Optional[Set[str]]
# TODO actually, probably can delete sim_odors now? why even have it? to tune on a diff
# set than to return responses for?
# TODO check new default for tune_on_hallem didn't break any of my existing calling code
def fit_mb_model(orn_deltas: Optional[pd.DataFrame] = None, sim_odors=None, *,
    tune_on_hallem: bool = False, pn2kc_connections: str = 'hemibrain',
    use_connectome_APL_weights: bool = False, weight_divisor: Optional[float] = None,
    _wPNKC: Optional[pd.DataFrame] = None, _wPNKC_one_row_per_claw: bool = False,
    n_claws: Optional[int] = None, drop_multiglomerular_receptors: bool = True,
    drop_receptors_not_in_hallem: bool = False, seed: int = 12345,
    target_sparsity: Optional[float] = None,
    target_sparsity_factor_pre_APL: Optional[float] = None,
    _use_matt_wPNKC=False, _drop_glom_with_plus=True,
    _add_back_methanoic_acid_mistake=False, equalize_kc_type_sparsity: bool = False,
    ab_prime_response_rate_target: Optional[float] = None,
    homeostatic_thrs: bool = False, claw_sparsity: bool = False,
    fixed_thr: Optional[Union[float, np.ndarray]] = None,
    # TODO TODO TODO support vector on these? or how else? (want to be able to boost
    # them)
    wAPLKC: Optional[float] = None, wKCAPL: Optional[float] = None,
    #
    print_olfsysm_log: Optional[bool] = None, return_dynamics: bool = False,
    plot_dir: Optional[Path] = None, make_plots: bool = True,
    _plot_example_dynamics: bool = False, title: str = '',
    drop_silent_cells_before_analyses: bool = drop_silent_model_kcs,
    repro_preprint_s1d: bool = False, return_olfsysm_vars: bool = False,
    # TODO TODO implement
    # TODO rename 'broadcell_...'? (actually just rename to something generic, then add
    # other kwargs to control what defines the cells to boost)
    # TODO TODO TODO add other options for defining cells to boost APL on. want
    # multiresponders as one option [could keep them defined by mask saved by
    # natmix_data/analysis.py], but also want options for:
    # 1) KCs w/ more community PN input (or more input from some input set of
    #    glomeruli?)
    # 2) KCs w/ more input from periphery
    multiresponder_APL_boost: Optional[float] = None, _multiresponder_mask: Optional[pd.Series] = None,
    boost_wKCAPL: Literal[False, True, 'only'] = False,
) -> Tuple[pd.DataFrame, Optional[pd.DataFrame], Dict[str, Any]]:
    # TODO doc point of sim_odors. do we need to pass them in (not typically, no)?
    # (even when neither tuning nor running on any hallem data?)
    # TODO does matt's code support float wPNKC? can i just directly normalize wPNKC and
    # pass that in, rather than dealing w/ weight_divisor=<float>?
    # TODO TODO have responses [/spike_counts] returned w/ row indices using same
    # connectome cell IDs are wPNKC row index ('bodyid' as called in hemibrain data prat
    # assembled) (or have wPNKC also use same sequential int index)
    # TODO allow passing in wPNKC matrix directly? mainly thinking of using for tests
    # now... would have to override pn2kc_connections (or take as option to that param)
    """
    Args:
        orn_deltas: dataframe of shape (# glomeruli, # odors). values should be in units
            of change in spike deltas (`model_mb_responses` will do this scaling for
            you). Input should only contain one value per (glomerulus, odor) pair, so
            take a mean across flies (if applicable) before passing.

            Odor (column) index should also not have multiple repeats of the same odor.
            Odor strings (in at least one index level) should be in format like:
            '<odor-name-abbreviation> @ <log10-conc>', e.g. 'eb @ -3'.
            Odor index may also have a 'panel' level, to group odors by experiment,
            though output `responses` and `spike_counts` currently do not preserve
            this level [could implement].

            Only glomeruli in intersection of connectome (hemibrain, unless otherwise
            specified) and Task et al 2022 glomeruli will be included in model.
            Additional input glomeruli will be dropped, and any of these glomeruli
            missing from input will have their spike-change-deltas imputed as 0.
            Glomeruli will use SFRs reported in Hallem, when cognate OR is in Hallem
            dataset, or mean Hallem SFR otherwise.

        target_sparsity: target mean response rate (across tuned odors, which is all
            odors by default). By default, model is only tuned until mean response
            rate is within +/- 10% (sp_acc) of target. If passed, `fixed_thr` and
            `wAPLKC` should not be.

        fixed_thr: added to each KCs spontaneous firing rate (SFR) to produce the spike
            threshold. `olfsysm` has options to not add this, but not currently exposed
            by this wrapper. expected that only either this and `wAPLKC` OR
            `target_sparsity` are specified.

        wAPLKC: weight from APL to every KC. `wKCAPL` defined from this, unless both are
            passed. If `use_connectome_APL_weights=True`, used to set
            `rv.kc.wAPLKC_scale` instead (which is multiplied by
            `connectome_APL_weights` output, that has been scaled so its mean is 1).

        wKCAPL: used in same manner of `wAPLKC`. If this is passed, `wAPLKC` must
            also be non-None. If only `wAPLKC` is passed, this is defined from it (as
            `wAPLKC` / <#-of-KCs>).

        use_connectome_APL_weights: if True, `connectome_APL_weights` called (with
            `connectome=pn2kc_connections`) to set `rv.kc.w[APLKC|KCAPL]`.
            `connectome_APL_weights` output is scaled to have a mean of 1 before being
            used to set these model variables.

        pn2kc_connections: string specifying method for forming PN->KC connection
            matrix. Must be one of `connectome_options` or `variable_n_claw_options`.

            If among the former, passed directly to `connectome_wPNKC` `connectome=`,
            otherwise `connectome_wPNKC` called with `connectome='hemibrain'`.

        weight_divisor: passed to `connectome_wPNKC` (only relevant for connectome
            `pn2kc_connections` options)

        _drop_glom_with_plus: passed to `connectome_wPNKC`

        seed: if using one of `pn2kc_connections` options that uses RNG to generate the
            PN->KC weight matrix (e.g. 'uniform', 'hemidraw', NOT 'hemibrain'), this
            seeds that RNG. The model (as configured by default, and as presented by
            this wrapper) is otherwise deterministic. NOTE: seeded by default.

        n_claws: for relevant `pn2kc_connections` (e.g. 'uniform', 'hemidraw', NOT
            'hemibrain') this sets that number of PNs each KC draws (i.e. # of claws for
            each KC)

        return_dynamics: if True, returns all available model internals, all as new
            elements of already-returned `param_dict`. This includes model ORN & PN
            firing rates, KC membrane potentials, KC spikes, APL membrane potential, and
            mean current from KCs to the APL, and potentially some other variables.

        plot_dir: if passed, will save some model-internals plots under this directory
            (which should be unique across all calls, within one run), and will copy the
            `olfsysm` log to `plot_dir / 'olfsysm_log.txt'` (log file will have suffix
            for seed if variable # of claws)

        drop_silent_cells_before_analyses: only relevant if `make_plots=True`

        title: (internal use only) only used if plot_dir passed. used as prefix for
            titles of plots.

        repro_preprint_s1d: (internal use only) whether to add fake odors + return data
            to allow reproduction of preprint figure S1D (showing model response rates
            to fake CO2, fake ms, and real eb)

        boost_wKCAPL: if boosting APL via `multiresponder_APL_boost=<float>`, will only
            boost `wAPLKC` if this is False.

            If True, will boost both `wAPLKC` and `wKCAPL` (by the same
            `multiresponder_APL_boost` factor).

            If 'only', will NOT boost `wAPLKC` and will only boost `wKCAPL` for these
            cells.

    Returns:
        responses: `spike_counts`, but binarized so any amount of spikes = True, else
            False.

        spike_counts: dataframe of shape (# KCs, # odors). If input had 'panel' level in
            odor (column) index, this currently does not preserve that level.
            If `repro_preprint_s1d=True` (which is NOT the default), extra
            (synthetic) odors for that plot will be included in output.

        wPNKC: dataframe of shape (# KCs, # glomeruli).

            Currently, I've only tested Matt's code with integer values, which can be
            interpreted as # of claws between PNs (of each glomerulus) to each KC.

        param_dict: dict containing tuned parameters (e.g. 'fixed_thr', 'wAPLKC'),
            certain model intermediates (e.g. 'kc_spont_in'), and certain parameters
            relevant for reproducibility (e.g. 'sp_acc', 'max_iters').

            If `use_connectome_APL_weights=True`, output will have `wAPLKC_scale` and
            `wKCAPL_scale`, which are scalars that could be used as input to `wAPLKC` /
            `wKCAPL` kwargs on another `fit_mb_model` call, where they will then also be
            interpreted to scale unit-mean connectome APL weight vectors. The other call
            should have `use_connectome_APL_weights=True` as well.
    """
    if _wPNKC is not None:
        # just a hacky way to check pn2kc_connections is unset (== default 'hemibrain',
        # unless i move default out of kwarg def to be able to detect unset more easily)
        assert pn2kc_connections == 'hemibrain'

    if pn2kc_connections not in pn2kc_connections_options:
        raise ValueError(f'{pn2kc_connections=} not in {pn2kc_connections_options}')

    if pn2kc_connections == 'caron':
        # TODO support (isn't this default olfsysm behavior?)? may need for comparisons
        # to ann's model (but hopefully there's a determinstic version of her model,
        # like our 'hemibrain', if i really care about that? not sure i could get same
        # RNG wPNKC in Matt's code vs hers...)?
        raise NotImplementedError

    # TODO rename? there is a fixed number of claws, just that we can set them w/
    # n_claws for these models, as opposed to wPNKC determining it (from whatever
    # connectome) in other cases.
    variable_n_claws = False
    if pn2kc_connections not in variable_n_claw_options:
        if n_claws is not None:
            raise ValueError(f'n_claws only supported for {variable_n_claw_options}')
    else:
        # TODO also default to averaging over at least a few seeds in all these cases?
        # how much do things actually tend to vary, seed to seed?
        variable_n_claws = True
        if n_claws is None:
            # NOTE: it seems to default to 6 in olfsysm.cpp
            raise ValueError('n_claws must be passed an int if pn2kc_connections in '
                f'{variable_n_claw_options}'
            )

    # TODO rename hallem_input to only_run_on_hallem (or something better)?
    hallem_input = False
    if orn_deltas is None:
        hallem_input = True
        # TODO just load orn_deltas here?
    else:
        # TODO delete
        orn_deltas = orn_deltas.copy()
        #

        # TODO switch to requiring 'glomerulus' (and in the one test that passes hallem
        # as input explicitly, process to convert to glomeruli before calling this fn)?
        valid_orn_index_names = ('receptor', 'glomerulus')
        if orn_deltas.index.name not in valid_orn_index_names:
            raise ValueError(f"{orn_deltas.index.name=} not in {valid_orn_index_names}")

        # TODO delete this path? shouldn't really be used...
        if orn_deltas.index.name == 'receptor':
            # TODO delete? (/ use to explain what is happening in case where
            # verbose=True and we are dropping stuff below)
            receptors = orn_deltas.index.copy()
            #

            glomeruli = [
                orns.find_glomeruli(r, verbose=False) for r in orn_deltas.index
            ]
            assert not any('+' in g for gs in glomeruli for g in gs)
            glomeruli = ['+'.join(gs) for gs in glomeruli]

            orn_deltas.index = glomeruli
            orn_deltas.index.name = 'glomerulus'

            # should drop any input glomeruli w/ '+' in name (e.g. 'DM3+DM5')
            orn_deltas = handle_multiglomerular_receptors(orn_deltas,
                drop=drop_multiglomerular_receptors
            )
        #

        # TODO if orn_deltas.index.name == 'glomerulus', assert all input are in
        # task/connectome glomerulus names
        # TODO same check on hallem glomeruli names too (below)?

    mp = osm.ModelParams()

    # TODO TODO what was matt using this for in narrow-odors-jupyter/modeling.ipynb
    #
    # Betty seemed to think this should always be True?
    # TODO was this actualy always True for matt's other stuff (including what's in
    # preprint? does it matter?)
    # Doesn't seem to affect any of the comparisons to Matt's outputs, whether this is
    # True or not (though I'm not clear on why it wouldn't do something, looking at the
    # code...)
    mp.kc.ignore_ffapl = True

    # may or may not care to relax this later
    # (so that we can let either be defined from one, or to try varying separately)
    if wAPLKC is None and wKCAPL is not None:
        raise NotImplementedError('wKCAPL can only be specified if wAPLKC is too')

    if fixed_thr is not None:
        # TODO TODO (still an issue?) probably still allow non-None target_sparsity if
        # there is vector fixed_thr (why?)? (currently just also hardcoding wAPLKC from
        # call in test_vector_thr)
        assert target_sparsity is None
        assert target_sparsity_factor_pre_APL is None
        #
        assert wAPLKC is not None, 'for now, assuming both passed if either is'

        # TODO still support varying apl activity here? (for a limited sens analysis)
        assert not homeostatic_thrs

        # TODO need to support int type too (in both of the two isinstance calls below)?
        # isinstance(<int>, float) is False
        if isinstance(fixed_thr, float):
            mp.kc.fixed_thr = fixed_thr
        else:
            # NOTE: will set rv.kc.thr below in this case, and mp.kc.fixed_thr should
            # not be used
            # TODO check olfsysm actually not using fixed_thr in this case
            assert isinstance(fixed_thr, np.ndarray)
            # TODO assert length matches other relevant dimensions (and if i change
            # type to Series from ndarray, also check metadata matches?)

        # except for "homeostatic" variants, Ann also sets "KC thresholds to a fixed
        # amount above [the time-averaged spontaneous PN input they receive]"
        # (from her thesis)
        mp.kc.add_fixed_thr_to_spont = True

        # actually do need this. may or may not need thr_type='fixed' too
        mp.kc.use_fixed_thr = True
        mp.kc.thr_type = 'fixed'
    else:
        if not homeostatic_thrs:
            mp.kc.thr_type = 'uniform'
        else:
            assert not equalize_kc_type_sparsity

            mp.kc.thr_type = 'hstatic'

            mp.kc.add_fixed_thr_to_spont = False
            mp.kc.use_fixed_thr = False

            # may or may not need this
            mp.kc.use_homeostatic_thrs = True

    if target_sparsity is not None:
        assert wAPLKC is None and wKCAPL is None
        mp.kc.sp_target = target_sparsity

    # target_sparsity_factor_pre_APL=2 would preserve old default behavior, where KC
    # threshold set to achieve 2 * sp_target, then APL tuned to bring down to sp_target
    if target_sparsity_factor_pre_APL is not None:
        # since APL should only be able to decrease response rate from where we set it
        # by picking KC spike threshold
        assert target_sparsity_factor_pre_APL >= 1

        if target_sparsity is not None:
            sp_target = target_sparsity
        else:
            # should be the olfsysm default (get from mp.kc?)
            sp_target = .1
        assert sp_target * target_sparsity_factor_pre_APL <= 1.0
        del sp_target

        mp.kc.sp_factor_pre_APL = target_sparsity_factor_pre_APL

        # TODO TODO (move to test_mb_model.py) test that if this is 1.0, then APL is
        # kept off (or will one iteration of tuning loop still happen + change things?),
        # or at least doesn't change responses/spike_counts
        # TODO TODO what's max value of this (min that forces threshold to do nothing,
        # with only APL bringing activity down? or does that not max sense?) maybe i
        # should change olfsysm to use something with a more sensible max (so i can go
        # between two extremes of all-threshold vs all-APL more easily)?
        # (probably just `1 / target_sparsity`? maybe accounting for how `sp_acc` would
        # factor into that)
        # TODO add unit test that my `1 / target_sparsity` guess above correct

    # NOTE: I committed olfsysm/hc_data.csv under al_analysis/data, since I couldn't
    # find a nice mechanism to install that CSV as part of olfsysm setup. This should be
    # the same as the olfsysm CSV.
    hc_data_csv = repo_root / 'data/hc_data.csv'
    # get crypic `ValueError: stod` in `osm.load_hc_data` below, if this doesn't exist
    assert hc_data_csv.exists()

    # just assuming olfsysm is at the path I would typically clone it to. this check
    # isn't super important. just establishing that the hc_data.csv committed in this
    # repo matches where we copied it from.
    olfsysm_repo = Path('~/src/olfsysm').expanduser()
    if olfsysm_repo.exists():
        olfsysm_hc_data_csv = olfsysm_repo / 'hc_data.csv'
        assert olfsysm_hc_data_csv.exists()

        # checking files are exactly the same
        unchanged = filecmp.cmp(hc_data_csv, olfsysm_hc_data_csv, shallow=False)
        assert unchanged

        del olfsysm_hc_data_csv
    del olfsysm_repo

    # TODO can i change to not load this when i'm just passing in my own data? necessary
    # even then? (add unit test to check?) (shouldn't be, if we are ourselves setting or
    # not using the 3 variables mentioned in comment below)
    #
    # initializes:
    # - mp.orn.data.delta to (#-hallem-gloms, #-hallem-odors)
    # - mp.orn.data.spont to (#-hallem-gloms, 1)
    # - mp.kc.cxn_distrib to values currently hardcoded inside load_hc_data
    #   (from Caron, presumably?)
    #
    # load_hc_data does not use the supplemental-odor section of the CSV, despite them
    # being present in the olfsysm CSV (and this one we copied+committed to this repo).
    # just the 110 main-text odors + sfr_col.
    osm.load_hc_data(mp, str(hc_data_csv))

    hallem_orn_deltas = orns.orns(add_sfr=False, drop_sfr=False, columns='glomerulus').T

    checks = True
    if checks:
        # columns: [glomeruli, receptors]
        hc_data = pd.read_csv(hc_data_csv, header=[0,1], index_col=[0,1])
        # [odor "class" (int: [0, 12]), odor name (w/ conc suffix for supplemental)]
        hc_data.index.names = ['class', 'odor']
        hc_data.index = hc_data.index.droplevel('class')
        hc_data.columns.names = ['glomerulus', 'receptor']
        hc_data = hc_data.T

        coreceptor_idx = hc_data.index.get_level_values('receptor').get_loc('33b')
        # get_loc can return other type if there isn't just one match
        assert isinstance(coreceptor_idx, int)
        hc_data.index = hc_data.index.droplevel('receptor')
        hc_data_gloms = list(hc_data.index)
        # renaming from duplicate 'dm3'
        hc_data_gloms[coreceptor_idx] = 'dm3+dm5'
        hc_data.index = pd.Index(data=hc_data_gloms, name='glomerulus')
        assert not hc_data.index.duplicated().any()

        # hc_data.columns[110:-1] are all the supplemental odors, which are not in
        # current hallem_orn_deltas. columns[-1] is sfr_col for both hc_data and
        # hallem_orn_deltas. first 110 should be same main-text Hallem odors (in same
        # order) for each, just formatted slightly differently for these few.
        #
        # {'2 3-butanediol': '2,3-butanediol',
        #  '2 3-butanedione': '2,3-butanedione',
        #  'ammoniumhydroxide': 'ammonium hydroxide',
        #  'ethylcinnamate': 'ethyl cinnamate',
        #  'linoleum acid': 'linoleic acid',
        #  'methanoicacid': 'methanoic acid',
        #  'nonionic acid': 'nonanoic acid',
        #  'pyretic acid': 'pyruvic acid'}
        hc_data_odor_renames = {
            k: v for k, v in zip(hc_data.columns[:110], hallem_orn_deltas.columns[:110])
            if k != v
        }
        hc_data.columns = hc_data.columns.map(lambda x: hc_data_odor_renames.get(x, x))
        assert not hc_data.columns.isna().any()
        assert not hc_data.columns.duplicated().any()

        hc_supp_odors = hc_data.columns[110:-1]
        assert not hc_supp_odors.isin(hallem_orn_deltas.columns).any()
        hc_data = hc_data.drop(columns=hc_supp_odors)

        assert hc_data.columns.equals(hallem_orn_deltas.columns)
        assert hallem_orn_deltas.index.str.lower().equals(hc_data.index)
        assert np.array_equal(hallem_orn_deltas, hc_data)

        del hc_data_csv, hc_data

    assert not hallem_orn_deltas.index.duplicated().any()
    # Or33b ('DM3+DM5' in my drosolf output, a duplicate 'dm3' in Matt's olfsysm CSV) is
    # the co-receptor for both DM3 (Or47a) and DM5 (Or85a)
    assert all(x in hallem_orn_deltas.index for x in ('DM3', 'DM5'))
    # should drop 'DM3+DM5'
    hallem_orn_deltas = handle_multiglomerular_receptors(hallem_orn_deltas,
        drop=drop_multiglomerular_receptors
    )

    # how to handle this for stuff not in hallem? (currently imputing mean Hallem sfr)
    sfr_col = 'spontaneous firing rate'
    sfr = hallem_orn_deltas[sfr_col]
    assert hallem_orn_deltas.columns[-1] == sfr_col
    hallem_orn_deltas = hallem_orn_deltas.iloc[:, :-1].copy()
    n_hallem_odors = hallem_orn_deltas.shape[1]
    assert n_hallem_odors == 110

    # TODO refactor
    hallem_orn_deltas = abbrev_hallem_odor_index(hallem_orn_deltas, axis='columns')

    # TODO delete
    # TODO any code i'm still using break if hallem_input=True and sim_odors is not
    # passed in? not currently passing in sim_odors anymore...
    # (only 1 call in model_test.py explicitly passes in, and only to check against
    # calls that don't) (also used in all preprint_repro_model_kw_list items below...
    # remove it from them [+ check output unchanged])?
    '''
    if hallem_input:
        assert sim_odors is None
        #print('see comment above')
        #import ipdb; ipdb.set_trace()
    '''
    #

    # TODO delete? still want to support?
    # TODO add comment explaining purpose of this block
    if hallem_input and sim_odors is not None:
        sim_odors_names2concs = dict()
        for odor_str in sim_odors:
            name = olf.parse_odor_name(odor_str)
            log10_conc = olf.parse_log10_conc(odor_str)

            # If input has any odor at multiple concentrations, this will fail...
            assert name not in sim_odors_names2concs
            sim_odors_names2concs[name] = log10_conc

        assert len(sim_odors_names2concs) == len(sim_odors)

        # These should have any abbreviations applied, but should currently all be the
        # main data (excluding lower concentration ramps + fruits), and not include
        # concentration (via suffixes like '@ -3')
        hallem_odors = hallem_orn_deltas.columns

        # TODO would need to relax this if i ever add lower conc data to hallem input
        assert all(olf.parse_log10_conc(x) is None for x in hallem_odors)

        # TODO TODO replace w/ hope_hallem_minus2_is_our_minus3 code used elsewhere
        # (refactoring to share), rather than overcomplicating here?
        #
        # TODO TODO warn about any fuzzy conc matching (maybe later, only if
        # hallem_input=True?)
        # (easier if i split this into ~2 steps?)
        hallem_sim_odors = [n for n in hallem_odors
            if n in sim_odors_names2concs and -3 <= sim_odors_names2concs[n] < -1
        ]
        # this may not be all i want to check
        assert len(hallem_sim_odors) == len(sim_odors)

        # since we are appending ' @ -2' to hallem_orn_deltas.columns below
        hallem_sim_odors = [f'{n} @ -2' for n in hallem_sim_odors]

    # TODO factor to drosolf.orns?
    assert hallem_orn_deltas.columns.name == 'odor'
    hallem_orn_deltas.columns += ' @ -2'

    # so that glomerulus order in Hallem CSVs will match eventual wPNKC output (which
    # has glomeruli sorted)
    #
    # making a copy to sort by glomeruli, since that would break an assertion later
    # (comparing against mp.orn internal data), if I sorted source variables.
    hallem_orn_deltas_for_csv = hallem_orn_deltas.sort_index(axis='index')
    sfr_for_csv = sfr.sort_index()

    if hallem_delta_csv.exists():
        assert hallem_sfr_csv.exists()
        # TODO or just save to root, but only do so if not already there? and load and
        # check against that otherwise? maybe save to ./data

        # TODO could just load first time we reach this (per run of script)...
        deltas_from_csv = pd.read_csv(hallem_delta_csv, index_col='glomerulus')
        sfr_from_csv = pd.read_csv(hallem_sfr_csv, index_col='glomerulus')

        deltas_from_csv.columns.name = 'odor'

        assert sfr_from_csv.shape[1] == 1
        sfr_from_csv = sfr_from_csv.iloc[:, 0].copy()

        assert sfr_for_csv.equals(sfr_from_csv)
        # changing abbreviations of some odors broke this previously
        # (hence why i replaced it w/ the two assertions below. now ignoring odor
        # columns)
        #assert hallem_orn_deltas_for_csv.equals(deltas_from_csv)
        assert np.array_equal(hallem_orn_deltas_for_csv, deltas_from_csv)
        assert hallem_orn_deltas_for_csv.index.equals(deltas_from_csv.index)
    else:
        if data_outputs_root.is_dir():
            # (subdirectory of data_outputs_root)
            hallem_csv_root.mkdir(exist_ok=True)

            # TODO assert columns of the two match here (so i don't need to check from
            # loaded versions, and so i can only check one against wPNKC, not both)
            to_csv(hallem_orn_deltas_for_csv, hallem_delta_csv)
            to_csv(sfr_for_csv, hallem_sfr_csv)

            # TODO delete? unused
            #deltas_from_csv = hallem_orn_deltas_for_csv.copy()
            #sfr_from_csv = sfr_for_csv.copy()
            #

        # TODO warn if data_outputs_root does not exist

    del hallem_orn_deltas_for_csv, sfr_for_csv

    if hallem_input:
        orn_deltas = hallem_orn_deltas.copy()

        if _add_back_methanoic_acid_mistake:
            warn('intentionally mangling Hallem methanoic acid responses, to recreate '
                'old bug in Ann/Matt modeling analysis! do not use for any new '
                'results!'
            )
            orn_deltas['methanoic acid @ -2'] = [
                -2,-14,31,0,33,-8,-6,-9,8,-1,-20,3,25,2,5,12,-8,-9,14,7,0,4,14
            ]

    # TODO should tune_on_hallem be set True if input is already hallem? prob?
    # (i.e. if orn_deltas not passed)

    # TODO (delete?) implement means of getting threshold from hallem input + hallem
    # glomeruli only -> somehow applying that threshold [+APL inh?] globally (and
    # running subsequent stuff w/ all glomeruli, including non-hallem ones) (even
    # possible?)
    # TODO (delete?) now that i can just hardcode the 2 params, can i make plots where i
    # "tune" on hallem and then apply those params to the model using my data as input,
    # w/ all glomeruli (or does it still not make sense to use the same global params,
    # w/ new PNs w/ presumably new spontaneous input now there? think it might not make
    # sense...)
    # TODO delete
    '''
    if not hallem_input and tune_on_hallem:
        # (think i always have this True when tune_on_hallem=True, at the moment, but if
        # i can do what i'm asking in comment above, could try letting this be False
        # while tune_on_hallem=True, for input that has more glomeruli than in Hallem)
        print(f'{drop_receptors_not_in_hallem=}')
        import ipdb; ipdb.set_trace()
    '''
    #

    connectome = (
        # NOTE: this means that if pn2kc_connections == 'hemidraw', it will use marginal
        # probabilities from 'hemibrain' connectome. no current support for using either
        # fafb data source for that.
        pn2kc_connections if pn2kc_connections in connectome_options else 'hemibrain'
    )
    kc_types = None
    if _wPNKC is None:
        # TODO check that nothing else depends on order of columns (glomeruli) in these
        # (add a unit test permuting columns via _wPNKC kwarg, and delete this comment?)

        if _wPNKC_one_row_per_claw:
            # initially, Tianpei had hardcoded these mp.kc.* values in his olfsysm
            # compilation, but want to keep old values
            old_max_iters = mp.kc.max_iters
            old_sp_lr_coeff = mp.kc.sp_lr_coeff
            # TODO assert old values actually were both 10 (depends on me reverting
            # olfsysm correctly and recompiling)

            # was default of 10 before
            mp.kc.max_iters = 100

            # was default of 10.0 before
            # it seems he had at one point also tried 1.0, but i'm assuming 1.5 is the
            # latest value he intended to use
            #mp.kc.sp_lr_coeff = 1.0
            mp.kc.sp_lr_coeff = 1.5

            warn('hardcoding new defaults for _wPNKC_one_row_per_claw=True case:\n'
                f'{mp.kc.max_iters=} (was {old_max_iters})\n'
                f'{mp.kc.sp_lr_coeff=} (was {old_sp_lr_coeff})\n'
            )

            synapse_data_dir = from_prat / '2025-04-24'
            assert synapse_data_dir.is_dir()

            synapse_con_path = synapse_data_dir / 'PN2KC_Connectivity.csv'
            synapse_loc_path = synapse_data_dir / 'PN2KC_Synapse_Locations.csv'
            assert synapse_con_path.exists()
            assert synapse_loc_path.exists()

            wPNKC = connectome_wPNKC(
                connectome=connectome,
                weight_divisor=weight_divisor,
                synapse_con_path=synapse_con_path,
                synapse_loc_path=synapse_loc_path,
                plot_dir=plot_dir if pn2kc_connections in connectome_options else None,
                _use_matt_wPNKC=_use_matt_wPNKC,
                _drop_glom_with_plus=_drop_glom_with_plus,
            )
            if 'compartment' in wPNKC.index.names:
                claw_comp = wPNKC.index.get_level_values('compartment').to_numpy(
                    np.int32, copy=True
                )
                assert claw_comp.size == len(wPNKC), "compartment length mismatch"

            if plot_dir is not None:
                # TODO need to handle multiple saves to same path?
                to_csv(wPNKC.reset_index(), plot_dir / 'test_spatial_wPNKC.csv',
                    index=True
                )
        else:
            wPNKC = connectome_wPNKC(
                connectome=connectome,
                weight_divisor=weight_divisor,
                # TODO TODO TODO doc why we even need to call connectome_wPNKC in
                # pn2kc_connections like 'uniform' (and is _drop_glom_with_plus relevant
                # there?) (will check it matters w/ uniform repro test i'm working on)
                #
                # disabling plot_dir here b/c models that are run w/ multiple seeds
                # (handled in code that calls this fn, not within here), would end up
                # trying to make the same plots for each seed (which would trigger
                # savefig assertion that we aren't writing to same path more than once)
                plot_dir=None if variable_n_claws else plot_dir,
                _use_matt_wPNKC=_use_matt_wPNKC,
                _drop_glom_with_plus=_drop_glom_with_plus,
            )
    else:
        print("_wPNKC exists")
        wPNKC = _wPNKC.copy()
        # Conditionally drop 'kc_type' from wPNKC
        # if _wPNKC_one_row_per_claw:
        #     print("wPNKC_one_row_per_claw passed in _wPNKC")
        #     claw_index = wPNKC.index.copy()
        #     ix = wPNKC.index
        #     to_drop = [lvl for lvl in ('claw_id','claw_x','claw_y','claw_z','compartment')
        #             if lvl in ix.names]
        #     kc_index = (ix.droplevel(to_drop) if to_drop else ix).drop_duplicates()
        #     claw_comp = np.zeros(len(wPNKC), dtype=np.int64)
        # else: 
        #     print("wPNKC_one_row_per_KC passed in _wPNKC")
        #     kc_index = wPNKC.index
    

    if not _wPNKC_one_row_per_claw:
        # no claw_index needed here
        kc_index = wPNKC.index.copy()
    else:
        # claw_index = wPNKC.index.copy()
        # kc_index = claw_index.droplevel(
        #     # TODO refactor to share w/ defs elsewhere (move claw_coord_cols to
        #     # module level, etc)
        #     ['claw_id','claw_x','claw_y','claw_z','compartment']
        # ).drop_duplicates()
        claw_index = wPNKC.index.copy()
        to_drop = [lvl for lvl in ('claw_id','claw_x','claw_y','claw_z','compartment')
                if lvl in claw_index.names]
        kc_index = (claw_index.droplevel(to_drop) if to_drop else ix).drop_duplicates()
        claw_comp = np.zeros(len(wPNKC), dtype=np.int64)

    # if isinstance(wPNKC.index, pd.MultiIndex) and (KC_TYPE in wPNKC.index.names):
    #     wPNKC = wPNKC.droplevel(KC_TYPE)
    # # Conditionally drop 'kc_type' from kc_index
    # if isinstance(kc_index, pd.MultiIndex) and (KC_TYPE in kc_index.names):
    #     kc_index = kc_index.droplevel(KC_TYPE)


    if KC_TYPE in wPNKC.index.names:
        # TODO TODO at least doc why we still need to drop this level (only to
        # re-add later), or remove
        # TODO delete? currently tempted to assign this kc_type col back into a
        # level of wPNKC index below (am doing that now) (and want all outputs w/ a
        # KC index to have them consistent)
        kc_types = kc_index.get_level_values(KC_TYPE)
        kc_index = kc_index.droplevel(KC_TYPE)
        # TODO delete?
        # claw_index = claw_index.droplevel(KC_TYPE)

        # TODO TODO even if we do need to drop in kc_index, do we need to drop in
        # wPNKC.index? either way, all code should probably be changed to never need to
        # drop this level
        if not _wPNKC_one_row_per_claw:
            wPNKC.index = kc_index.copy()

        # TODO delete / restore similar, that also works in one-row-per-claw case
        #assert wPNKC.index.names == [kc_id_col]

    glomerulus_index = wPNKC.columns

    if not hallem_input:
        zero_filling = (~ glomerulus_index.isin(orn_deltas.index))
        if zero_filling.any():
            msg = ('zero filling spike deltas for glomeruli not in data: '
                f'{sorted(glomerulus_index[zero_filling])}'
            )
            warn(msg)

        # TODO (?) if i add 'uniform' draw path, make sure zero filling is keeping
        # glomeruli that would implicitly be dropped in hemibrain (/ hemidraw / caron)
        # cases (as we don't need wPNKC info in 'uniform' case, as all glomeruli are
        # sampled equally, without using any explicit connectivity / distribution)
        # (don't warn there either)
        #
        # Any stuff w/ '+' in name (e.g. 'DM3+DM5' in Hallem) should already have been
        # dropped.
        input_glomeruli = set(orn_deltas.index)
        glomeruli_missing_in_wPNKC = input_glomeruli - set(glomerulus_index)
        if len(glomeruli_missing_in_wPNKC) > 0:
            # TODO assert False? seems we could do that at least for megamat data...
            warn('dropping glomeruli not in wPNKC (while zero-filling): '
                f'{glomeruli_missing_in_wPNKC}'
            )

        if tune_on_hallem:
            # TODO make sure we aren't writing wPNKC in this case (and maybe not other
            # hallem CSVs? they are probably fine either way...)
            hallem_not_in_wPNKC = set(hallem_orn_deltas.index) - set(glomerulus_index)
            assert len(hallem_not_in_wPNKC) == 0 or hallem_not_in_wPNKC == {'DA4m'}, \
                f'unexpected {hallem_not_in_wPNKC=}'

            if len(hallem_not_in_wPNKC) > 0:
                warn(f'dropping glomeruli not in wPNKC {hallem_not_in_wPNKC} from '
                    'Hallem data to be used for tuning'
                )

            # this will be concatenated with orn_deltas below, and we don't want to add
            # back the glomeruli not in wPNKC
            hallem_orn_deltas = hallem_orn_deltas.loc[
                [c for c in hallem_orn_deltas.index if c in glomerulus_index]
            ].copy()

        orn_deltas_pre_filling = orn_deltas.copy()

        # TODO simplify this. not a pandas call for it? reindex_like seemed to not
        # behave as expected, but maybe it's for something else / i was using it
        # incorrectly
        # TODO just do w/ pd.concat? or did i want shape to match hallem exactly in that
        # case? matter?
        # TODO reindex -> fillna?
        orn_deltas = pd.DataFrame([
                orn_deltas.loc[x].values if x in orn_deltas.index
                # TODO correct? after concat across odors in tune_on_hallem=True case?
                else np.zeros(len(orn_deltas.columns))
                # TODO also use glomerulus_index here (instead of wPNKC.columns) for
                # consistency w/ above?
                for x in wPNKC.columns
            ], index=glomerulus_index, columns=orn_deltas.columns
        )
        print("orn_deltas pd.Datafram passed")
        # TODO need to be int (doesn't seem so)?
        mean_sfr = sfr.mean()

        non_hallem_gloms = sorted(set(glomerulus_index) - set(sfr.index))
        if len(non_hallem_gloms) > 0:
            warn(f'imputing mean Hallem SFR ({mean_sfr:.2f}) for non-Hallem glomeruli:'
                f' {non_hallem_gloms}'
            )

        sfr = pd.Series(index=glomerulus_index,
            data=[(sfr.loc[g] if g in sfr else mean_sfr) for g in glomerulus_index]
        )
        assert sfr.index.equals(orn_deltas.index)
    #

    odor_index = orn_deltas.columns
    n_input_odors = orn_deltas.shape[1]

    extra_orn_deltas: Optional[pd.DataFrame] = None
    # TODO delete/comment after i'm done?
    #'''
    eb_mask = orn_deltas.columns.get_level_values('odor').str.startswith('eb @')
    # should be true for megamat and hallem
    if repro_preprint_s1d and eb_mask.sum() == 1:
        # TODO finish support for "extra" odors (to be simmed, but not tuned on)
        # (expose as kwarg eventually prob)
        # (would not be conditional on eb if so... just a hack to skip validation, and
        # only want S1D if we do have eb, as thats what preprint one used)

        # TODO try to move up above any modifications to orn_deltas (mainly the
        # glomeruli filling above) after getting it to work down here? (why? just to
        # make easier to convert to kwarg?)

        fake_odors = ['fake ms @ 0']
        if 'V' in orn_deltas.index:
            fake_odors.append('fake CO2 @ 0')

        # should only be in 'hallem' cases
        else:
            # TODO TODO how did matt handle this? (not in wPNKC I'm currently using in
            # Hallem case) (pretty sure most of his modelling is done w/o 'V' (or any
            # non-Hallem glomeruli) in wPNKC. so what is he doing for wPNKC here? and
            # what data is he using for the non-Hallem glomeruli for tuning?)
            #
            # (not doing fake-CO2 in 'hallem' context for now)
            warn("glomerulus 'V' not in wPNKC, so not adding fake CO2!")

        # TODO convert to kwarg -> def in model_mb... and pass in thru there?
        extra_orn_deltas = pd.DataFrame(index=orn_deltas.index, columns=fake_odors,
            data=0
        )
        print("extra_orn_deltas pd.Datafram passed")
        assert 'odor' in orn_deltas.columns.names
        extra_orn_deltas.columns.name = 'odor'
        # TODO handle appending ' @ 0' automatically if needed (only if i actually
        # expose extra_orn_deltas as a kwarg)?

        extra_orn_deltas.loc['DL1', 'fake ms @ 0'] = 300
        if 'V' in orn_deltas.index:
            extra_orn_deltas.loc['V', 'fake CO2 @ 0'] = 300

        eb_deltas = orn_deltas.loc[:, eb_mask]

        if 'panel' in eb_deltas.columns.names:
            eb_deltas = eb_deltas.droplevel('panel', axis='columns')

        assert eb_deltas.shape[1] == 1
        eb_deltas = eb_deltas.iloc[:, 0]
        assert len(eb_deltas) == len(extra_orn_deltas)

        # eb_deltas.name will be like 'eb @ -3' (previous odor columns level value)
        extra_orn_deltas[eb_deltas.name] = eb_deltas

        if sim_odors is not None:
            assert hallem_input
            # sim_odors contents not used for anything other than internal plots below,
            # so sufficient to only grow hallem_sim_odors here (which is used to subset
            # responses right before returning, and for nothing else [past this point at
            # least])
            #
            # not also growing by extra `eb_deltas.name`, because that gets removed
            # before hallem_sim_odors used (extra eb is not returned in hallem or any
            # other case. only checked against responses to existing eb col)
            hallem_sim_odors.extend(fake_odors)
    #'''

    # TODO can i remove need for this (and just use odor_index), if i remove the extra
    # odors asap? prob not...
    # I'm currently assuming that pks (but not responses
    # TODO rename to odor_index_noextras or something? may depend on whether i use for
    # much beyond pks (where i think it is the tuned odors that are needed)
    tuning_odor_index = odor_index.copy()

    n_extra_odors = 0
    if extra_orn_deltas is not None:
        n_extra_odors = extra_orn_deltas.shape[1]

        if 'panel' in orn_deltas.columns.names:
            assert 'extra' not in set(orn_deltas.columns.get_level_values('panel'))
            extra_orn_deltas = util.addlevel(extra_orn_deltas, 'panel', 'extra',
                axis='columns'
            )

        # TODO assert row index unchanged and column index up-to-old-length too?
        #
        # removed verify_integrity=True since there is currently duplicate 'eb' in
        # hallem case (w/o 'panel' level to disambiguate) (only when adding extra odors)
        orn_deltas = pd.concat([orn_deltas, extra_orn_deltas], axis='columns')

        # TODO TODO TODO either maintain original odor_index, and use that below where
        # appropriate, or quickly restore this after dropping those odors (may need the
        # original odor_index in some places regardless...)
        # TODO TODO actually need this version of odor_index anywhere?
        odor_index = orn_deltas.columns

        # TODO make sure we aren't overwriting either of these below before running!
        mp.kc.tune_from = range(n_input_odors)
        mp.sim_only = range(n_input_odors)


    # TODO maybe set tune_on_hallem=False (early on) if orn_deltas is None?
    if tune_on_hallem and not hallem_input:
        # TODO maybe make a list (largely just so i can access it more than once)?
        # TODO where is default defined for this? not seeing it... behave same as if not
        # passed (e.g. if only have hallem odors)
        mp.kc.tune_from = range(n_hallem_odors)

        # Will need to change this after initial (threshold / inhibition setting) sims.
        # TODO interactions between this and tune_from? must sim_only contain tune_from?
        mp.sim_only = range(n_hallem_odors)

        # TODO worth setting a seed here (as model_mix_responses.py did, but maybe not
        # for good reason)?

        # at this point, if i pass in orn_deltas=orns.orns(add_sfr=False).T, only
        # columns differ (b/c odor renaming)

        # TODO TODO adapt to work w/ panel col level? what to use for hallem? 'hallem'?
        # None?
        # TODO assert this concat doesn't change odor (col) index? inspect what it's
        # doing to sanity check?
        #
        # TODO TODO test on my actual data (just tried hallem duped so far).
        # (inspect here to check for weirdness?)
        # TODO TODO need to align (if mismatching sets of glomeruli)?
        # TODO add metadata to more easily separate?
        # TODO TODO maybe add verify_integrity=True (or at least test that everything
        # works in case where columns are verbatim duplicated across the two, which
        # could probably happen if an odor was at minus 2, or if i add support for other
        # concentrations?)
        orn_deltas = pd.concat([hallem_orn_deltas, orn_deltas], axis='columns')

        # since other checks will compare these two indices later
        assert set(sfr.index) == set(orn_deltas.index)

        orn_deltas = orn_deltas.loc[sfr.index].copy()

        # TODO delete? not sure if it's triggered outside of case where i accidentally
        # passed input where all va/aa stuff was dropped (by calling script w/
        # 2023-04-22 as end of date range, rather than start)
        try:
            # TODO (if i want to keep this) do i want to use odor_index or
            # tuning_odor_index (the former also includes "odors" from extra_orn_deltas,
            # if that's not None)?
            #
            # TODO if i wanna keep this, move earlier (or at least have another version
            # of this earlier? maybe in one of first lines in fit_mb_model, or in
            # whatever is processing orn_deltas before it's passed to fit_mb_model?)
            # (the issue seems to be created before we get into fit_mb_model)
            assert sim_odors is None or sim_odors == set(
                odor_index.get_level_values('odor')
            ), 'why'
        except AssertionError:
            import ipdb; ipdb.set_trace()

    if not hallem_input:
        # TODO maybe i should still have an option here to tune on more data than what i
        # ultimately return (perhaps including diagnostic data? though they prob don't
        # have representative KC sparsities either...)

        # TODO TODO try to implement other strategies where we don't need to throw
        # away input glomeruli/receptors
        # (might need to make my own gkc_wide csv equivalent, assuming it only contains
        # the connections involving the hallem glomeruli)
        # (also, could probably not work in the tune_on_hallem case...)

        # TODO delete here (already moved into conditional below)
        #hallem_glomeruli = hallem_orn_deltas.index

        # TODO TODO raise NotImplementedError/similar if tune_on_hallem=True,
        # not hallem_input, and not drop_receptors_not_in_hallem?

        # TODO TODO maybe this needs to be True if tune_on_hallem=True? at least as
        # implemented now?
        # TODO rename to drop_glomeruli_not_in_hallem?
        if drop_receptors_not_in_hallem:
            # NOTE: this should already have had 'DM3+DM5' (Or33b) removed above
            hallem_glomeruli = hallem_orn_deltas.index

            glomerulus2receptors = orns.task_glomerulus2receptors()
            receptors = np.array(
                ['+'.join(glomerulus2receptors[g]) for g in orn_deltas.index]
            )
            # technically this would also throw away 33b, but that is currently getting
            # thrown out above w/ the drop_multiglomerular_receptors path
            receptors_not_in_hallem = ~orn_deltas.index.isin(hallem_glomeruli)
            if receptors_not_in_hallem.sum() > 0:
                # TODO warn differently (/only?) for stuff that was actually in our
                # input data, and not just zero filled above?
                msg = 'dropping glomeruli not in Hallem:'
                # TODO sort on glomeruli names (seems it already is. just from hallem
                # order? still may want to sort here to ensure)
                msg += '\n- '.join([''] + [f'{g} ({r})' for g, r in
                    zip(orn_deltas.index[receptors_not_in_hallem],
                        receptors[receptors_not_in_hallem])
                ])
                msg += '\n'
                warn(msg)

            orn_deltas = orn_deltas[~receptors_not_in_hallem].copy()
            sfr = sfr[~receptors_not_in_hallem].copy()

            # TODO refactor to not use glomerulus index, and just always use
            # wPNKC.columns, to not have to deal w/ the two separately? (here and
            # elsewhere...)
            assert glomerulus_index.equals(wPNKC.columns)
            glomerulus_index = glomerulus_index[~receptors_not_in_hallem].copy()
            wPNKC = wPNKC.loc[:, ~receptors_not_in_hallem].copy()

    # TODO TODO probably still support just one .name == 'odor' tho...
    # (esp for calls w/ just hallem input, either old ones here or model_test.py?)
    # (could just check 'odor' in .names that works even if single level)
    # TODO do i only want to allow [the possibility of] a single other 'panel' level, or
    # allow arbitrary other levels?
    # TODO move earlier?
    assert orn_deltas.columns.name == 'odor' or (
        orn_deltas.columns.names == ['panel', 'odor']
    )

    # TODO would we or would we not have removed it in that case? and what about
    # pratyush wPNKC case?
    # If using Matt's wPNKC, we may have removed this above:
    if 'DA4m' in hallem_orn_deltas.index:
        assert np.array_equal(hallem_orn_deltas, mp.orn.data.delta)

        if hallem_input:
            # TODO just do this before we would modify sfr (in that one branch above)?
            assert np.array_equal(sfr, mp.orn.data.spont[:, 0])

    # TODO TODO merge da4m/l hallem data (pretty sure they are both in my own wPNKC?)?
    # TODO TODO do same w/ 33b (adding it into 47a and 85a Hallem data, for DM3 and DM5,
    # respectively)?

    # TODO TODO add comment explaining circumstances when we wouldn't have this.  it
    # seems to be zero filled (presumably just b/c in wPNKC earlier, and i think that's
    # the case whether _use_matt_wPNKC is True or False). maybe just in non-hemibrain
    # stuff? can i assert it's always true and delete some of this code?
    # TODO TODO only drop DA4m if it's not in wPNKC (which should only be if
    # _use_matt_wPNKC=False?)?
    #
    # We may have already implicitly dropped this in the zero-filling code
    # (if that code ran, and if wPNKC doesn't have DA4m in its columns)
    have_DA4m = 'DA4m' in sfr.index or 'DA4m' in orn_deltas.index

    # TODO replace by just checking one for have_DA4m def above, w/ an assertion the
    # indices are (still) equal here?
    if have_DA4m:
        assert 'DA4m' in sfr.index and 'DA4m' in orn_deltas.index

    # TODO delete
    # currently getting tripped by model_test.py case that passes in hallem orn_deltas
    #print(f'{have_DA4m=}')
    #if not have_DA4m:
    #    print()
    #    print('did not have DA4m in sfr.index. add comment explaining current input')
    #    import ipdb; ipdb.set_trace()
    #

    # TODO also only do if _use_matt_wPNKC=True (prat's seems to have DA4m...)?
    #if (hallem_input or tune_on_hallem) and have_DA4m:
    # TODO this aligned with what i want?
    # TODO revert to using wPNKC.columns instead of glomerulus_index, for clarity?
    if 'DA4m' not in glomerulus_index and have_DA4m:
        # TODO why was he dropping it tho? was it really just b/c it wasn't in (his
        # version of) hemibrain?
        # DA4m should be the glomerulus associated with receptor Or2a that Matt was
        # dropping.
        # TODO TODO TODO why was i doing this? delete? put behind descriptive flag at
        # least? if i didn't need to keep receptors in line w/ what's already in osm,
        # then why do the skipping above? if i did, then is this not gonna cause a
        # problem? is 2a (DA4m) actually something i wanted to remove? why?
        # (was it just b/c it [for some unclear reason] wasn't in matt's wPNKC?)

        # TODO maybe replace by just having wPNKC all 0 for DA4m in _use_matt_wPNKC
        # case, where i would need to fill in those zeros in wPNKC (which doesn't
        # already have DA4m (Or2a), i believe)? could be slightly less special-casey...?
        sfr = sfr[sfr.index != 'DA4m'].copy()
        orn_deltas = orn_deltas.loc[orn_deltas.index != 'DA4m'].copy()

        # TODO TODO also remove DA4m from orn_deltas_pre_filling?
        # (maybe just subset to what's in sfr/orn_deltas but not orn_deltas_pre_filling,
        # but down by usage of orn_deltas_pre_filling?)

    assert sfr.index.equals(orn_deltas.index)

    # TODO delete
    _wPNKC_shape_changed = False
    if wPNKC.shape != wPNKC[sfr.index].shape:
        print()
        print(f'wPNKC shape BEFORE subsetting to sfr.index: {wPNKC.shape}')
        _wPNKC_shape_changed = True
    #

    # TODO TODO also need to subset glomerulus_index here now? just always use
    # wPNKC.columns and remove glomerulus_index?
    # TODO just add assertion that wPNKC shape unchanged by this? i haven't seen the
    # surrounding debug prints trigger in a while, and i'm not sure if we path we care
    # about can reproduce them...

    wPNKC = wPNKC[sfr.index].copy()

    # TODO delete
    if _wPNKC_shape_changed:
        # TODO TODO is this only triggered IFF have_DA4m? move all this wPNKC stuff into
        # that conditional above?
        print(f'wPNKC shape AFTER subsetting to sfr.index: {wPNKC.shape}')
        print()
        print('NEED TO SUBSET GLOMERULUS_INDEX HERE (/ refactor to just use wPNKC)?')
        import ipdb; ipdb.set_trace()
        print()
    del _wPNKC_shape_changed
    #

    # TODO try removing .copy()?
    mp.orn.data.spont = sfr.copy()
    mp.orn.data.delta = orn_deltas.copy()

    # TODO need to remove DA4m (2a) from wPNKC first too (already out, it seems)?
    # don't see matt doing it in hemimat-modeling... (i don't think i need to.
    # rv.pn.pn_sims below had receptor-dim length of 22)

    if variable_n_claws:
        # TODO is seed actually only used in variable_n_claws=True cases?
        # (seems so, and doesn't seem to matter it is set right before KC sims)
        # TODO should seed be Optional?
        mp.kc.seed = seed
        mp.kc.nclaws = n_claws

    if not _wPNKC_one_row_per_claw:
        # TODO also take an optional parameter to control this number?
        # (for variable_n_claws cases mainly)
        # TODO or if always gonna use wPNKC, option to use # from [one of] fafb data
        # sources (2482 in left), instead of hemibrain?
        mp.kc.N = len(wPNKC)
    else:
        # this should also work if values are all True/False, or all float 1.0/0.0.
        # NOTE: should be OK if some claws receive no input (should only be for KCs with
        # no claws with input, and thus should only be in a single claw for each such
        # KC, with claw_id=0)
        assert set(wPNKC.values.flat) == {1, 0}

        # TODO also assert a consistent KC id ('kc_id'?) column name throughout?
        # currently mostly have something like 'bodyId', but 'kc_id' is more clear
        claw_id = 'claw_id'
        assert claw_id in wPNKC.index.names

        # TODO assert coords all positive or have some other properties?
        claw_coord_levels = [f'claw_{coord}' for coord in ('x', 'y', 'z')]
        assert all(c in wPNKC.index.names for c in claw_coord_levels)

        assert KC_ID in wPNKC.index.names
        # TODO just replace usage of kc_id below w/ KC_ID?
        kc_id = KC_ID
        assert not wPNKC.index.to_frame(index=False)[[kc_id, claw_id]].duplicated(
            ).any()

        checks = True
        if checks:
            claws_without_input = (wPNKC.T == 0).all()
            wPNKC_only_kcs_with_input = wPNKC.loc[~ claws_without_input]

            wPNKC_only_kcs_without_input = wPNKC.loc[claws_without_input]
            assert (wPNKC_only_kcs_without_input.index.get_level_values(claw_id) == 0
                ).all()

            kcs_without_input = wPNKC_only_kcs_without_input.index.get_level_values(
                kc_id
            )
            assert not kcs_without_input.duplicated().any()
            kcs_with_input = set(
                wPNKC_only_kcs_with_input.index.get_level_values(kc_id).unique()
            )
            assert not any(x in kcs_with_input for x in kcs_without_input)

            assert (wPNKC_only_kcs_with_input.T.sum() == 1).all()
            assert (wPNKC_only_kcs_with_input.T.max() == 1).all()

            for kc, kc_df in wPNKC.groupby(kc_id, sort=False):
                kc_claw_ids = kc_df.index.get_level_values(claw_id)
                # checking that claw_id values count up from 0 within each KC
                assert set(kc_claw_ids) == set(np.arange(len(kc_claw_ids)))

        # TODO will i end up wanting to transpose this, to have it's shape in olfsysm
        # consistent w/ some other stuff in there? (see wAPLKC vs wKCAPL, for one
        # current case were olfsysm wants some things in either row or column vectors)
        # TODO try w/o .values after getting working with it?
        kc_ids = kc_index.get_level_values(kc_id).values
        kc_ids_per_claw = claw_index.get_level_values(kc_id).values
        n_kcs = len(set(kc_ids))

        # mp.kc.N = len(claw_index)
        mp.kc.N = len(kc_index)
        # TODO TODO TODO implement in olfsysm (-> use for determining which claws to
        # consider as part of one KC)
        mp.kc.kc_ids = kc_ids_per_claw

        # TODO TODO TODO implement in olfsysm (in such a way that related test
        # [test_spatial_wPNKC_equiv] passes)
        mp.kc.wPNKC_one_row_per_claw = True
        # TODO TODO may want a new olfsysm variable (other than wPNKC) for this
        # (# claw, # glomeruli) shape wPNKC matrix, if easier to modify olfsysm if we
        # keep wPNKC of shape (# KCs, # glomeruli), which it might be if olfsysm uses
        # wPNKC extensively for getting # KCs, etc


    if pn2kc_connections in connectome_options:
        mp.kc.preset_wPNKC = True

    elif pn2kc_connections == 'hemidraw':
        # TODO support using wPNKC from fafb-left/fafb-right (currently just hemibrain,
        # w/ _use_matt_wPNKC=False. i.e. using the newer data from prat's query)?
        # (and/or also support arbitrary _wPNKC input)

        # TODO check index (glomeruli) is same as sfr/etc (all other things w/ glomeruli
        # that model uses)
        # TODO just set directly into mp.kc.cxn_distrib?
        # (and in other places that set this)
        #
        # TODO have olfsysm use same appropriate to internally normalize (to mean of 1)
        # connectome wAPLKC/wKCAPL (as i currently do in here) (already doing in here
        # for connectome APL weights)
        #
        # TODO add unit test confirming we don't need to pre-normalize, and then delete
        # uncertain language
        #
        # TODO add this to param dict if it's set? (whether via this code, or future
        # code using other wPNKC inputs)
        #
        # should be normalized (to mean of 1? check) inside olfsysm
        cxn_distrib = wPNKC.sum()

        # TODO delete?
        if hallem_input:
            # TODO compute this from something?
            n_hallem_glomeruli = 23
            assert mp.kc.cxn_distrib.shape == (1, n_hallem_glomeruli)
        #

        # TODO TODO what currently happens if using # glomeruli other > hallem?
        # seems like it may already be broken? (and also in uniform case. not sure if
        # this is why tho) (? delete?)
        #
        # TODO can we modify olfsysm to break if input shape is wrong? why does it work
        # for mp.orn.data.spont but not this? (shape of mp.orn.data.spont is (n, 1)
        # before, not (1, n) as this is)
        # (maybe it was fixed in commit that added allowdd option, and maybe that's why
        # i hadn't noticed it? or i just hadn't actually tested this path before?)
        #
        # NOTE: this reshaping (from (n_glomeruli,) to (1, n_glomeruli)) was critical
        # for correct output (at least w/ olfsysm.cpp from 0d23530f, before allowdd)
        mp.kc.cxn_distrib = cxn_distrib.to_frame().T
        assert mp.kc.cxn_distrib.shape == (1, len(cxn_distrib))

        wPNKC = None

    # NOTE: if i implement this, need to make sure cxn_distrib is getting reshaped as in
    # 'hemidraw' case above. was critical for correct behavior there.
    #elif pn2kc_connections == 'caron':
    #    # TODO could modify this (drop same index for 2a) if i wanted to use caron
    #    # distrib Of shape (1, 23), where 23 is from 24 Hallem ORs minus 33b probably?
    #    cxn_distrib = mp.kc.cxn_distrib[0, :].copy()
    #    assert len(cxn_distrib) == 23

    elif pn2kc_connections == 'uniform':
        mp.kc.uniform_pns = True

        wPNKC = None

    # TODO add additional kwargs, to allow setting and/or scaling only one of these at
    # at time?
    if use_connectome_APL_weights:
        mp.kc.preset_wAPLKC = True
        mp.kc.preset_wKCAPL = True

    if _plot_example_dynamics:
        if hallem_input:
            # will probably be killed by system OOM killer
            warn('plotting/returning model dynamics likely to crash with hallem input, '
                'b/c many odors'
            )

        # NOTE: if these are left to default of False, seems the rv.kc.vm_sims (or
        # whatever cognate output variable) will seem like an empty list here.
        #
        # These will all save output to `rv.kc.<var-name>` for save flag like
        # `mp.kc.save_<var-name>`.
        mp.kc.save_vm_sims = True
        mp.kc.save_spike_recordings = True
        mp.kc.save_inh_sims = True
        mp.kc.save_Is_sims = True
        # if `mp.kc.ves_p == 0`, the "vesicle depletion" part of olfsysm is disabled.
        # see related comments around use of nves_sims below.
        if mp.kc.ves_p != 0:
            mp.kc.save_nves_sims = True

    rv = osm.RunVars(mp)

    kc_to_claws = None
    if _wPNKC_one_row_per_claw:
        rv.kc.claw_compartments = claw_comp
        kc_ids_per_claw = np.asarray(kc_ids_per_claw, dtype=np.int64)

        # TODO replace this w/ more idiomatic / simply numpy/pandas code?
        # Compact body IDs to 0..N-1 (first-appearance order)
        id2compact = {}
        compact = np.empty(kc_ids_per_claw.shape[0], dtype=np.int32)
        next_idx = 0
        for i, bid in enumerate(kc_ids_per_claw):
            b = int(bid)
            idx = id2compact.get(b)
            if idx is None:
                idx = next_idx
                id2compact[b] = idx
                next_idx += 1
            compact[i] = idx
        N = int(next_idx)

        # TODO add some assertions here that IDs created are correct?

        # Ensure params agree (or update them)
        # Overwrite mapping at runtime; a vector of kc ids for each claw
        rv.kc.claw_to_kc = compact  # len=num_claws

        # Build kc_to_claws: map of claw Ids for each KC.
        kc_to_claws = [[] for _ in range(N)]
        for claw_idx, kc_idx in enumerate(compact):
            kc_to_claws[int(kc_idx)].append(int(claw_idx))
        rv.kc.kc_to_claws = kc_to_claws

        # TODO add assertions checking kc_to_claws is correct?

    # TODO need to support int type too (and in all similar isinstance calls)?
    # isinstance(<int>, float) is False
    if fixed_thr is not None and not isinstance(fixed_thr, float):
        mp.kc.use_vector_thr = True

        assert len(fixed_thr.shape) == 1
        # TODO necessary? not sure (run test_vector_thr again after finishing vector
        # fixed_thr support -> try to see if required)
        thr = np.expand_dims(fixed_thr, 1)
        #thr = fixed_thr

        rv.kc.thr = thr
        del thr

    # TODO TODO support vector wAPLKC (+ separately specifying float wKCAPL there?
    # or deduce which elements haven't been boosted?) (mainly want to support boosting)
    if wAPLKC is not None:
        assert target_sparsity_factor_pre_APL is None
        assert fixed_thr is not None, 'for now, assuming both passed if either is'

        mp.kc.tune_apl_weights = False

        # TODO test this isn't broken for the use_connectome_APL_weights=True case
        # (doesn't seem to be...) (and even need it there? also test w/o it, after
        # getting working)
        if wKCAPL is None:
            wKCAPL = wAPLKC / mp.kc.N
        #

        if not use_connectome_APL_weights:
            # NOTE: min/max for these should all be the same. they are essentially
            # scalars, at least as tuned before
            # rv.kc.wKCAPL.shape=(1, 1630)
            # rv.kc.wKCAPL.max()=0.002386503067484662
            # rv.kc.wAPLKC.shape=(1630, 1)
            # rv.kc.wAPLKC.max()=3.8899999999999992 
            if _wPNKC_one_row_per_claw: 
                print("rv.kc.wAPLKC declared here")
                

                rv.kc.wAPLKC = np.ones((compact.size, 1)) * wAPLKC
                rv.kc.wKCAPL = np.ones((1, compact.size)) * wKCAPL
                print("rv.kc.wAPLKC size: ", compact.size)
            else: 
                rv.kc.wAPLKC = np.ones((mp.kc.N, 1)) * wAPLKC
                rv.kc.wKCAPL = np.ones((1, mp.kc.N)) * wKCAPL

            # TODO try setting wAPLKC = 1 (or another reasonable constant), and only
            # vary wKCAPL? (also considering adding an olfsysm param to vary ratio
            # between the two, as mentioned in another comment)
            # (or probably vice versa, where wKCAPL = 1 / mp.kc.N, and wAPLKC varies)

        # TODO save/print APL activity (timecourse?) to check it's reasonable?
        # (but it's non-spiking... what is reasonable?)

    if pn2kc_connections in connectome_options or _wPNKC is not None:
        # if `_wPNKC is not None`, its contents were already copied into wPNKC above
        rv.kc.wPNKC = wPNKC

    wAPLKC_scale = None
    wKCAPL_scale = None
    if use_connectome_APL_weights:
        if wAPLKC is not None:
            assert wKCAPL is not None

            # NOTE: expected a single float passed in here, interpret as in same manner
            # as w[APLKC|KCAPL]_scale floats output by prior calls
            assert isinstance(wAPLKC, float)
            assert isinstance(wKCAPL, float)

            # TODO add additional kwargs, to allow setting and/or scaling only one of
            # these at at time (would also want to change block above setting
            # mp.kc.preset_w[APLKC|KCAPL] above)?
            wAPLKC_scale = wAPLKC
            wKCAPL_scale = wKCAPL

            rv.kc.wAPLKC_scale = wAPLKC_scale
            rv.kc.wKCAPL_scale = wKCAPL_scale

        if not _wPNKC_one_row_per_claw:
            for_kc_types = kc_types
        else:
            for_kc_types = claw_index.get_level_values(KC_TYPE)

        wAPLKC, wKCAPL = connectome_APL_weights(connectome=connectome, wPNKC=wPNKC,
            kc_types=for_kc_types, kc_to_claws=kc_to_claws, plot_dir=plot_dir
        )

        if not _wPNKC_one_row_per_claw:
            wAPLKC = wAPLKC / wAPLKC.mean()
            wKCAPL = wKCAPL / wKCAPL.mean()

        assert wAPLKC.index.equals(wKCAPL.index)
        if not _wPNKC_one_row_per_claw:
            assert wPNKC.index.equals(wAPLKC.index)
        else:
            # TODO check wAPLKC index against claw_index? (maybe after dropping some
            # levels from one or the other?)

            # TODO delete?
            assert len(wPNKC) == len(wAPLKC)

        # (min is 1 for both of these)
        # ipdb> wAPLKC.max()
        # 38.0
        # ipdb> wKCAPL.max()
        # 27.0

        warn(f'scaling {connectome=} wAPLKC & wKCAPL, each to mean of 1')

        wAPLKC_arr = np.expand_dims(wAPLKC.values, 1)
        if _wPNKC_one_row_per_claw:
            assert wAPLKC_arr.shape == (len(kc_ids_per_claw), 1)
        else:
            assert wAPLKC_arr.shape == (mp.kc.N, 1)
        rv.kc.wAPLKC = wAPLKC_arr.copy()

        wKCAPL_arr = np.expand_dims(wKCAPL.values, 0)
        if _wPNKC_one_row_per_claw:
            assert wKCAPL_arr.shape == (1, len(kc_ids_per_claw))
        else:
            assert wKCAPL_arr.shape == (1, mp.kc.N)
        rv.kc.wKCAPL = wKCAPL_arr.copy()

        n_zero_input_wAPLKC = (wAPLKC == 0).sum()
        n_zero_input_wKCAPL = (wKCAPL == 0).sum()
        input_wAPLKC = wAPLKC.copy()
        input_wKCAPL = wKCAPL.copy()

    # TODO implement (+ delete similar comment above if so)
    # TODO TODO restore this assertion? still relevant for multiresponder_APL_boost
    # block that exists below now? test w/o connectome APL weights?
    """
    if not use_connectome_APL_weights:
        assert multiresponder_APL_boost is None, 'not supported'
    """

    # TODO need delete=False?
    temp_log_file = NamedTemporaryFile(suffix='.olfsysm.log', delete=False)

    # also includes directory (e.g. '/tmp/tmp5lhlb2n0.olfsysm.log')
    temp_log_path: str = temp_log_file.name
    try:
        # it seems to just append to this file, if it already exists (should no longer
        # an issue now that I'm making temp files)
        rv.log.redirect(temp_log_path)

    # TODO just `raise` (/ remove try/except)? shouldn't need to support olfsysm
    # versions this old anymore
    #
    # just so i can experiment w/ reverting to old olfsysm, before i added this
    except AttributeError:
        pass

    if print_olfsysm_log is None:
        # TODO add new verbose kwarg in here (put all unconditional prints inside there
        # too)
        print_olfsysm_log = al_util.verbose

    if print_olfsysm_log:
        print(f'writing olfsysm log to {temp_log_path}')

    # for i, arr in enumerate(rv.orn.sims):
    #     print(f"Shape of array at index {i}: {arr.shape}")
    osm.run_ORN_LN_sims(mp, rv)

    osm.run_PN_sims(mp, rv)
    before_any_tuning = time.time()

    # This is the only place where build_wPNKC and fit_sparseness are called, and they
    # are only called if the 3rd parameter (regen=) is True.

    # Something happened here.. possibly because of how wAPLKC size didn't match up?
    # There should be some mechanism to translate use_connectome_APL weights into olfsysm.

    # spatial_wPNKC = True ->wPNKC_one_claw_per_row
    # we want the argument to be True to equal to the row set as KC;
    osm.run_KC_sims(mp, rv, True)

    tuning_time_s = time.time() - before_any_tuning

    # TODO is it all zeros after the n_hallem odors?
    # TODO do responses to first n_hallem odors stay same after changing sim_only and
    # re-running below?
    # Of shape (n_kcs, n_odors). odors as columns, as elsewhere.
    responses = rv.kc.responses.copy()
    responses_after_tuning = responses.copy()

    # TODO clarify whether this is just from stim_start:stim_end
    # (bit hard to tell from quick look at olfsysm. possible this is over all time
    # points...? that might not be what i want...).
    #
    # ok, well at least these are true (from hemibrain run on megamat data):
    # ipdb> spike_recordings[:, :, :stim_start_idx].sum()
    # 0.0
    # ipdb> spike_recordings[:, :, stim_end_idx:].sum()
    # 2.0
    #
    # yes, it does seem (the 2) spikes after stim_end_idx are also counted
    # ipdb> spike_counts.sum().sum()
    # 5468.0
    # ipdb> spike_recordings.sum()
    # 5468.0
    spike_counts = rv.kc.spike_counts.copy()

    # TODO if tune_apl_weights=False, assert wAPLKC/wKCAPL (and *_scale counterparts,
    # for preset_*=True cases) do not change from initialization to end?
    # TODO also check we aren't *too* far off in homeostatic_thrs case (when current
    # call may not have it True, but using vector thr from such a call)
    #
    # could be True even if `target_sparsity is None` (if olfsysm default of 0.1 is
    # used), but scalar fixed_thr/wAPLKC/wKCAPL should not be passed then
    if mp.kc.tune_apl_weights:
        # TODO assert that things mentioned in comment above are actually None (or
        # vector, not scalar, for at least fixed_thr)?

        if len(mp.kc.tune_from) > 0:
            # mp.kc.tune_from is an empty list if not explicitly set
            sp_actual = responses[:, mp.kc.tune_from].mean()
        else:
            sp_actual = responses.mean()

        # NOTE: if this fails, may want to check if
        # (rv.kc.tuning_iters == mp.kc.max_iters)
        # (and increase if needed [/ add a check we haven't reached max_iters])
        #
        # matt's tuning loop runs while:
        # (abs(sp - p.kc.sp_target) > (p.kc.sp_acc * p.kc.sp_target)
        abs_sp_diff = abs(sp_actual - mp.kc.sp_target)
        rel_sp_diff = abs_sp_diff / mp.kc.sp_target

        # TODO raise some kind of convergence failure error instead?
        # NOTE: do not remove this assertion
        # if use_connectome_APL_weights == False:
        #     import ipdb; ipdb.set_trace() 

        print("rel_sp_diff: ", rel_sp_diff)
        # assert rel_sp_diff <= mp.kc.sp_acc, (f'{rel_sp_diff=} > {mp.kc.sp_acc=}'
        #     f'\n{sp_actual=}\n{mp.kc.sp_target=}'
        # )

        del sp_actual, abs_sp_diff, rel_sp_diff

    if variable_n_claws:
        assert mp.kc.seed == seed

        wPNKC = rv.kc.wPNKC.copy()
        # TODO should these not also be the case in variable_n_claws == False case?
        # move these two assertions out?
        assert wPNKC.shape[1] == len(glomerulus_index)
        assert len(wPNKC) == len(responses)

        # TODO don't define from responses.index (that's just a default range index w/
        # name KC_ID anyway) (-> move earlier -> define kc_types from wPNKC index
        # -> define all other KC indices from that)
        wPNKC = pd.DataFrame(data=wPNKC, columns=glomerulus_index)
        # TODO move KC ID col def to a central place (-> prob rename to 'kc_id' after)
        wPNKC.index.name = KC_ID
        print("wPNKC pd.Datafram passed")


    # TODO skip this re-adding if i change above to not drop kc_type level from wPNKC
    # index? any code in between that would actually err w/o the dropping?
    if kc_types is not None:
        assert not kc_types.isna().any()

        # TODO move this outside of these conditionals?
        assert KC_TYPE not in kc_index.names

        if not variable_n_claws:
            # TODO need to special case? just always use to_frame()/etc?
            if len(kc_index.names) > 1:
                for_index = kc_index.to_frame(index=False)
                for_index[KC_TYPE] = kc_types
                kc_index = pd.MultiIndex.from_frame(for_index)
            else:
                kc_index = pd.MultiIndex.from_arrays([kc_index, kc_types])

            assert KC_TYPE in kc_index.names

        if not _wPNKC_one_row_per_claw:
            wPNKC.index = kc_index
        # KC_type was not dropped from claw_index

    # TODO TODO maybe correlate spont_in against raw (or claw) PN->KC weight for that
    # glomerulus? any better than (Caron-wPNKC-based) 3B/C point in ann's preprint?
    # maybe use average PN->KC weight per-glomerulus to fill in missing spont_in values
    # (for glomeruli not in hallem)?
    try:
        # line that would trigger the AttributeError
        spont_in = rv.kc.spont_in.copy()

    # to allow trying older versions of olfsysm, that didn't have rv.kc.spont_in
    # (which is what this would be doing, if i WAS still `pass`-ing instead of
    # `raise`-ing below)
    except AttributeError:
        # was previously just `pass`-ing here, but don't think i need to support this
        # again moving forward.
        raise

    type2target_response_rate = None
    if fixed_thr is not None:
        # this currently only works by adjusting thresholds per type, so can't have any
        # kind of prespecified thresholds
        assert not equalize_kc_type_sparsity

        # TODO need to support int type too (in both of the two isinstance calls below)?
        # isinstance(<int>, float) is False
        #
        # just checking what we set above hasn't changed
        if isinstance(fixed_thr, float):
            assert mp.kc.fixed_thr == fixed_thr

        assert mp.kc.add_fixed_thr_to_spont == True
        # actually do need this (or else what? it's tuned?). may or may not need
        # thr_type='fixed' too
        assert mp.kc.use_fixed_thr == True
        assert mp.kc.thr_type == 'fixed'
        # TODO some assertion w/ spont_in here? should we be able to calculate fixed_thr
        # same way?

    elif not homeostatic_thrs:
        thr = rv.kc.thr

        unique_thrs_and_counts = pd.Series((thr - 2*spont_in).squeeze()).value_counts()
        unique_fixed_thrs = unique_thrs_and_counts.index
        # TODO try min/max instead of value w/ max count? any possibility of
        # avoiding the numerical issue causing this?
        # TODO take this kind of strategy by default for _single_unique_val?
        # seems we couldn't use current implementation of that here
        # (but haven't proven that this strategy is an improvement...)
        #
        # pick one w/ biggest count (assuming that is least likely to have been affected
        # by numerical issues...). values are the counts (w/ largest count at -1).
        # index contains the thresholds.
        #
        # this should correspond to the thr_const variable inside
        # olfsysm.choose_KC_thresh_uniform (and can be set by passing as the fixed_thr
        # kwarg to this function, which will also set mp.kc.add_fixed_thr_to_spont=True)
        fixed_thr = unique_thrs_and_counts.sort_values().index[-1]
        # TODO TODO TODO bypass probably rest of this conditional in
        # homeostatic_thrs=True case (or above too...)
        assert np.allclose(fixed_thr, unique_fixed_thrs)

        # TODO put behind verbose kwarg (/delete)
        print(f'fixed_thr: {fixed_thr}')

        # TODO move below into a unit test (that also hardcodes
        # tune_apl_weights=False)? can i use it to figure out if there's a strategy than
        # can consistently pick which of numerically-slightly-diff thresholds to use to
        # exactly recreate what responses would have been pre-APL?
        #
        # ***w/ mp.kc.tune_apl_weights hardcoded above rv def to False*** :
        # ipdb> np.array_equal(pks >= unique_fixed_thrs.max(), responses)
        # True
        #
        # ipdb> (pks > unique_fixed_thrs.min()).mean()
        # 0.20003214400514305
        # ipdb> (pks >= unique_fixed_thrs.min()).mean()
        # 0.20003214400514305
        #
        # ipdb> unique_fixed_thrs.min()
        # 256.8058676548658
        # ipdb> unique_fixed_thrs.max()
        # 256.8058676548659
        pks = pd.DataFrame(data=rv.kc.pks, index=kc_index, columns=tuning_odor_index)
        print("pks pd.Datafram passed")


        # TODO summarize+delete most of comment block below
        #
        # ipdb> pks.stack().iloc[:, 0].quantile(q=[0, 0.2, 0.5, 0.8, 1])
        # 0.0    -228.153484
        # 0.2       9.505707
        # 0.5     113.635038
        # 0.8     256.812860
        # 1.0    1232.700436
        # Name: megamat, dtype: float64
        # ipdb> pks.stack().iloc[:, 0].sort_values()
        # kc_id       kc_type  odor
        # 415852518   g        aa @ -3       -228.153484
        # 5813020132  g        B-cit @ -3    -211.070698
        # 5812981441  g        2-but @ -3    -191.946836
        # 415852518   g        va @ -3       -191.910623
        # 5812982766  g        2-but @ -3    -182.479178
        #                                       ...
        # 693500652   g        eb @ -3        970.448394
        #                      2h @ -3        971.923691
        #                      1-6ol @ -3    1122.538275
        #                      IaA @ -3      1184.759164
        #                      pa @ -3       1232.700436
        #
        # ipdb> pks.stack().squeeze().quantile(q=1 - mp.kc.sp_target *
        #    mp.kc.sp_factor_pre_APL, interpolation='higher')
        # 256.84082743722297
        # ipdb> fixed_thr
        # 256.8058676548658
        # ipdb> pks.stack().squeeze().quantile(
        #    q=1 - mp.kc.sp_target * mp.kc.sp_factor_pre_APL, interpolation='lower')
        # 256.80586765486584
        # ipdb> mp.kc.sp_target * mp.kc.sp_factor_pre_APL
        # 0.2
        # ipdb> lower = pks.stack().squeeze().quantile(q=1 - mp.kc.sp_target *
        #    mp.kc.sp_factor_pre_APL, interpolation='lower')
        # ipdb> higher = pks.stack().squeeze().quantile(q=1 - mp.kc.sp_target *
        #    mp.kc.sp_factor_pre_APL, interpolation='higher')
        # ipdb> (pks >= lower).mean()
        # panel    odor
        # megamat  2h @ -3       0.350273
        #          IaA @ -3      0.276503
        #          pa @ -3       0.343169
        #          2-but @ -3    0.208743
        #          eb @ -3       0.289617
        #          ep @ -3       0.248634
        #          aa @ -3       0.045902
        #          va @ -3       0.110929
        #          B-cit @ -3    0.009836
        #          Lin @ -3      0.055191
        #          6al @ -3      0.248087
        #          t2h @ -3      0.249727
        #          1-8ol @ -3    0.142077
        #          1-5ol @ -3    0.301093
        #          1-6ol @ -3    0.329508
        #          benz @ -3     0.156831
        #          ms @ -3       0.034426
        # dtype: float64
        # ipdb> (pks >= lower).mean().mean()
        # 0.20003214400514305
        # ipdb> (pks > lower).mean().mean()
        # 0.19999999999999998
        # ipdb> (pks > higher).mean().mean()
        # 0.19996785599485697
        # ipdb> (pks >= higher).mean().mean()
        # 0.19999999999999998
        pks = pks.stack(pks.columns.names).squeeze()
        assert isinstance(pks, pd.Series)

        # olfsysm defaults: mp.kc.sp_target=0.1, mp.kc.sp_factor_pre_APL=2.0
        target_response_rate_pre_apl = mp.kc.sp_target * mp.kc.sp_factor_pre_APL

        # TODO delete (/ turn into tests).
        # almost entire purpose of this was to justify my interpolation method was
        # consistent w/ how threshold was calculated inside olfsysm.
        """
        #interpolation_for_thr = 'midpoint'
        # fails sooner than 'lower' (w/ >=)?
        #interpolation_for_thr = 'higher'
        # initially this seemed right (w/ >=). now it seems inconsistent? maybe that's
        # the best i can do?
        #interpolation_for_thr = 'lower'
        for interpolation_for_thr in ('lower', 'higher'):

            # NOTE: updating from pandas 1.3.1 to 1.5.0 seemed to fix a DeprecationWarning
            # here (about interpolation= being replaced w/ method=, despite all pandas
            # versions seemingly using interpolation= for Series.quantile). numpy==1.24.4
            fixed_thr2 = pks.quantile(q=1 - target_response_rate_pre_apl,
                interpolation=interpolation_for_thr
            )

            # TODO delete
            print()
            print(f'{interpolation_for_thr=} (to define fixed_thr2)')
            print()
            print(f'{fixed_thr=}')
            print(f'{fixed_thr2=}')
            print()
            print(f'{(pks >= fixed_thr).equals(pks >= fixed_thr2)=}')
            print(f'{(pks > fixed_thr).equals(pks > fixed_thr2)=}')
            print()
            #

            #print(pd.Series((thr - 2*spont_in).squeeze()).value_counts())
            # 195.742763    821
            # 195.742763    508
            # 195.742763    501
            #
            #print(pd.Series((thr - 2*spont_in).squeeze()).value_counts().index)
            # Float64Index([195.7427633158587, 195.74276331585867, 195.74276331585872],
            #   dtype='float64')
            #
            # ipdb> pd.Series((thr - 2*spont_in).squeeze()).max()
            # 195.74276331585872
            # ipdb> pd.Series((thr - 2*spont_in).squeeze()).min()
            # 195.74276331585867
            #print()

            # TODO TODO unit test taking selected fixed_thr, setting that into olfsysm
            # fixed_thr, and re-running model (or running equiv new model) ->
            # checking/verifying which one reproduces output spike_counts exactly?
            #
            # TODO delete (try to move to unit test)
            #mp.kc.use_fixed_thr = True
            #mp.kc.thr_type = 'fixed'
            #mp.kc.add_fixed_thr_to_spont = True
            #mp.kc.tune_apl_weights = False

            #mp.kc.fixed_thr = fixed_thr2
            ## looks like i do need regen=True to get thr change to take effect
            #osm.run_KC_sims(mp, rv, True)
            #spike_counts2 = rv.kc.spike_counts.copy()
            #print(f'{np.array_equal(spike_counts, spike_counts2)=}')
            #print()

            for fthr in sorted(unique_fixed_thrs):
                print(f'{fthr=}')
                print(f'{unique_thrs_and_counts[fthr]=}')
                print(f'{(pks >= fthr).equals(pks >= fixed_thr2)=}')
                print(f'{(pks > fthr).equals(pks > fixed_thr2)=}')

                #mp.kc.fixed_thr = fthr
                # looks like i do need regen=True to get thr change to take effect
                #osm.run_KC_sims(mp, rv, True)
                #spike_counts2 = rv.kc.spike_counts.copy()
                # TODO TODO why was this always true despite thresholding on pks being
                # different (for diff choice of threshold)?
                #print(f'{np.array_equal(spike_counts, spike_counts2)=}')

                print()

            # so at least we can actually get diff output for different-enough
            # fixed_thr...
            #
            # ipdb> mp.kc.fixed_thr
            # 195.74276331585872
            # ipdb> mp.kc.fixed_thr = 195.7
            # ipdb> osm.run_KC_sims(mp, rv, True)
            # ipdb> spike_counts2 = rv.kc.spike_counts.copy()
            # ipdb> print(f'{np.array_equal(spike_counts, spike_counts2)=}')
            # np.array_equal(spike_counts, spike_counts2)=False

            import ipdb; ipdb.set_trace()
            #
            #

        #assert np.isclose(fixed_thr, fixed_thr2)
        try:
            # TODO i can't assert it's exactly equal can i? aren't i just picking a
            # value from a list tho? why can i not get it exact?
            assert np.isclose(fixed_thr, fixed_thr2)
        except AssertionError:
            warn(f'{fixed_thr=} != {fixed_thr2=}')
            # TODO TODO TODO why broken now (sometimes?)?
            # ipdb> fixed_thr
            # 268.0375322649455
            # ipdb> fixed_thr2
            # 268.0081239925118
            import ipdb; ipdb.set_trace()

        # TODO TODO try other interpolation methods (+ combos w/ other choices? what?)?
        # maybe i picked the wrong approach?
        #
        # TODO delete?
        #
        # seems this will also fail if above fails
        #assert (pks >= fixed_thr).equals(pks >= fixed_thr2)
        try:
            # TODO TODO restore?
            #assert (pks >= fixed_thr).equals(pks >= fixed_thr2)
            #
            assert (pks > fixed_thr).equals(pks > fixed_thr2)
        # TODO TODO TODO fix
        except AssertionError:
            warn(f'fixed_thr and fixed_thr2 produce diff thresholded pks!!!')
            import ipdb; ipdb.set_trace()
        """
        #

        interpolation_for_thr = 'lower'
        # TODO also compute this in fixed_thr branch above, and use to save a
        # parameter for what the target_sparsity_factor_pre_APL should be?
        # (does olfsysm even compute pks in that case? might not...)
        # (when stepping thr and wAPLKC separately will likely lead to values != 2)
        fixed_thr2 = pks.quantile(q=1 - target_response_rate_pre_apl,
            interpolation=interpolation_for_thr
        )

        # TODO also assert we can recreate responses by using this threshold?
        # (prob more important) (would need to be in a context where responses don't
        # have APL used to compute them tho)

        # TODO do something with this? at least put in param dict
        #
        # "reponse_rate" same units/meaning as "target_sparsity", but better name
        pre_apl_response_rate = (pks >= fixed_thr2).mean().mean()

        # TODO in future, could add a param that's a type->target_rate dict, but would
        # be more complicated(/longer) in filenames and stuff, so some extra
        # clutter/complexity (already have such a dict below. would just need to expose
        # it as a new kwarg)

        # TODO TODO i think if i want a certain response rate at output, i really might
        # have to modify olfsysm to run the APL tuning probably jointly on all types...

        if equalize_kc_type_sparsity:
            # TODO need to support int type too (in both of the two isinstance calls
            # below)? isinstance(<int>, float) is False
            #
            # if we already had vector thresholds, then they won't be particularly
            # meaningful after we overwrite those outputs with those using cell_thrs
            # below.
            assert fixed_thr is None or isinstance(fixed_thr, float)
            assert not mp.kc.use_vector_thr

            # probably don't care to implement this, but would need to rethink current
            # ordering of olfsysm calls if so
            if tune_on_hallem:
                raise NotImplementedError

            # to compare against the output of the call that will happen below this
            # conditional (before and after attempt at equalizing KC response rates)
            print('response rates BEFORE attempting to equalize pre-APL response rates'
                ' across KC types:'
            )
            pre_responses = pd.DataFrame(responses, index=kc_index, columns=odor_index)
            print("pre_responses pd.Datafram passed")
            if extra_orn_deltas is not None:
                # this subset of odors is not tuned, so we don't care about it here
                # (and as a result values seem not even properly initialized here)
                pre_responses = pre_responses.drop(columns=extra_orn_deltas.columns)

            _print_response_rates(pre_responses)

            print()

            kc_type_set = set(kc_types)
            type2target_response_rate = {
                t: r for t, r in
                zip(sorted(kc_type_set), [mp.kc.sp_target] * len(kc_type_set))
            }
            if ab_prime_response_rate_target is not None:
                assert 0 <= ab_prime_response_rate_target <= 1

                # otherwise, either we have the wrong input data or the "a'b'" KCs are
                # called something else.
                assert "a'b'" in type2target_response_rate

                type2target_response_rate["a'b'"] = ab_prime_response_rate_target

            # kc_type
            # a'b'       213.766788
            # ab         247.624665
            # g          304.647391
            # unknown    150.569856
            # Name: megamat, dtype: float64
            #
            # x.name will be a str kc_type
            thr_by_type = pks.groupby(KC_TYPE).apply(lambda x: x.quantile(
                # TODO see how the final rates of each class differ after tuning
                q=1 - type2target_response_rate[x.name] * mp.kc.sp_factor_pre_APL,
                interpolation=interpolation_for_thr
            ))

            # TODO TODO TODO add support for sensitivity analysis in this case?
            cell_thrs = kc_types.map(thr_by_type)

            # TODO also include thr_by_type in param_dict?

            # TODO keep this print (/warn) for a verbose branch?
            print('thr_by_type:')
            print(thr_by_type.to_string())

            # TODO check that these thresholds (if APL is skipped) produce
            # sp-factor * type-target in each type?

            mp.kc.use_vector_thr = True
            mp.kc.add_fixed_thr_to_spont = True
            # actually do need this. may or may not need thr_type='fixed' too
            mp.kc.use_fixed_thr = True
            mp.kc.thr_type = 'fixed'

            # TODO either use a different type or otherwise fix formatting of this into
            # params.csv and related (currently show up w/ middle values truncated, like
            # `[1 2 3 ... 98 99 100]`)
            #
            # overwriting fixed_thr since otherwise it is the float scalar threshold
            # value from *before* picking a threshold for each subtype (to "equalize"
            # the response rate across subtypes), so no longer really meaningful.
            fixed_thr = cell_thrs.values.copy()

            # TODO necessary? not sure (run test_vector_thr again after finishing vector
            # fixed_thr support -> try to see if required)
            thr = np.expand_dims(fixed_thr, 1)
            #thr = fixed_thr

            rv.kc.thr = thr

            # TODO TODO probably also expose the whole type->thr (/fraction) dict below,
            # as does seem (for some reason...) we will need to tweak gamma-KC response
            # fraction up (after APL brings it down to 0.07, below 0.1 target)
            # (under which circumstances did it do this again? connectome APL?)
            #
            # TODO expose this as kwarg? does =False actually make sense?
            retune_apl_post_equalized_thrs = True

            if use_connectome_APL_weights:
                # TODO duplicate (/refactor to share) assertions below on output
                # wAPLKC/wKCAPL (so that we can also check here before overwriting
                # them)?
                # TODO could also change olfsysm so rv.kc.w[APLKC|KCAPL] store the
                # unscaled versions? not sure i care to though.
                #
                # since current rv.kc.w[APLKC|KCAPL] matrices are scaled by the
                # corresponding rv.kc.w[APLKC|KCAPL]_scale scalars before
                # osm.fit_sparseness returns, we need to restart them at a mean of 1
                # before re-scaling, so that the *_scale variables are interpretable
                # in the same manner.
                #
                # TODO check that these values are then scaled by the (still updated)
                # rv.kc.w[APLKC|KCAPL]_scale vars (inside fit_sparseness)
                # TODO assert w[APLKC|wKCAPL]_scale != (default of) 1?
                rv.kc.wAPLKC = wAPLKC_arr
                rv.kc.wKCAPL = wKCAPL_arr
            #

            if not retune_apl_post_equalized_thrs:
                mp.kc.tune_apl_weights = False

            checks = True
            # TODO move/dupe these checks to a unit test
            if checks:
                # TODO check that another run_KC_sims call before changing rv gives us
                # same outputs? prob not worth it...

                # NOTE: .copy() is necessary
                old_spike_counts = spike_counts.copy()

                osm.run_KC_sims(mp, rv, False)
                spike_counts_type_thresh = rv.kc.spike_counts.copy()
                assert not np.array_equal(old_spike_counts, spike_counts_type_thresh,
                    # need equal_nan=True b/c NaN for extra_orn_deltas odors, if any
                    # (b/c those odors are excluded from tuning, and only run in a later
                    # step)
                    equal_nan=True
                )

                # TODO compare to a recursive fit_mb_model call output (passing
                # fixed_thr=thr (or cell_thrs.values, if having already adding singleton
                # dim at end is an issue w/ fixed_thr [which it very well could be, esp
                # since another one will probably get added in recursive call])?
                # TODO how to get all kwargs nicely tho? refactor this fn to pass them
                # all as a dict (basically just to make recursive calls easier)? would
                # come at the cost of having them all explicitly in kwargs tho, unless
                # maybe i broke out a separate fn to initialize the defaults, w/ all
                # kwargs there?

                osm.run_KC_sims(mp, rv, False)
                spike_counts_type_thresh2 = rv.kc.spike_counts.copy()
                assert np.array_equal(
                    spike_counts_type_thresh, spike_counts_type_thresh2, equal_nan=True
                )

            osm.run_KC_sims(mp, rv, True)
            # TODO also exclude any extra_orn_deltas odors here? above?
            # (the values are garbage, yes, b/c sim_only excludes them)
            responses = rv.kc.responses.copy()
            spike_counts = rv.kc.spike_counts.copy()

            # just for check in extra_orn_deltas case below
            responses_after_tuning = responses.copy()

            if checks:
                assert not np.array_equal(spike_counts, old_spike_counts,
                    equal_nan=True
                )
                assert not np.array_equal(spike_counts, spike_counts_type_thresh2,
                    equal_nan=True
                )

            wPNKC2 = rv.kc.wPNKC.copy()
            assert np.array_equal(wPNKC, wPNKC2)

            spont_in2 = rv.kc.spont_in.copy()
            assert np.array_equal(spont_in, spont_in2)

            del thr, spont_in2, wPNKC2

    else:
        assert homeostatic_thrs
        fixed_thr = rv.kc.thr.squeeze().copy()

        # ideally so this works w/ another call w/ add_fixed_thr_to_spont=True, as other
        # vector fixed_thr outputs. necessary b/c of different handling in olfsysm.
        # test_homeostatic_thrs confirms this is correct.
        fixed_thr = fixed_thr - 2 * spont_in.squeeze()

    if extra_orn_deltas is not None:
        # TODO add unit test to confirm (some way of) simming just last bit is equiv to
        # re-simming all and subsetting to last bit (then replace code that re-sims all
        # w/ code that just sims extra odors)
        # TODO maybe just sim the last bit and concat to existing responses,
        # instead of re-running all (check equiv tho)
        #mp.sim_only = range(n_input_odors, n_input_odors + n_extra_odors)
        mp.sim_only = range(n_input_odors + n_extra_odors)

        osm.run_ORN_LN_sims(mp, rv)
        osm.run_PN_sims(mp, rv)
        # Don't want to do either build_wPNKC or fit_sparseness here (after tuning)
        osm.run_KC_sims(mp, rv, False)

        responses = rv.kc.responses.copy()
        spike_counts = rv.kc.spike_counts.copy()

        assert np.array_equal(
            responses_after_tuning[:, :n_input_odors], responses[:, :n_input_odors]
        )

    if tune_on_hallem and not hallem_input:
        assert (responses[:, n_hallem_odors:] == 0).all()

        # TODO also assert in here that sim_odors is None or sim_odors == odor_index?
        # (or move that assertion, which should be somewhere above, outside other
        # conditionals)

        mp.sim_only = range(n_hallem_odors,
            n_hallem_odors + n_input_odors + n_extra_odors
        )

        osm.run_ORN_LN_sims(mp, rv)
        osm.run_PN_sims(mp, rv)

        # Don't want to do either build_wPNKC or fit_sparseness here (after tuning)
        osm.run_KC_sims(mp, rv, False)

        responses = rv.kc.responses.copy()
        spike_counts = rv.kc.spike_counts.copy()

        assert np.array_equal(
            responses_after_tuning[:, :n_hallem_odors], responses[:, :n_hallem_odors]
        )

        # TODO also test where appended stuff has slightly diff number of odors than
        # hallem (maybe missing [one random/first/last] row?)
        responses = responses[:, n_hallem_odors:]
        spike_counts = spike_counts[:, n_hallem_odors:]
    #

    # TODO TODO check this multiresponder_APL_boost path also works in
    # use_connectome_APL_weights=False case. (add to unit test, if not already there)
    # (+ probably support if not)
    #
    # TODO TODO modify so we can pass vector wAPLKC, and move this earlier?
    # (may even work to have passed vector wAPLKC take place of connectome_wAPLKC
    # outputs, where it is scaled to mean of 1 and then scaled via wAPLKC_scale)
    # (had initially tried this boost pre-tuning, but didn't get it working there.
    # commented block with that code exists in first commit w/ multiresponder_APL_boost)
    #
    # NOTE: currently need to implement in all final calls (after any pre-tuning calls),
    # since we don't have a way to pass vector wAPLKC into subsequent calls. this is
    # somewhat limiting (can't actually tune overall response rate w/ these boosted
    # wAPLKC values).
    if multiresponder_APL_boost is not None:
        if _multiresponder_mask is None:
            # NOTE: just assuming we want to union all the per-panel masks in this dir
            # (as long as this branch is only hit in the pre-tuning on control+kiwi
            # data, that should be ok)
            mask_dir = Path(
                '~/src/natmix_data/pdf/scaled_model_versions/final_scaling'
            ).expanduser()

            mask_paths = list(mask_dir.glob('multiresponder_*.p'))
            assert len(mask_paths) == 2

            mask = pd.Series(index=wAPLKC.index, data=False)
            # TODO TODO compare multiresponders across panels
            # (+ plot clustering of responses across both panels?)
            for mask_path in mask_paths:
                panel_mask = pd.read_pickle(mask_path).droplevel(KC_TYPE)
                assert mask.index.names == panel_mask.index.names
                # indices can differ b/c cells were already dropped in natmix_data, so
                # we can't directly union the Series
                mask[panel_mask[panel_mask].index] = True

                # TODO TODO warn about how many cells we have for each, how many
                # overlap, and how many we have at the end
        else:
            mask = _multiresponder_mask

        # TODO assert index of mask matches something else?

        # TODO or delete all these None defs, and define these + print whether we are
        # boosting each specific var or not?
        mask_mean_wAPLKC_before = None
        nonmask_mean_wAPLKC = None
        mask_mean_wAPLKC_after = None

        mask_mean_wKCAPL_before = None
        nonmask_mean_wKCAPL = None
        mask_mean_wKCAPL_after = None

        boosting_wAPLKC = False
        boosting_wKCAPL = False
        #

        wAPLKC_arr = rv.kc.wAPLKC.copy()

        # for boost_wKCAPL=True, both wAPLKC and wKCAPL are boosted.
        # for boost_wKCAPL=False, only wAPLKC boosted.
        if boost_wKCAPL in (False, True):
            if boost_wKCAPL == False:
                vars_being_boosted = 'wAPLKC (NOT wKCAPL)'
            else:
                vars_being_boosted = 'wAPLKC AND wKCAPL'
                boosting_wKCAPL = True

            boosting_wAPLKC = True

            mask_mean_wAPLKC_before = wAPLKC_arr[mask].mean()
            nonmask_mean_wAPLKC = wAPLKC_arr[~mask].mean()

            wAPLKC_arr[mask] *= multiresponder_APL_boost

            mask_mean_wAPLKC_after = wAPLKC_arr[mask].mean()
            rv.kc.wAPLKC = wAPLKC_arr
        else:
            assert boost_wKCAPL == 'only'
            vars_being_boosted = 'ONLY wKCAPL (not wAPLKC)'
            boosting_wKCAPL = True

        if boost_wKCAPL in (True, 'only'):
            wKCAPL_arr = rv.kc.wKCAPL.copy()

            assert wKCAPL_arr.shape[0] == 1 and len(wKCAPL_arr.shape) == 2
            assert len(wAPLKC_arr) == wKCAPL_arr.shape[1]

            mask_mean_wKCAPL_before = wKCAPL_arr[:, mask].mean()
            nonmask_mean_wKCAPL = wKCAPL_arr[:, ~mask].mean()

            wKCAPL_arr[:, mask] *= multiresponder_APL_boost

            mask_mean_wKCAPL_after = wKCAPL_arr[:, mask].mean()

            rv.kc.wKCAPL = wKCAPL_arr

        warn(f'scaling {vars_being_boosted} by {multiresponder_APL_boost=} for '
            f'{mask.sum()} cells (hack to try to remove multi-responders)!'
        )

        mp.kc.tune_apl_weights = False

        osm.run_KC_sims(mp, rv, False)

        spike_counts_before = spike_counts.copy()

        responses = rv.kc.responses.copy()
        spike_counts = rv.kc.spike_counts.copy()

        boost_msg = f'boosting multiresponder {vars_being_boosted}:\n'
        # TODO move boost_msg def above, and remove boosting_w[APLKC|KCAPL] vars (only
        # used for this)?
        if boosting_wAPLKC:
            boost_msg += (
                f' mean non-multiresponder wAPLKC:    {nonmask_mean_wAPLKC:.3f}\n'
                f' mean multiresponder wAPLKC before: {mask_mean_wAPLKC_before:.3f}\n'
                f' mean multiresponder wAPLKC after:  {mask_mean_wAPLKC_after:.3f}\n'
            )
        if boosting_wKCAPL:
            boost_msg += (
                f' mean non-multiresponder wKCAPL:    {nonmask_mean_wKCAPL:.3f}\n'
                f' mean multiresponder wKCAPL before: {mask_mean_wKCAPL_before:.3f}\n'
                f' mean multiresponder wKCAPL after:  {mask_mean_wKCAPL_after:.3f}\n'
            )
        #

        # TODO turn some of this into (also?) assertions (/tests? happy w/ tests
        # as-is?) (that responses actually decreased in class w/ wAPLKC boosted, as long
        # as it wasn't just wKCAPL that was boosted)?
        warn(boost_msg +

            ' total multiresponder spikes before:     '
                f'{spike_counts_before[mask.values].sum()}\n'

            ' total non-multiresponder spikes before: '
                f'{spike_counts_before[~mask.values].sum()}\n'

            ' total multiresponder spikes after:      '
                f'{spike_counts[mask.values].sum()}\n'

            ' total non-multiresponder spikes after:  '
                f'{spike_counts[~mask.values].sum()}'
        )

        del (vars_being_boosted, spike_counts_before, nonmask_mean_wAPLKC,
            mask_mean_wAPLKC_after, mask_mean_wAPLKC_before, nonmask_mean_wKCAPL,
            mask_mean_wKCAPL_after, mask_mean_wKCAPL_before, boosting_wAPLKC,
            boosting_wKCAPL, wAPLKC_arr
        )
    #

    # want this to be after last olfsysm call
    temp_log_file.close()

    # TODO replace w/ wrappers for each osm call, that prints right after each call?
    # (or some combined approach?) (seeing these outputs interleaved w/ python debug
    # prints would prob make some debugging easier)
    # TODO or read lines after each call, and only print new ones? (so we can still have
    # one master log too, if we want that...)
    if print_olfsysm_log:
        print('olfsysm log:')
        log_txt = Path(temp_log_path).read_text()
        cprint(log_txt, 'light_yellow')

    # TODO warn that we aren't copying log, if plot_dir is None?
    if plot_dir is not None:
        # TODO fix/delete. encountering again from uniform model repro test (w/
        # n_seeds=2) (well, was before checking log instead of plot dir. also not force
        # making plots in variable_n_claws=True case now)
        # TODO delete
        # TODO replace _seen_plot_dirs+usage w/ copy2/to_txt wrapper that will check for
        # me whether we have already to this path?
        #assert plot_dir not in _seen_plot_dirs
        #

        # shutil.copy2 will fail anyway if this doesn't exist, but the error message is
        # a bit less clear
        assert plot_dir.is_dir()

        if not variable_n_claws:
            olfsysm_log = plot_dir / 'olfsysm_log.txt'
        else:
            # TODO want to make separate plot subdirs for seeds rather than just
            # suffixing log file? or just skip all the other outputs?
            olfsysm_log = plot_dir / f'olfsysm_log.seed{seed}.txt'

        assert olfsysm_log not in _seen_olfsysm_logs

        # TODO need to take care to not overwrite if -c/-C? (shouldn't be a huge deal
        # either way. this should mainly be for debugging while something is actively
        # changing anyway)

        # will overwrite `dst`, if it already exists.
        shutil.copy2(temp_log_path, olfsysm_log)

        _seen_olfsysm_logs.add(olfsysm_log)
        # TODO delete
        #_seen_plot_dirs.add(plot_dir)

    Path(temp_log_path).unlink()

    if not use_connectome_APL_weights:
        # these should either be the same as any hardcoded (scalar) wAPLKC [+ wKCAPL]
        # inputs, or the values chosen by the tuning process. _single_unique_val will
        # raise AssertionError if the input arrays contain more than one unique value.
        # For wAPLKC (column vector, shape Nx1)
        # Make an array where each index `kc` maps to its compartment

        # just to try things out;
        # delete afterwards
        np.set_printoptions(precision=6, suppress=False)
        # now slices will print with 6 decimal places
        if not _wPNKC_one_row_per_claw: 
            rv_scalar_wAPLKC = _single_unique_val(rv.kc.wAPLKC)
            rv_scalar_wKCAPL = _single_unique_val(rv.kc.wKCAPL)

        if wAPLKC is not None:
            # TODO delete? just checking what we set above hasn't changed
            assert mp.kc.tune_apl_weights == False

                # assert rv_scalar_wAPLKC == wAPLKC

            # this should now be defined whenever wAPLKC is, whether passed in or not...
            assert wKCAPL is not None
            if not _wPNKC_one_row_per_claw: 
                assert rv_scalar_wKCAPL == wKCAPL
        else:
            if not _wPNKC_one_row_per_claw: 
                # TODO delete prints? (at least put behind a verbose kwarg)
                print(f'wAPLKC: {rv_scalar_wAPLKC}')
                print(f'wKCAPL: {rv_scalar_wKCAPL}')
                #
                wAPLKC = rv_scalar_wAPLKC
                wKCAPL = rv_scalar_wKCAPL
            else:
                wAPLKC = rv.kc.wAPLKC
                wKCAPL = rv.kc.wKCAPL
    else:
        # TODO delete if i can get both of these (+ wPNKC) to preserve kc_type level, if
        # wPNKC ever has it (currently just hemibrain)
        #
        # TODO why does it seem kc_type has already been dropped from the .index of each
        # of these? just don't do that (rather than adding it back)
        # (would need to stat by not dropping it from wPNKC, which is then passed to
        # connectome_APL_weights(). could prob then remove separate kc_types= kwarg to
        # that fn)
        kc_ids = kc_index.get_level_values(KC_ID)
        if not _wPNKC_one_row_per_claw:
            # TODO TODO maybe these should be asserting against kc_index instead of
            # kc_ids? (or at least w[APLKC|KCAPL].index.get_level_values(KC_ID)?)
            assert kc_ids.equals(wAPLKC.index)
            assert kc_ids.equals(wKCAPL.index)

            assert kc_ids.equals(input_wAPLKC.index)
            assert kc_ids.equals(input_wKCAPL.index)
            apl_weight_index = kc_index
        else:
            apl_weight_index = claw_index

        input_wAPLKC.index = apl_weight_index
        input_wKCAPL.index = apl_weight_index
        #

        # TODO (outside this fn?) make histograms of these scaled values somewhere,
        # similar histograms of connectome weights?
        # TODO any point copying here?
        wAPLKC = pd.Series(index=apl_weight_index, data=rv.kc.wAPLKC.squeeze())
        wKCAPL = pd.Series(index=apl_weight_index, data=rv.kc.wKCAPL.squeeze())

        n_zero_tuned_wAPLKC = (wAPLKC == 0).sum()
        n_zero_tuned_wKCAPL = (wKCAPL == 0).sum()
        # might need to update olfsysm tuning to avoid adding extra zeros in these
        # vectors, if it ever does
        # TODO warn if either scale is 0 (should only encounter w/ sensitivity analysis
        # sweep, and only as steps are currently configured, where 0 is the lower
        # bound)?
        if wAPLKC_scale is not None and wAPLKC_scale > 0:
            assert n_zero_input_wAPLKC == n_zero_tuned_wAPLKC

        if wKCAPL_scale is not None and wKCAPL_scale > 0:
            assert n_zero_input_wKCAPL == n_zero_tuned_wKCAPL

        # TODO only do this if we didn't already have wAPLKC_scale/wKCAPL_scale defined
        # (not None) before this? or check output against those pre-existing vars
        # separately, if we have them?
        wAPLKC_scale = rv.kc.wAPLKC_scale
        wKCAPL_scale = rv.kc.wKCAPL_scale

        # TODO TODO TODO just move the APL boosting after this conditional?
        # TODO TODO TODO fix + restore
        print('fix me')
        '''
        # do need exact=False on both of these calls (first call doesn't always trip w/o
        # it, but there still are cases where it does)
        wAPLKC_scale_recomputed = _single_unique_val(
            wAPLKC[input_wAPLKC > 0] / input_wAPLKC[input_wAPLKC > 0], exact=False
        )
        try:
            assert np.isclose(wAPLKC_scale, wAPLKC_scale_recomputed)
        # TODO TODO TODO fix
        # TODO or just relax this assertion? (but under what circumstances? seems
        # use_connectome_APL_weights=True & retune_apl_post_equalized_thrs=False)
        except AssertionError:
            print()
            print(f'{wAPLKC_scale=}')
            print(f'{wAPLKC_scale_recomputed=}')
            import ipdb; ipdb.set_trace()
        #

        wKCAPL_scale_recomputed = _single_unique_val(
            wKCAPL[input_wKCAPL > 0] / input_wKCAPL[input_wKCAPL > 0], exact=False
        )
        assert np.isclose(wKCAPL_scale, wKCAPL_scale_recomputed)
        '''


    assert responses.shape[1] == (n_input_odors + n_extra_odors)
    responses = pd.DataFrame(responses, index=kc_index, columns=odor_index)
    print("responses pd.Datafram passed")

    assert spike_counts.shape[1] == (n_input_odors + n_extra_odors)
    assert len(responses) == len(spike_counts)
    spike_counts = pd.DataFrame(spike_counts, index=kc_index, columns=odor_index)
    print("spike_counts pd.Datafram passed")

    if extra_orn_deltas is not None:
        extra_responses = responses.iloc[:, -n_extra_odors:]

        if 'panel' in extra_responses.columns.names:
            extra_responses = extra_responses.droplevel('panel', axis='columns')

        old_eb = responses.iloc[:, :-n_extra_odors].loc[:, eb_mask]
        if 'panel' in responses.columns.names:
            old_eb = old_eb.droplevel('panel', axis='columns')

        assert old_eb.shape[1] == 1
        old_eb = old_eb.iloc[:, 0]

        eb_idx = -1

        new_eb = extra_responses.iloc[:, eb_idx]
        assert new_eb.name.startswith('eb @')

        assert new_eb.equals(old_eb)

        # just removing eb, so there won't be that duplicate, which could cause some
        # problems later (did cause some of the plotting code in here to fail i think).
        # doesn't matter now that we know new and old are equal.
        responses = responses.iloc[:, :eb_idx].copy()
        spike_counts = spike_counts.iloc[:, :eb_idx].copy()

        # TODO delete? am i not removing 'eb' now anyway?
        '''
        if make_plots:
            # causes errors re: duplicate ticklabels in some of the orn_deltas plots
            # currently (would need to remove 'eb' from all of those plots, but also
            # prob want to remove all extra_orn_deltas odors for them. still need to
            # keep in returned responses tho)
            warn('fit_mb_model: setting make_plots=False since not currently supported '
                'in extra_orn_deltas case'
            )
        # TODO restore? needed to keep this true to test some code below
        # (in _plot_example_dynamics, but also interaction w/ this case)
        #make_plots = False
        '''

    spont_in = pd.Series(index=kc_index, data=spont_in.squeeze())

    param_dict = {
        'fixed_thr': fixed_thr,

        # still want these here in the use_connectome_APL_weights=True case?
        # (yes, but they will be popped from output and serialized separately in that
        # case, like kc_spont_in always is. they would otherwise interfere w/ how i'm
        # currently formatted + saving params into CSVs). They are also saved as
        # separate pickles when they are popped.
        'wAPLKC': wAPLKC,
        'wKCAPL': wKCAPL,

        'kc_spont_in': spont_in,
    }

    # NOTE: currently will probably not be able to achieve these after APL tuning
    # (until olfsysm is modified to tune within subtypes), but (if not None) per-type
    # thresholds will be picked to achieve sparsities here scaled by
    # mp.kc.sp_factor_pre_APL (default=2.0).
    if equalize_kc_type_sparsity:
        assert type2target_response_rate is not None
        param_dict['type2target_response_rate'] = type2target_response_rate

        # both of these should also be defined if equalize_kc_type_sparsity=True
        param_dict['type2thr'] = thr_by_type.to_dict()
        param_dict['retune_apl_post_equalized_thrs'] = retune_apl_post_equalized_thrs

    if use_connectome_APL_weights:
        assert wAPLKC_scale is not None and wKCAPL_scale is not None
        param_dict.update({'wAPLKC_scale': wAPLKC_scale, 'wKCAPL_scale': wKCAPL_scale})

    tuning_dict = {
        # TODO expose at least these first two (sp_acc, max_iters) as kwargs.
        # prob also sp_lr_coeff.
        # TODO TODO + maybe default to smaller tolerance (+ more iterations if
        # needed). what currently happens if tolerance not reached in max_iters?
        # add my own assertion (in this script) that we are w/in sp_acc?
        #
        # parameters relevant to model threshold + APL tuning process
        # default=0.1 (fraction +/- sp_target)
        'sp_acc': mp.kc.sp_acc,

        # default=10
        'max_iters': mp.kc.max_iters,

        'sp_lr_coeff': mp.kc.sp_lr_coeff,
        'apltune_subsample': mp.kc.apltune_subsample,

        # should be how many iterations it took to tune,
        'tuning_iters': rv.kc.tuning_iters,

        # removed tuning_time_s from this, because it would cause -c checks to fail
    }
    # TODO still do in some cases where fixed_thr is a vector?
    if fixed_thr is None:
        print('tuning parameters:')
        pprint(tuning_dict)
        print('tuning time: {tuning_time_s:.1f}s')
        print()

    param_dict = {**param_dict, **tuning_dict}

    # TODO put prints below behind a verbose flag? (this whole conditional basically)
    _print_response_rates(responses)

    # TODO can i not just assert this now?
    if KC_TYPE in responses.index.names:
        n_kcs_by_type = responses.index.get_level_values(KC_TYPE).value_counts()

        silent_kcs = (responses == 0).T.all()
        silent_frac_by_type = silent_kcs.groupby(KC_TYPE).sum() / n_kcs_by_type
        # TODO still (at least if verbose) print this (one number) if no type
        print()
        print('silent_frac_by_type:')
        print(silent_frac_by_type.to_string())
        print()

        # TODO check that if i use uniform/whatever instead of hemibrain wPNKC, this
        # bias favoring heavily responsive gamma KCs goes down?
        # TODO TODO should wPNKC be set in a way that normalizes within type, to
        # avoid this bias introduced? or should i address it in some other way instead?
        # in a separate step than what i end up using to implement the Inada paper a'/b'
        # vs other cell type responsiveness (which might just be threshold in their
        # paper?)
        # TODO TODO should i test that i can actually use non-int wPNKC now?

    # TODO why is this seemingly a list of arrays, while the equiv kc variable seems to
    # be an array immediately? binding code seems similar...

    orn_sims = np.array(rv.orn.sims)
    # orn_sims.shape=(110, 22, 5500)
    # also a list out of the box
    # pn_sims.shape=(110, 22, 5500)
    pn_sims = np.array(rv.pn.pn_sims)

    if tune_on_hallem and not hallem_input:
        orn_sims = orn_sims[n_hallem_odors:]
        pn_sims = pn_sims[n_hallem_odors:]

        if _plot_example_dynamics:
            # TODO also subset other dynamics vars, at least if we are gonna return them
            # (or use them for _plot_example_dynamics)?
            raise NotImplementedError('prob need to subset those vars below')

    # orn_sims is of shape (n_odors, n_glomeruli, n_timepoints)
    n_samples = orn_sims.shape[-1]
    assert pn_sims.shape[-1] == n_samples
    # from default parameters:
    # p.time.pre_start  = -2.0;
    # p.time.start      = -0.5;
    # p.time.end        = 0.75;
    # p.time.stim.start = 0.0;
    # p.time.stim.end   = 0.5;
    # p.time.dt         = 0.5e-3;
    assert (n_samples * mp.time_dt) == (mp.time_end - mp.time_pre_start)
    assert (mp.time_pre_start < mp.time_start < mp.time_stim_start < mp.time_stim_end <
        mp.time_end
    )

    ts = pd.Series(name='seconds',
        data=np.linspace(mp.time_pre_start, mp.time_end, num=n_samples)
    )

    # time_start = "start of KC stimulation" [from spont PN activity]
    # (it's before stimulus comes on at time_stim_start)
    start_idx = np.searchsorted(ts, mp.time_start)
    stim_start_idx = np.searchsorted(ts, mp.time_stim_start)
    stim_end_idx = np.searchsorted(ts, mp.time_stim_end)

    if return_dynamics or _plot_example_dynamics:
        # TODO rename (+ move rv to param) -> move out of fit_mb_model? just to
        # declutter this fn...
        def _get_sim_var(name) -> np.ndarray:
            # all appear as #-odor-length lists w/o np.array(...) applied
            arr = np.array(getattr(rv.kc, name))

            _debug = False
            if not _debug:
                return arr

            print(f'{name=}')

            # this should be a vector of length equal to #-timepoints
            all0 = (arr == 0).all(axis=(0,1))

            # NOTE: only not true for nves_sims, which isn't all 0 anywhere
            # (it's all 1 everywhere. prob disabled. see below.)
            #print(f'{all0[:(start_idx + 1)].all()=}')
            # only vm_sims has this as False (excluding nves_sims)
            # (others still all 0 at +3 too)
            #print(f'{all0[:(start_idx + 2)].all()=}')

            # TODO use this (to get mean/min/max/etc within)?
            after_start = arr[:, :, start_idx:]
            # TODO also print min/max/mean/[np.quantile 0.5] for each?
            # maybe only within non-zero part? and/or only within stim window?

            if all0.any():
                first_non_all0_idx = np.argwhere(~all0)[0][0]
                print(f'{first_non_all0_idx=}')

                # last index all 0
                last_all0_idx = np.argwhere(all0)[-1][0]
                print(f'{last_all0_idx=}')

                all0_to_last = (arr[:, :, :(last_all0_idx + 1)] == 0).all()
                print(f'{all0_to_last=}')
            else:
                print('not all0 anywhere!')
            print()

            return arr

        # TODO which of these are all 0 before stim_start_idx?
        #
        # these first 3 are of shape (#-odors, #-KCs, #-timepoints)
        #
        # "Membrane voltage"
        vm_sims = _get_sim_var('vm_sims')

        # presumably 0/1 recording which time bins have spikes in them?
        spike_recordings = _get_sim_var('spike_recordings')
        # this assertion takes a sec (put behind a checks flag?)
        assert set(spike_recordings.flat) == {0, 1}

        # this has been 0 by default my whole time working with the model. presumably
        # matt also decided pretty quickly to not use this, tho not sure why.
        #
        # I assume this is either not in Ann's model, or primarily not used there?
        # TODO TODO is this true? what might we get from adding this back in to the
        # model?
        #
        # if `mp.kc.ves_p == 0`, the "vesicle depletion" part of olfsysm is disabled
        if mp.kc.ves_p != 0:
            # "vesicle depletion factor"
            nves_sims = _get_sim_var('nves_sims')
            # this is probably  only the case if we get it when `mp.kc.ves_p != 0`,
            # which i haven't tested, and not sure we care to
            #assert (nves_sims == 1).all()
        else:
            warn('nves_sims are disabled, as has typically been the case for olfsysm')

        # these two are of shape (#-odors, 1, #-timepoints), with the length-1 component
        # removed by squeeze. both properties of scalar APL (hence 1 vs #-KCs).
        #
        # "APL potential" (mV?)
        inh_sims = _get_sim_var('inh_sims').squeeze()
        # "KC->APL synapse current"
        # TODO so this must be the current across all KCs, right?
        Is_sims = _get_sim_var('Is_sims').squeeze()

        # NOTE: just chose 'stim' for that dim name b/c xarray complained that
        # 'odor' overlapped with the odor_index level of the same name.
        #
        # wasn't also an issue with 'glomerulus' being the .name of
        # glomerulus_index, presumably b/c not multiple levels there.
        coords = {'stim': odor_index, 'time_s': ts}

        al_dims = ['stim', 'glomerulus', 'time_s']
        al_coords = {**coords, 'glomerulus': glomerulus_index}

        # TODO TODO fix:
        # (was probably b/c panel wasn't a level passed at that point?)
        # ValueError: coordinate stim has dimensions ('odor',), but these are not a subset of the DataArray dimensions ['stim', 'glomerulus', 'time_s']
        # (needed _plot_example_dynamics=True, from scripts/model_banana_iaa_concs.py)
        orn_sims = xr.DataArray(data=orn_sims, dims=al_dims, coords=al_coords)
        pn_sims = xr.DataArray(data=pn_sims, dims=al_dims, coords=al_coords)

        kc_dims = ['stim', 'kc', 'time_s']
        kc_coords = {**coords, 'kc': kc_index}
        vm_sims = xr.DataArray(data=vm_sims, dims=kc_dims, coords=kc_coords)
        spike_recordings = xr.DataArray(data=spike_recordings, dims=kc_dims,
            coords=kc_coords
        )
        if mp.kc.ves_p != 0:
            nves_sims = xr.DataArray(data=nves_sims, dims=kc_dims, coords=kc_coords)

        # may change if we end up having multiple APL compartments
        apl_dims = ['stim', 'time_s']
        apl_coords = coords

        inh_sims = xr.DataArray(data=inh_sims, dims=apl_dims, coords=apl_coords)
        Is_sims = xr.DataArray(data=Is_sims, dims=apl_dims, coords=apl_coords)

        if return_dynamics:
            dynamics_dict = {
                'orn_sims': orn_sims,
                'pn_sims': pn_sims,

                'inh_sims': inh_sims,
                'Is_sims': Is_sims,

                'vm_sims': vm_sims,
                'spike_recordings': spike_recordings,
            }
            if mp.kc.ves_p != 0:
                dynamics_dict['nves_sims'] = nves_sims

            assert not any(k in param_dict for k in dynamics_dict.keys())
            param_dict.update(dynamics_dict)
            # TODO TODO (delete? still relevant?) why is this not being run?

    if _plot_example_dynamics:
        # TODO remove make_plots part of this? (assuming i can't easily get those plots
        # to work w/ extra_orn_deltas, but i can easily get those to work w/ this)
        assert plot_dir is not None and make_plots
        assert plot_dir.exists(), f'{plot_dir=} did not exist'

        # TODO always plot whichever glomerulus has the biggest response (and say so)?
        # would make this code useful for more input data...
        # TODO work if DL5 not in input
        glom = 'DL5'
        dl5_idx = glomerulus_index.get_loc(glom)

        # TODO pick odor in a way that would work for all input data?
        #
        # will fail if input data doesn't have t2h (and probably also at this conc)
        odor_values = odor_index.get_level_values('odor')

        for odor in ('t2h @ -3', 'kmix0 @ 0'):
            if odor in odor_values:
                break

            # for if we don't find a match
            odor = None

        if odor is None:
            odor = odor_values[-1]
            warn(f'picking last odor {odor} for example dynamics plots')

        example_odor_idx = odor_values.get_loc(odor)

        # TODO TODO still keep one version of plot showing full timecourse, in case
        # understanding the ramp up ~"start" time (< "stim_start") is important?
        # (just set xlim differently and re-save?)

        # TODO factor out this plotting (so someone could run on saved dynamics
        # outputs)?

        # seem to need constrained layout to get fig.legend() reliably outside bounds of
        # Axes (at least w/o manual positioning...)?
        fig, (ax, spike_raster_ax) = plt.subplots(nrows=2, layout='constrained',
            sharex=True, figsize=(10, 10)
        )

        # TODO TODO finish
        #def _plot_normed()
        #

        # TODO make fn (/find a library for) plotting a stimlus bar along some time axis
        # (-> use that here instead)?
        #
        # used to have these are 'stim start' / 'stim end' in legend, but legend is
        # already too busy as-is.
        ax.axvline(mp.time_stim_start, color='k')
        ax.axvline(mp.time_stim_end, color='k')

        # TODO TODO is there some reason orn_sims.min() is not sfr.min()?
        # min seems to be 17, if i'm computing it right...
        # is it just that orn_sims is not in firing rate units?

        # TODO TODO refactor this normalized plotted
        #
        # TODO directly index odor/glom by name, now that we are using xarray?
        #
        # TODO add units for these (firing rate in Hz?) (via y-axis label?)
        #
        # units seems to be firing rates (absolute i think. actually, there are some
        # negative values, even in hallem_input=True [w/ matt config] case. that's not a
        # mistake though, is it?)
        ax.plot(ts, orn_sims[example_odor_idx, dl5_idx] /
            orn_sims[example_odor_idx, dl5_idx].max(), label=f'{glom} ORN'
        )
        ax.plot(ts, pn_sims[example_odor_idx, dl5_idx] /
            pn_sims[example_odor_idx, dl5_idx].max(), label=f'{glom} PN'
        )

        # TODO TODO TODO drop non-responding KCs before all plots using them
        # (both dynamics plots and whichever spike raster things i ultimately use)
        # TODO TODO also say in title (below) if we drop non-responders, if we do

        # plotting these before the KC mean[+types] now, since that part of the plot
        # can vary (in terms of # of lines), so having this earlier fixes the colors for
        # these
        ax.plot(ts, inh_sims[example_odor_idx] / inh_sims[example_odor_idx].max(),
            label='APL Vm'
        )
        ax.plot(ts, Is_sims[example_odor_idx] / Is_sims[example_odor_idx].max(),
            label='KC->APL current'
        )

        # TODO TODO or maybe i don't want to always drop non-responders from vm_sims
        # plots? at least have a version not dropping them? (would need to get indices
        # from determination on spike_recordings / example_odor_spikes anyway)

        # TODO TODO label plot with how many responders there are out of how many total
        # cells
        # TODO TODO per kc_type labels w/ how many silent in each? too noisy? separate
        # plot/something for that instead?
        # ipdb> example_odor_spikes[example_odor_spikes.T.sum() > 0].shape
        # (214, 5500)
        # ipdb> example_odor_spikes.shape
        # (1830, 5500)
        example_odor_spikes = spike_recordings[example_odor_idx].to_pandas()

        # TODO delete
        # TODO to what extent is this just a thing for t2h specifically? evident in mean
        # wPNKC connections from t2h responsive glomeruli?
        # ipdb> nonsilent_frac_by_type
        # kc_type
        # a'b'       0.041667
        # ab         0.049875
        # g          0.254902
        # unknown    0.050000
        # (from when silent_frac_by_type was defined from example_odor_spikes)
        #nonsilent_frac_by_type = 1 - silent_frac_by_type
        #

        # TODO maybe plot clusters? per cell-type clusters?
        # TODO or random sample a few and plot on axis by itself (w/ original scale. not
        # normalized)?
        example_odor_vm_sims = vm_sims[example_odor_idx]

        # taking mean over KCs, giving us a series of length equal to #-timepoints
        mean_vm_sims = example_odor_vm_sims.mean('kc')
        ax.plot(ts, mean_vm_sims / mean_vm_sims.max(), label='mean KC Vm')

        # TODO TODO make a version of all these plots w/ each quantity on a separate
        # facet (or at least, only those w/ comparable units sharing a facet), so that
        # axes can all have the right units

        # TODO TODO modify fit_mb_model to accept arbitrary wAPLKC/wKCAPL, like i
        # had for _wPNKC (-> use to play around w/ per-subtype scales from here)
        # (how equiv to code i've been adding to set thr by type? prob not? not sure i
        # need per-cell wAPLKC/wKCAPL once i get per-cell thr)
        # TODO or should the cell type variations happen by effectively scaling
        # spontaneous input to each cell (where fixed_thr currently added to that
        # anyway)? that feels much more likely to be equiv to just scaling the
        # thresholds/fixed_thr values per cell type... (scaling wPNKC could probably do
        # that?)
        # TODO TODO what was the issue with having a constant fixed_thr again (the
        # reason that ann/matt added to spontaneous firing rate)? ann explain in her
        # thesis / preprint?

        # TODO TODO TODO hline for threshold (per-KC, ofc)? to sanity check at least?
        # TODO TODO also for spont_in

        # could also use `example_odor_vm_sims.coords['kc'].to_index()`, which was
        # defined from `kc_index`, and should be equiv. not sure if there's a more
        # idiomatic xarray way to count these w/o converting to a pandas Index
        # ipdb> kc_index.to_frame(index=False)[KC_TYPE].value_counts()
        # ab         802
        # g          612
        # a'b'       336
        # unknown     80
        vm_sims_by_type = example_odor_vm_sims.groupby(KC_TYPE).mean()

        # normalizing to max of 1, as elsewhere
        vm_sims_by_type = vm_sims_by_type / vm_sims_by_type.max('time_s')
        kc_type_labels = [f'mean {x}-KC Vm' for x in vm_sims_by_type[KC_TYPE].values]

        # TODO TODO TODO make this plot again after trying to rescale a'/b' to be
        # relatively more effective at recruiting/etc APL (and also after dropping
        # silent KCs first, for both existing and rescaled-within-type version of plot)
        ax.plot(ts, vm_sims_by_type.T, label=kc_type_labels)

        # TODO TODO restore something like my spikes -> spike times -> sns.rugplot for
        # best responding cell (never committed, unfortunately), or just directly use
        # imshow/similar (like rastermap does), -> use to show spiking against
        # threshold/spont_in context for an example cell? or do that in separate plot(s)
        # specifically for it?

        # NOTE: plot_spike_rasters currently drops silent cells itself anyway
        # TODO but modify it to have it say somewhere how many it dropped?
        # or like a kwarg flag to enabled putting that info in y-label or something?
        plot_spike_rasters(example_odor_spikes, ax=spike_raster_ax)

        # applies to both ax and spike_raster_ax, b/c sharex=True above
        ax.set_xlim([-0.05, 0.7])
        ax.set_xlabel('time (s)')

        ax.set_ylabel('normalized response (max=1)')

        ax.set_title(f'{title}\nmodel {glom} (& downstream pop.) response to {odor}')
        fig.legend(loc='outside right center')

        # TODO move under model_internals stuff saved below?
        # TODO get ' @ ' from hong2p.olf?
        savefig(fig, plot_dir, f'model_dynamics_{odor.replace(" @ ", "_")}')

    # TODO so should i average starting a bit after stim start? seems it still take
    # a bit to peak. what did matt do?
    # in (DL5, t2h) case, PN peak is ~0.047, and ORN plateaus after ~0.077

    # TODO stim_end_idx + 1?
    orn_df = pd.DataFrame(index=odor_index, columns=glomerulus_index,
        data=orn_sims[:, :, stim_start_idx:stim_end_idx].mean(axis=-1)
    )
    pn_df = pd.DataFrame(index=odor_index, columns=glomerulus_index,
        data=pn_sims[:, :, stim_start_idx:stim_end_idx].mean(axis=-1)
    )
    print("orn_pn_df pd.Datafram passed")
    if extra_orn_deltas is not None:
        orn_df = orn_df.drop(index=extra_orn_deltas.columns)
        pn_df = pn_df.drop(index=extra_orn_deltas.columns)
    # TODO TODO also drop from orn_deltas? assertion failing below b/c not doing so
    # (or is that how they get returned? maybe just drop for purpose of assertion or
    # within whatever plotting, if important)

    if sim_odors is not None:
        # TODO have parse_odor_name return input (rather than current ValueError), if
        # input doesn't have '@' in it (or add in model_test.py r1 call that currently
        # is failing b/c of this)
        input_odor_names = {olf.parse_odor_name(x) for x in sim_odors}
    else:
        # TODO need to exclude extra_orn_deltas from this?
        # (given i'm checking subset below, prob fine. but COULD also prob exclude extra
        # odors, if that helps simplify code)
        input_odor_names = {
            olf.parse_odor_name(x) for x in odor_index.get_level_values('odor')
        }

    # TODO may want to discard some for some plots (e.g. in cases when input is not
    # hallem, but also has diagnostics / fake odors added in addition to megamat odors)?
    # (kinda like plots as is there actually, but may want to add lines to separate
    # megamat from rest?)
    #
    # OK if we have more odors (for Hallem input case, right?)
    megamat = len(megamat_odor_names - input_odor_names) == 0

    # print(f"megamat_odor_names = {megamat_odor_names}")
    # print(f"input_odor_names  = {input_odor_names}")

    del input_odor_names
    if megamat:
        # TODO assert 'panel' only megamat if we do have it?
        panel = None if 'panel' in orn_deltas.columns.names else 'megamat'

        if not hallem_input:
            # at least as configured now, this isn't doing anything.
            # TODO just assert that all of orn_deltas_pre_filling.index are still in
            # orn_deltas.index for now (commentin this)?
            orn_deltas_pre_filling = orn_deltas_pre_filling.loc[
                [g for g in orn_deltas_pre_filling.index if g in orn_deltas.index]
            ].copy()

            # TODO can i rely on panel already being there now? just remove all this
            # sorting? (or sort orn_deltas before, unconditionally)
            # (i assume it's not there when input is hallem?)
            # (but still want to sort when input is hallem, adding megamat, so all
            # megamat odors are first)

            orn_deltas_pre_filling = sort_odors(orn_deltas_pre_filling, panel=panel,
                warn=False
            )

            # TODO is it a problem that i'm now also only are only doing all below if
            # `not hallem_input`? (change any outputs in my main al_analysis.py
            # remy-paper analyses?) changed to fix impact of sorting on check in
            # model_test.py, but could also add kwarg to disable this sorting...

            orn_deltas = sort_odors(orn_deltas, panel=panel, warn=False)

            # TODO maybe only do this one on a copy we don't return? probably don't
            # really care if it's already sorted tho...
            # TODO even care to do this? if just for a corr diff thing, even need?
            responses = sort_odors(responses, panel=panel, warn=False)
            spike_counts = sort_odors(spike_counts, panel=panel, warn=False)

            orn_df = sort_odors(orn_df, panel=panel, warn=False)
            pn_df = sort_odors(pn_df, panel=panel, warn=False)
    else:
        # TODO delete if i modify below to also make plots for other panels
        # (replacing w/ sorting -> dropping levels for all these, as above)
        #
        # the only place these should all be used is in the plotting code below, which
        # currently only runs in `megamat == True` case
        del orn_deltas, orn_df, pn_df

    # TODO still want?
    if 'panel' in responses.columns.names:
        assert 'panel' in spike_counts.columns.names
        responses = responses.droplevel('panel', axis='columns')
        spike_counts = spike_counts.droplevel('panel', axis='columns')

    # TODO probably also do for other panels?
    #if plot_dir is not None and make_plots:
    if (plot_dir is not None and make_plots) and megamat:
        orn_df = orn_df.T
        pn_df = pn_df.T

        # TODO probably also a seperate plot including any hallem deltas tuned on (but
        # not in responses that would be returned). not that i actualy use that path
        # now...

        plot_dir = plot_dir / 'model_internals'
        plot_dir.mkdir(exist_ok=True)

        fig, _ = viz.matshow(sfr.to_frame(), xtickrotation='horizontal',
            **diverging_cmap_kwargs
        )
        savefig(fig, plot_dir, 'sfr')

        # TODO rename to be clear it's just orn/pn stuff?
        def _plot_internal_responses_and_corrs(subset_fn=lambda x: x, suffix='',
            **plot_kws):

            if extra_orn_deltas is not None:
                def _subset_fn(x):
                    try:
                        # will currently cause ValueError in some plotting calls below,
                        # if we don't drop (at least on megamat data, b/c eb is both in
                        # extra_orn_deltas and input odors there)
                        ret = x.drop(columns=extra_orn_deltas.columns)

                    except KeyError:
                        ret = x

                    return ret

                subset_fn = _subset_fn

            # TODO maybe subset these down to things that are still in
            # orn_deltas/sfr/wPNKC though?
            #
            # orn_deltas_pre_filling only defined in this case. otherwise, there
            # shouldn't really *be* any filling.
            if not hallem_input:
                orn_delta_prefill_corr = plot_responses_and_corr(
                    subset_fn(orn_deltas_pre_filling), plot_dir,
                    f'orn-deltas-prefill{suffix}', title=title, **plot_kws
                )
            else:
                orn_delta_prefill_corr = None

            # TODO also do orn_deltas + sfr?
            # (to see how that changes correlation)
            # TODO with and without filling? or just post filling?

            # TODO TODO why doesn't drop_nonhallem...=True
            # [and/or tune_on_hallem=True] not look better? try again? shouldn't input
            # not get correlated so much?
            # TODO TODO compare ORN correlations in that case (after dropping and
            # delta estimate) vs hallem correlations: to what extent are they different?
            # TODO TODO is it related to wPNKC handling? not returning to ~halfmat or
            # whatever if starting from hallem/hemibrain case?

            orn_delta_corr = plot_responses_and_corr(subset_fn(orn_deltas), plot_dir,
                f'orn-deltas{suffix}', title=title, **plot_kws
            )
            # hack to fix all iteams are single element data array
            if isinstance(orn_df.values[0,0], xr.DataArray):
                orn_corr = plot_responses_and_corr(subset_fn(orn_df.applymap(lambda x: x.item())), plot_dir,
                    f'orns{suffix}', title=title, **plot_kws
                )
                plot_responses_and_corr(subset_fn(pn_df.applymap(lambda x: x.item())), plot_dir, f'pns{suffix}',
                    title=title, **plot_kws
                )
            else:
                orn_corr = plot_responses_and_corr(subset_fn(orn_df), plot_dir,
                    f'orns{suffix}', title=title, **plot_kws
                )
                # not going to subtract pn corrs from kc corrs, so don't need return value
                plot_responses_and_corr(subset_fn(pn_df), plot_dir, f'pns{suffix}',
                    title=title, **plot_kws
                )

            # model KC corr + responses should be plotted externally. responses plotted
            # differently there too, clustering after dropping silent cells.
            return orn_delta_prefill_corr, orn_delta_corr, orn_corr

        # TODO TODO why in hallem_input cases do orn-deltas* outputs seem to be
        # pre-filling (and we have no separate orn-deltas_prefill* outputs). fix for
        # consistency?

        if hallem_input:
            def subset_sim_odors(df):
                # TODO delete? still necessary? seems we currently do this earlier
                if megamat:
                    df = sort_odors(df, panel='megamat', warn=False)
                #

                if sim_odors is None:
                    return df
                else:
                    return df.loc[:, [x in sim_odors for x in df.columns]]

            # assuming we won't be passing sim_odors for other cases (other than what?
            # which case is this? elaborate in comment), for now
            if sim_odors is not None:
                _plot_internal_responses_and_corrs(subset_fn=subset_sim_odors)

            # to compare to figures in ann's paper, where 110 odors are in hallem order
            def resort_into_hallem_order(df):
                # don't need to worry about panel level being present on odor_index, as
                # it never is in hallem_input case (only place this is used)
                return df.loc[:, odor_index]

            # TODO TODO are these not being generated in latest hallem_input call
            # (restoring hemibrain path)?
            orn_delta_prefill_corr, orn_delta_corr, orn_corr = \
                _plot_internal_responses_and_corrs(suffix='_all-hallem',
                    subset_fn=resort_into_hallem_order
                )

            if megamat:
                responses = resort_into_hallem_order(responses).copy()
                spike_counts = resort_into_hallem_order(spike_counts).copy()
        else:
            orn_delta_prefill_corr, orn_delta_corr, orn_corr = \
                _plot_internal_responses_and_corrs()

        # TODO plot distribution of spike counts -> compare to w/ ann's outputs

        if hallem_input:
            suffix = '_all-hallem'
        else:
            suffix = ''

        # NOTE: this should be the only time the model KC responses are used inside the
        # plotting this fn does (and thus, the only time this flag is relevant here).
        # still returning silent cells regardless, so stuff can make this decision
        # downstream of response caching.
        # TODO can i share silent cell handling w/ _plot_example_dynamics stuff that
        # also wants to drop silent KCs (might be tricky...)?
        if drop_silent_cells_before_analyses:
            title += _get_silent_cell_suffix(responses)
            model_kc_corr = drop_silent_model_cells(responses).corr()
            # drop_silent_model_cells should also work w/ spike count input
            spike_count_corr = drop_silent_model_cells(spike_counts).corr()
        else:
            model_kc_corr = responses.corr()
            spike_count_corr = spike_counts.corr()

        if extra_orn_deltas is not None:
            # TODO TODO why do we not seem to always still have them here?
            try:
                # TODO drop earlier on a copy of responses/spike_counts (still need to
                # return in main version of those variables)
                model_kc_corr = model_kc_corr.drop(index=extra_orn_deltas.columns
                    ).drop(columns=extra_orn_deltas.columns)
            except KeyError:
                pass

            try:
                spike_count_corr = spike_count_corr.drop(index=extra_orn_deltas.columns
                    ).drop(columns=extra_orn_deltas.columns)
            except KeyError:
                pass
            # TODO also need to drop from orn_delta_corr? anything else?

        # for sanity checking some of the diffs. should also be saving this outside.
        plot_corr(model_kc_corr, plot_dir, f'kcs_corr{suffix}', title=title)
        #
        # TODO also sanity check by extra plot_corr calls w/ orn_[delta_]corr
        # inputs (to check i'm using the right ones, etc)? should be exactly same as
        # orn-deltas_corr.pdf / orns_corr.pdf generated above.

        plot_corr(spike_count_corr, plot_dir, f'kcs_spike-count_corr{suffix}',
            title=title
        )

        if orn_delta_prefill_corr is not None:
            corr_diff_from_prefill_deltas = model_kc_corr - orn_delta_prefill_corr
            plot_corr(corr_diff_from_prefill_deltas, plot_dir,
                f'model_vs_orn-deltas-prefill_corr_diff{suffix}',
                title=title, xlabel=f'model KC - model ORN (deltas, pre-filling) corr'
            )

        # TODO keep the seperate versions comparing against orn-deltas vs average
        # of dynamic internal orns? actually ever diff?
        corr_diff_from_deltas = model_kc_corr - orn_delta_corr
        plot_corr(corr_diff_from_deltas, plot_dir,
            f'model_vs_orn-deltas_corr_diff{suffix}',
            title=title, xlabel=f'model KC - model ORN (deltas) corr'
        )

        corr_diff = model_kc_corr - orn_corr
        # the 'dyn' prefix is to differentiate from a plot saved in parent of plot_dir,
        # by other code.
        plot_corr(corr_diff, plot_dir, f'model_vs_dyn-orn_corr_diff{suffix}',
            title=title, xlabel=f'model KC - model ORN (avg of dynamics) corr'
        )

        if hallem_input:
            # TODO delete?
            #
            # for sanity checking some of the diffs. should also be saving this outside.
            model_kc_corr_only_megamat = subset_sim_odors(
                subset_sim_odors(model_kc_corr).T
            )
            plot_corr(model_kc_corr_only_megamat, plot_dir, 'kcs_corr', title=title)
            #

            spike_count_corr_only_megamat = subset_sim_odors(
                subset_sim_odors(spike_count_corr).T
            )
            plot_corr(spike_count_corr_only_megamat, plot_dir, 'kcs_spike-count_corr',
                title=title
            )

            # TODO also support subset_fn for plot_corr, rather than this kind of
            # subsetting?
            corr_diff_from_deltas_only_megamat = subset_sim_odors(
                subset_sim_odors(corr_diff_from_deltas).T
            )
            plot_corr(corr_diff_from_deltas_only_megamat, plot_dir,
                'model_vs_orn-deltas_corr_diff', title=title,
                xlabel=f'model KC - model ORN (deltas) corr'
            )

            corr_diff_only_megamat = subset_sim_odors(subset_sim_odors(corr_diff).T)
            plot_corr(corr_diff_only_megamat, plot_dir, 'model_vs_dyn-orn_corr_diff',
                title=title, xlabel=f'model KC - model ORN (avg of dynamics) corr'
            )

    # NOTE: currently doing after simulation, because i haven't yet implemented support
    # for tuning running on the full set of (hallem) odors, with subsequent simulation
    # running on a different set of stuff
    # TODO why checking sim_odors is not None if i'm just using hallem_sim_odors here?
    # this a mistake?
    if hallem_input and sim_odors is not None:
        assert all(x in responses.columns for x in hallem_sim_odors)
        # TODO delete (replace w/ setting up sim_only s.t. only hallem_sim_odors are
        # simulated)
        responses = responses[hallem_sim_odors].copy()
        spike_counts = spike_counts[hallem_sim_odors].copy()

        # TODO also print fraction of silent KCs here
        # (refactor that printing to an internal fn here)

        # TODO print out threshold(s) / inhibition? possible to summarize each? both
        # scalar? (may want to use these values from one run / tuning to parameterize
        # for more glomeruli / diff runs?)a

    # TODO TODO TODO try having multiple effective APLs? what are effects of calyx
    # APL vs lobe APL? do they both have meaningful effects and are they really best
    # thought of as decoupled?

    # TODO delete this (/ make it "private" w/ underscore prefix)?
    # TODO doc example of how to use these correctly?
    if return_olfsysm_vars:
        # NOTE: these objects not currently pickleable, and may (or may not) use a lot
        # of memory to keep them around.
        warn('also returning olfsysm vars in param dict! may need to avoid keeping '
            'references to too many of these objects. not supported by '
            'fit_and_plot_mb_model!'
        )
        # TODO TODO work?
        param_dict['mp'] = mp
        param_dict['rv'] = rv

    # TODO also return model if i can make it pickle-able (+ verify that. it's possible,
    # but not likely, that it can already be [de]serialized)
    #
    # TODO maybe in wPNKC index name clarify which connectome they came from (or
    # something similarly appropriate for each type of random draws)
    return responses, spike_counts, wPNKC, param_dict


# NOTE: this does control n_seeds used in calls made from model_mb_responses (currently
# explicitly referenced in most entries in model_kw_list), but does not currently set
# the default n_seeds for fit_and_plot_mb_model
# TODO change other code that uses this to compute # seeds rather than using this
# hardcoded value? currently may not get expected outputs sometimes
N_SEEDS = 100
# TODO just add cli flag for this, at this point?
# (for testing code faster, in a way that includes n_seeds > 1 model cases)
#N_SEEDS = 3

# TODO TODO and re-run whole script once implemented for those 2 (to compare
# sd / ('ci',95) / ('pi',95|50) for each)
#
# relevant for # odors vs fraction of KCs (response breadth) plot, as well
# as ORN vs KC correlation scatterplot.
#
# currently also used to show error across flies in plot_n_odors_per_cell
# (those plots will also have model seed errors shown in separate lines)
#
# +/- 1 SD (~68% of data, if normal. ('sd', 2) should be ~95% if normal).
# this should be same as ('sd', 1), if i understand docs correctly.
#seed_errorbar = 'sd'
#
# NOTE: trying this again 2025-04-14 to see if Betty likes it now for fig 3B.
# IQR (i.e. 25th - 75th percentile)
# TODO TODO TODO special case this one for 3B (similar to how i have a separate param
# for 2E), if they go with it
# TODO TODO how do they like this one for 3B?
#seed_errorbar = ('pi', 50)
#
# TODO restore? for things other than 3B at least?
seed_errorbar = ('ci', 95)

# was at B'c request to make new 2E versions using ('ci', 95), taking the first 20
# (/100) seeds.
#
# TODO TODO TODO update paper methods. only mention in fig2E legend that it was first 20
# seeds, and remove sentence about subsetting to first 20 seeds from end of that methods
# section
# TODO TODO wait, which have i been using? what are current paper plots using:
# (pretty sure all plots say in title if they are only using first 20 seeds, and only 2E
# says that in modeling.svg)
# - 3B?
# - S1C?
# - S1D?
# - validation/megamat sparsity plots?
# NOTE: fig 2E has this configured separately (via `fig2e_n_first_seeds`, currently 20)
# TODO clarify. not sure yet if she wants me to handle other seed_errorbar plots
# this way too... (don't think we do)
# TODO (still want to revert? idk... only if betty asks) revert to 20 (but maybe ignore
# for 3B scatterplots [and S1C?])
#n_first_seeds_for_errorbar = 20
n_first_seeds_for_errorbar = None

# TODO warn for anything using n_first_seeds other than module-level
# n_first_seeds_for_errorbar (have enough context for meaningful message? inspect?)?
# TODO also explain (in another line of text?) what seed=('pi', 50) means (+ maybe
# similar confusing ones). ('pi', 50) means "percentile interval" for 25th - 75th
# percentiles.
def _get_seed_err_text_and_fname_suffix(*, errorbar=seed_errorbar,
    n_first_seeds=n_first_seeds_for_errorbar):

    if errorbar is None:
        fname_suffix = ''
    elif type(errorbar) is not str:
        fname_suffix = f'_{"-".join([str(x) for x in errorbar])}'
    else:
        fname_suffix = f'_{errorbar}'

    # for use in plot titles / similar
    err_text = f'errorbar={errorbar}'

    if n_first_seeds is not None:
        fname_suffix += f'_{n_first_seeds}first-seeds-only'
        err_text += (f'\nonly analyzing first {n_first_seeds}/{N_SEEDS} '
            'seeds'
        )

    return err_text, fname_suffix


seed_err_text, seed_err_fname_suffix = _get_seed_err_text_and_fname_suffix()

# TODO factor to hong2p.util
# TODO use in other places that do something similar?
# TODO use monotonic / similar dynamic attributes if input is an appropriate pandas
# type (e.g. Index. is Series?)?
def is_sequential(data) -> bool:
    # works with np.ndarray input (and probably also pandas Series)
    #
    # NOTE: will not currently work w/ some other things I might want to use it on
    # (e.g. things that don't have  .min()/.max() methods)
    return set(range(data.min(), data.max() + 1)) == set(data)


def select_first_n_seeds(df: pd.DataFrame, *,
    n_first_seeds: Optional[int] = n_first_seeds_for_errorbar) -> pd.DataFrame:

    # assuming this function simply won't be called otherwise
    assert n_first_seeds is not None

    # assuming this fn only called on data w/ seed information (either as a column or
    # row index level)
    if 'seed' in df.columns:
        seed_vals = df.seed
    else:
        assert 'seed' in df.index.names
        seed_vals = df.index.get_level_values('seed')

    warn(f'subsetting model data to first {n_first_seeds} seeds!')

    first_n_seeds = seed_vals.sort_values().unique()[:n_first_seeds]
    assert seed_vals.min() == first_n_seeds.min() and is_sequential(first_n_seeds)

    # NOTE: not copy-ing. assuming caller won't try to mutate output w/o manually
    # .copy()-ing it first.
    subset = df[seed_vals.isin(first_n_seeds)]

    # TODO use # of seeds actually in df instead of N_SEEDS?
    #
    # wouldn't play nice if there were ever e.g. a diff number of cells per seed, but
    # that's not how it is now. this assertion isn't super important though, just a
    # sanity check.
    assert np.isclose(len(subset) / len(df), min(n_first_seeds, N_SEEDS) / N_SEEDS)

    return subset


def plot_n_odors_per_cell(responses, ax, *, ax_for_ylabel=None, title=None,
    label='# odors per cell', label_suffix='', color='blue', linestyle='-',
    log_yscale=False) -> None:

    # TODO say how many total cells (looks like 1630 in halfmat model now?)

    # 'stim' is what Remy binary responses currently has
    # 'odor' seems to be what I get from my saved responses pickles
    assert responses.columns.name in ('odor1', 'stim', 'odor')

    n_odors = responses.shape[1]

    n_odors_col = 'n_odors'
    frac_responding_col = 'frac_responding_to_n_odors'

    # need the +1 on stop to be inclusive of n_odors
    # (so we can have a bin for cells that respond to 0 odors, as well as bin for
    # cells that respond to all 110 odors)
    n_odor_index = pd.RangeIndex(0, (n_odors + 1), name=n_odors_col)

    lineplot_kws = dict(
        # TODO refactor to share (subset of) these w/ other plots using seed_errorbar?
        #
        # like 'white' more than 'None' for markerfacecolor here.
        marker='o', markerfacecolor='white', linestyle=linestyle, legend=False,
        ax=ax
    )

    label = f'{label}{label_suffix}'

    def _n_odors2frac_per_cell(n_odors_per_cell):
        # TODO delete sort_index? prob redundant since i'm reindexing below...
        #
        # this will be ordered w/ silent cells first,
        # cells responding to 1 odor 2nd, ...
        n_odors_per_cell_counts = n_odors_per_cell.value_counts().sort_index()
        # TODO delete? made irrelevant by reindex below (prob)?
        n_odors_per_cell_counts.name = n_odors_col

        # .at[0] raising a KeyError should have the same interpretation
        assert n_odors_per_cell_counts.at[0] > 0, ('plot would be wrong if input '
            'already had silent cells dropped'
        )

        assert n_odors_per_cell.sum() == (
            (n_odors_per_cell_counts.index * n_odors_per_cell_counts).sum()
        )

        # shouldn't really need .fillna(0), b/c either 0/NaN shouldn't show up in
        # (currently log scaled) plots.
        # TODO may want to keep anyway, in case i want to try switching off log scale?
        n_odors_per_cell_counts = n_odors_per_cell_counts.reindex(n_odor_index
            ).fillna(0)

        assert n_odors_per_cell_counts.sum() == len(n_odors_per_cell)

        frac_responding_to_n_odors = n_odors_per_cell_counts / len(n_odors_per_cell)
        frac_responding_to_n_odors.name = frac_responding_col

        # (was 0.9999999999999999 in some cases)
        assert np.isclose(frac_responding_to_n_odors.sum(), 1)

        return frac_responding_to_n_odors


    # NOTE: works whether responses contains {0.0, 1.0} or {False, True}
    assert set(np.unique(responses.values)) == {0, 1}
    # how many odors each cell responds to
    n_odors_per_cell = responses.sum(axis='columns')

    experimental_unit_opts = {remy_fly_id, 'seed'}

    experimental_unit_levels = set(responses.index.names) & experimental_unit_opts
    assert len(experimental_unit_levels) <= 1

    if len(experimental_unit_levels) > 0:
        experimental_unit = experimental_unit_levels.pop()

        if n_first_seeds_for_errorbar is not None and experimental_unit == 'seed':
            responses = select_first_n_seeds(responses)

        errorbar = seed_errorbar
        lineplot_kws['errorbar'] = errorbar
        lineplot_kws['seed'] = bootstrap_seed
        lineplot_kws['err_style'] = 'bars'

        # assuming each use of this fn will have at least SOME model data (true as of
        # 2024-08-06), otherwise may not want to always use `seed_err_text` which
        # sometimes has an extra line about only using first N seeds (when relevant
        # variable is set)
        if title is None:
            title = seed_err_text
        else:
            title += f'\n{seed_err_text}'

        lineplot_kws['x'] = n_odors_col
        lineplot_kws['y'] = frac_responding_col

        frac_responding_to_n_odors = n_odors_per_cell.groupby(level=experimental_unit
            ).apply(_n_odors2frac_per_cell)
        # TODO some way to get groupby->apply to preserve .name _n_odors2frac_per_cell
        # sets? (so we don't have to duplicate that here)
        frac_responding_to_n_odors.name = frac_responding_col

        # TODO reset_index necessary?
        frac_responding_to_n_odors = frac_responding_to_n_odors.reset_index()

    # should only happen for modelling inputs w/ hemibrain wPNKC (as the other wPNKC
    # options should have a 'seed' level)
    else:
        frac_responding_to_n_odors = _n_odors2frac_per_cell(n_odors_per_cell)

    # NOTE: did just downgrade to matplotlib==3.4.3, so this is not currently an issue.
    # hopefully seaborn fixes it soon, so I can upgrade back to >=3.7.3
    # (see comments below)
    #
    # TODO did this actually have negative values? (just in the way seaborn calculates
    # the err, at least up to 0.13.2)
    #
    # ...
    # pebbled_6f/pdf/ijroi/mb_modeling/megamat/dff_scale-to-avg-max__data_pebbled__hallem-tune_False__pn2kc_uniform__n-claws_7__drop-plusgloms_False__target-sp_0.0915__n-seeds_100/sparsity_per_odor.pdf
    # Uncaught exception
    # Traceback (most recent call last):
    #   File "./al_analysis.py", line 13234, in <module>
    #     main()
    #   File "./al_analysis.py", line 13223, in main
    #     model_mb_responses(consensus_df, across_fly_ijroi_dir,
    #   File "/home/tom/src/al_analysis/mb_model.py", line 8232, in model_mb_responses
    #     params_for_csv = fit_and_plot_mb_model(panel_plot_dir,
    #   File "/home/tom/src/al_analysis/mb_model.py", line 5222, in fit_and_plot_mb_model
    #     plot_n_odors_per_cell(responses_including_silent, ax,
    #   File "/home/tom/src/al_analysis/mb_model.py", line 3280, in plot_n_odors_per_cell
    #     sns.lineplot(frac_responding_to_n_odors, label=label, color=color,
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/seaborn/relational.py", line 507, in lineplot
    #     p.plot(ax, kwargs)
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/seaborn/relational.py", line 354, in plot
    #     ebars = ax.errorbar(
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/matplotlib/__init__.py", line 1446, in inner
    #     return func(ax, *map(sanitize_sequence, args), **kwargs)
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/matplotlib/axes/_axes.py", line 3636, in errorbar
    #     raise ValueError(
    # ValueError: 'yerr' must not contain negative values
    try:
        sns.lineplot(frac_responding_to_n_odors, label=label, color=color,
            markeredgecolor=color, **lineplot_kws
        )

    except ValueError as err:
        # TODO TODO raise if message doesn't match:
        # "'yerr' must not contain negative values"

        # TODO TODO maybe it wasn't still a problem after upgrading seaborn? error i'm
        # getting now is still a ValueError, but with a diff message. more basic cause
        # it seems? try to repro w/ full number of seeds
        # ValueError: Could not interpret value `frac_responding_to_n_odors` for `y`. An
        # entry with this name does not appear in `data`.
        #
        # still a problem after upgrading from seaborn 0.13.0 to 0.13.2 (which does
        # appear to be latest seaborn, as of 2025-04-14). could probably downgrade to
        # 3.4.3 (https://github.com/sktime/pytorch-forecasting/issues/1145) but not sure
        # that's a great long term solution. see also:
        # https://github.com/matplotlib/matplotlib/issues/26187
        #
        # ipdb> pp lineplot_kws
        # {'ax': <Axes: >,
        #  'err_style': 'bars',
        #  'errorbar': ('pi', 50),
        #  'legend': False,
        #  'linestyle': '-',
        #  'marker': 'o',
        #  'markerfacecolor': 'white',
        #  'seed': 1337,
        #  'x': 'n_odors',
        #  'y': 'frac_responding_to_n_odors'}
        #
        # ipdb> frac_responding_to_n_odors
        #        seed  n_odors  frac_responding_to_n_odors
        # 0     94895        0                    0.589548
        # 1     94895        1                    0.107784
        # 2     94895        2                    0.076756
        # 3     94895        3                    0.053892
        # 4     94895        4                    0.039194
        # ...     ...      ...                         ...
        # 1795  94994       13                    0.004899
        # 1796  94994       14                    0.000544
        # 1797  94994       15                    0.000544
        # 1798  94994       16                    0.000000
        # 1799  94994       17                    0.000000
        # [1800 rows x 3 columns]
        #
        # ipdb> frac_responding_to_n_odors.min()
        # seed                          94895.0
        # n_odors                           0.0
        # frac_responding_to_n_odors        0.0
        # dtype: float64
        # ipdb> frac_responding_to_n_odors.max()
        # seed                          94994.00000
        # n_odors                          17.00000
        # frac_responding_to_n_odors        0.63963
        # dtype: float64
        # ipdb> frac_responding_to_n_odors.isna().any()
        # seed                          False
        # n_odors                       False
        # frac_responding_to_n_odors    False
        import ipdb; ipdb.set_trace()

    if log_yscale:
        # TODO increase if needed (i.e. if we ever use fafb wPNKC / cell #s, which have
        # 2482 in fafb-left, and probably similar # in right)
        n_cells_for_ylim = 2000

        # TODO this working w/ twinx() (seems to be, but why? why only need to use
        # ax_for_ylabel for ylabel, and not yscale / etc)?
        # TODO add comment explaining what nonpositive='mask' does (and are there any
        # alternatives? what, and why did i pick this?)
        # (i think nonpositive='clip' is the default, and the only alternative)
        ax.set_yscale('log', nonpositive='mask')

        # TODO try just using len(responses)? (would cause problems if that ever
        # differed across calls made on same Axes...)
        ax.set_ylim([1 / n_cells_for_ylim, 1])

    ylabel = 'cell fraction responding to N odors'
    if ax_for_ylabel is None:
        ax.set_ylabel(ylabel)
    else:
        ax_for_ylabel.set_ylabel(ylabel)

    # https://stackoverflow.com/questions/30914462
    ax.xaxis.set_major_locator(MaxNLocator(integer=True))

    xlabel = '# odors'
    ax.set_xlabel(xlabel)

    if title is not None:
        ax.set_title(title)


# TODO TODO still needed? don't i have some corr calc that resorts to input order?
# plot_corr?
# TODO try to fix corr calc to not re-order stuff (was that the issue?) -> delete
# this?
# NOTE: need to re-sort since corr_triangular necessarily (why? can't i have it sort
# to original order or something?) sorts internally
def _resort_corr(corr, add_panel, **kwargs):
    return sort_odors(corr, panel=add_panel, **kwargs)


# TODO factor to hong2p.viz
def add_unity_line(ax: Axes, *, linestyle='--', color='r', **kwargs) -> None:
    ax.axline((0, 0), slope=1, linestyle=linestyle, color=color, **kwargs)


# TODO delete? (for debugging)
_spear_inputs2dfs = dict()
#
def bootstrapped_corr(df: pd.DataFrame, x: str, y: str, *, n_resamples=1000,
    # TODO default to 95% ci?
    # TODO delete debug _plot_dir kwarg?
    ci=90, method='spearman', _plot_dir=None) -> str:
    # TODO update doc to include new values also returned:
    # corr_text, corr, ci_lower, ci_upper, pval
    # TODO TODO be clear about what unit we are bootstrapping over (+ what test is being
    # used to compute p-value). update doc to reflect that it's not just spearman this
    # can work with (also pearson)
    """Returns str summary of Spearman's R between columns x and y.

    Summary contains Spearman's R, the associated p-value, and a bootstrapped 95% CI.
    """
    assert 0 < ci < 100, 'ci must be between 0 and 100'

    # TODO delete
    # (after replacing model_mb...  _spear_inputs2dfs usage w/ equiv corrs from loaded
    # responses)
    #
    # rhs check just to exclude hallem stuff i don't care about that is causing resort
    # to fail
    if (_plot_dir is not None and not _plot_dir.name.startswith('data_hallem__') and
        # should already have an equivalent 'orn_corr' version here (w/ corresponding
        # non-dist y too)
        y != 'orn_corr_dist'):

        assert method == 'spearman'

        key = (_plot_dir, x, y)
        assert key not in _spear_inputs2dfs, f'{key=} already seen!'
        _spear_inputs2dfs[key] = df.copy()

        pdf = df.copy()
        if pdf.index.names != ['odor1','odor2']:
            assert all(x in pdf.columns for x in ['odor1','odor2'])
            pdf = df.set_index(['odor1','odor2'])

        if x.endswith('_dist'):
            assert y.endswith('_dist')
            # converting back from correlation distance to correlation
            pdf[x] = 1 - pdf[x]
            pdf[y] = 1 - pdf[y]
        else:
            assert not y.endswith('_dist')

    to_check = df.copy()
    if x.endswith('_dist'):
        assert y.endswith('_dist')
        # converting back from correlation distance to correlation
        to_check[x] = 1 - to_check[x]
        to_check[y] = 1 - to_check[y]
    else:
        assert not y.endswith('_dist')

    assert to_check[x].max() <= 1, f'{x=} probably mislabelled correlation DISTANCE'
    assert to_check[y].max() <= 1, f'{y=} probably mislabelled correlation DISTANCE'
    del to_check

    if df[[x,y]].isna().any().any():
        # TODO fix NaN handling in method='pearson' case
        # (just dropna in all cases, and remove nan_policy arg to spearmanr)
        assert method == 'spearman', ('would need to restore NaN dropping. pearsonr '
            'does not have the same nan_policy arg spearmanr does.'
        )

        # TODO delete
        # only the Hallem cases (which dont' pass _plot_dir) should have any null model
        # corrs
        assert _plot_dir is None
        #
        assert x == 'model_corr' or x == 'model_corr_dist'
        assert not df[y].isna().any()
        # so that spearmanr doesn't return NaN here (dropping seems consistent w/ what
        # pandas calc does by default)
        #df = df.dropna(subset=[x])

    if method == 'spearman':
        # nan_policy='omit' consistent w/ pandas behavior. should only be relevant for a
        # small subset of the Hallem model outputs (default spearmanr behavior would be
        # to return NaN here)
        results = spearmanr(df[x], df[y], nan_policy='omit')

    elif method == 'pearson':
        # NOTE: no nan_policy arg here. would need to manually drop, as I had before.
        results = pearsonr(df[x], df[y])

    else:
        raise ValueError(f"{method=} unrecognized. should be either "
            "'spearman'/'pearson'"
        )

    corr = results.correlation
    pval = results.pvalue

    # the .at[x,y] is to get a scalar from matrix like
    #                mean_kc_corr  mean_orn_corr
    # mean_kc_corr       1.000000       0.657822
    # mean_orn_corr      0.657822       1.000000
    assert np.isclose(df[[x,y]].corr(method=method).at[x,y], corr)

    # TODO try this kind of CI as well?
    # https://stats.stackexchange.com/questions/18887
    # TODO try "jacknife" version mentioned in wikipedia? is my basic bootstrapping
    # approach even reasonable?

    # TODO tqdm? slow (when doing 1000) (yes! but tolerable)?
    result_list = []
    for i in range(n_resamples):
        resampled_df = df[[x, y]].sample(
                n=len(df), replace=True, random_state=(bootstrap_seed + i)
            ).reset_index(drop=True)

        if method == 'spearman':
            # TODO TODO also need nan_policy='omit' here? (or just drop in advance, to
            # also work in pearson case...)
            curr_results = spearmanr(resampled_df[x], resampled_df[y])
        elif method == 'pearson':
            curr_results = pearsonr(resampled_df[x], resampled_df[y])

        # (we would have raised an error already if method wasn't in one of two options
        # above)
        # pylint: disable=possibly-used-before-assignment
        result_list.append({
            'sample': i,
            method: curr_results.correlation,
            'pval': curr_results.pvalue,
        })

    bootstrap_corrs = pd.DataFrame(result_list)

    alpha = (1 - ci / 100) / 2

    corr_ci = bootstrap_corrs[method].quantile(q=[alpha, 1 - alpha])
    corr_ci_lower = corr_ci.iloc[0]
    corr_ci_upper = corr_ci.iloc[1]
    corr_ci_text = f'{ci:.0f}% CI = [{corr_ci_lower:.2f}, {corr_ci_upper:.2f}]'

    # TODO put n_resamples in text too?

    # .2E will show 2 places after decimal then exponent (scientific notation),
    # e.g. 1.89E-180
    corr_text = f'{method}={corr:.2f}, p={pval:.2E}, {corr_ci_text}'
    return corr_text, corr, corr_ci_lower, corr_ci_upper, pval


# TODO test w/ Series too (-> update type hint ["Arraylike"?] if we can get it to work)?
def step_around(center: Union[float, np.ndarray], param_lim_factor: float,
    param_name: Optional[str] = None, *, n_steps: int = 3, drop_negative: bool = True,
    drop_zero: bool = False) -> np.ndarray:
    # TODO doc

    assert param_lim_factor > 0

    # TODO check that center is positive? not sure some of the stuff below makes
    # sense if it's not (assumes the <=0 elements will be at start of list)

    # TODO rename this? it's not the size of the single steps, now is it? (no, it's the
    # total extent we'll step in either direction, though could be limited by 0)
    step_size = np.abs(center * param_lim_factor)

    # if center is a vector w/ shape (N,), and param_steps would have
    # length M w/ scalar center, param_steps will now be of shape (M, N).
    # len(param_steps) will be the same regardless.
    param_steps = np.linspace(center - step_size, center + step_size,
        num=n_steps
    )

    if drop_zero:
        assert drop_negative

    prefix = '' if param_name is None else f'{param_name=}: '
    if drop_negative:
        param_steps[param_steps < 0] = 0

        # TODO factor out? allow passing arbitrary value instead of just 0?
        def _last_zero_idx(xs):
            """Returns index of last 0 element in vector, or NaN if there isn't one.
            """
            assert xs.ndim == 1
            is_zero = xs == 0
            if not is_zero.any():
                return np.nan

            return np.argwhere(is_zero)[-1, 0]


        if (param_steps == 0).any():
            if isinstance(center, float):
                last_zero_idx = _last_zero_idx(param_steps)
            else:
                # TODO just do this call in both cases (should work for float too)?
                last_zero_idx = np.apply_along_axis(_last_zero_idx, 0, param_steps)

            # if we chose steps in such a way that (for 2d input), we could have some
            # columns without 0 values while other columns have them, would need to
            # handle this case. current method should produce them in all the same place
            # though.
            # TODO try removing this assertion (-> filling NaN below, to 0, so
            # first_idx_to_use uses all data for those columns) (would that even work
            # tho? cause then output cols would be of different length. might need to
            # postprocess instead?)
            assert not np.isnan(last_zero_idx).any()

            first_idx_to_use = last_zero_idx
            if drop_zero:
                first_idx_to_use += 1

            if param_steps.ndim > 1:
                assert param_steps.ndim == 2
                # this should also only list NaN once (if any), even if there are
                # multiple in input
                unique_first_indices = np.unique(first_idx_to_use)
                # if we chose steps differently (rather than being relative within
                # each column), could be possible to get different
                # first-nonzero-element indices. for now, it shouldn't be.
                # would just need to think about what i want the warning message to
                # be in that case.
                assert len(unique_first_indices) == 1

                # unless i want to slice within each column below (currently no
                # point for same reason i can rely on a single unique value above),
                # and then somehow combine together (w/ potentially diff lengths),
                # need to just get a single integer to slice with.
                #
                # NOTE: warning below also assumes it's a single integer
                first_idx_to_use = unique_first_indices[0]

            if first_idx_to_use > 0:
                warn(f'{prefix}setting lowest {first_idx_to_use} steps (negative) to 0')

            param_steps = param_steps[first_idx_to_use:]

            if not drop_zero:
                # TODO actually guaranteed step sizes are uneven now? maybe we could
                # choose values where that's not true? add to unit test? (and then maybe
                # check explicitly that the step sizes are uneven here?)
                warn(f'{prefix}step sizes uneven after setting negative values to 0!')

    # TODO actually check we have something less than center if we care about that.
    # otherwise delete. currently can get past this if i just have enough steps for the
    # stuff >= center to satisfy this
    #
    #assert len(param_steps) >= 3, (f'{prefix}must have at least 1 step on '
    #    'either side of center'
    #)

    assert sum(np.allclose(row, center) for row in param_steps) == 1, \
        f'{prefix}center not in steps'

    if drop_negative:
        if drop_zero:
            assert (param_steps > 0).all()
        else:
            assert (param_steps >= 0).all()

    return param_steps


model_responses_cache_name = 'responses.p'
model_spikecounts_cache_name = 'spike_counts.p'

_fit_and_plot_seen_param_dirs = set()
# TODO why is sim_odors an explicit kwarg? just to not have included in strs describing
# model params? i already special case orn_deltas to exclude it. why not do something
# like that (if i keep the param at all)?
# TODO try to get [h|v]lines between components, 2-component mixes, and 5-component
# mix for new kiwi/control data (at least for responses and correlation matrices)
# (could just check for '+' character, to handle all cases)
# TODO TODO add flag to toggle showing all KC subtype mean resopnse rates in all titles?
def fit_and_plot_mb_model(plot_dir: Path, sensitivity_analysis: bool = False,
    sens_analysis_kws: Optional[Dict[str, Any]] = None, try_cache: bool = True,
    # TODO rename comparison_responses to indicate it's only used for sensitivity
    # analysis stuff? (and to be more clear how it differs from comparison_[kcs|orns])
    comparison_responses: Optional[pd.DataFrame] = None,
    # TODO default to n_seeds=None and then in code set it 1, warning to explicitly set
    # it (prob)? or default to N_SEEDS (don't want to accidentally make slow calls we
    # don't reallyy want tho...)?
    n_seeds: int = 1, restrict_sparsity: bool = False,
    min_sparsity: float = 0.03, max_sparsity: float = 0.25,
    _in_sens_analysis: bool = False,
    # TODO just use model_kws for fixed_thr/wAPLKC?
    # (may now make sense, if i'm gonna add a flag to indicate whether we are in a
    # sensitivity analysis subcall)
    fixed_thr: Optional[Union[float, np.ndarray]] = None,
    wAPLKC: Optional[float] = None,
    drop_silent_cells_before_analyses: bool = drop_silent_model_kcs,
    _add_combined_plot_legend=False, sim_odors=None, comparison_orns=None,
    comparison_kc_corrs=None, _strip_concs_comparison_kc_corrs=False,
    param_dir_prefix: str = '', title_prefix: str= '',
    extra_params: Optional[dict] = None, _only_return_params: bool = False, **model_kws
    ) -> Optional[Dict[str, Any]]:
    # TODO doc which extra plots made by each of comparison* inputs (or which plots are
    # changed, if no new ones)
    """
    Args:
        plot_dir: parent to directory that will be created to contain model outputs and
            plots. created model output directories will have names incuding key
            parameters.

        sensitivity_analysis: if True, will run multiple versions of the model
            (saving output for each to a separte subdirectory), with `fixed_thr` and
            `wAPLKC` stepped around tuned values from primary model outputs.
            use `sens_analysis_kws` to control steps.

        try_cache: set False to force* any model cache to be ignored. Calls via
            `al_analysis.py` CLI with `-i model` will have the same effect.

        min_sparsity: (internal use only) only used for models parameterized with fixed
            `fixed_thr` and `wAPLKC` (typically in context of sensitivity analysis).
            return before generating plots if output sparsity is outside these bounds.

        max_sparsity: (internal use only) see min_sparsity.

        extra_params: saved alongside internal params in cache pickle/CSV
            (for keeping tracking of important external parameters, for reproducibility)

        **model_kws: passed to `fit_mb_model` (see its docstring, particularly for key
            inputs, such as `orn_deltas`)

    Returns dict with key model parameters (some tuned), any input `extra_params`, as
    well as 'output_dir' with name of created directory (which contains model outputs
    and plots).

    Notes:
    The contents of the `orn_deltas.csv` files copied to each model output directory
    should reflect the `model_kws['orn_deltas']` input to this function.
    """
    assert n_seeds >= 1

    # TODO delete restrict_sparsity? currently used?
    # TODO delete [min|max]_sparsity too?
    if not restrict_sparsity:
        min_sparsity = 0
        max_sparsity = 1

    # TODO delete. isn't responses_to just overwritten w/ 'pebbled' below
    # (before being used, right?)
    # TODO TODO use one of newer strs in al_analysis.py for this (-> move to al_util?)?
    # might this ever be 'Z-scored F' instead of dF/F?
    my_data = f'pebbled {dff_latex}'

    if 'orn_deltas' in model_kws:
        # TODO fix how this might misrepresent stuff if i pass hallem data in manually?
        # (allow passing in description of the data, overriding this?)
        responses_to = my_data
    else:
        responses_to = 'hallem'
    #

    # TODO also try tuning on remy's subset of hallem odors?
    # (did i already? is it clear that what's in preprint was not done this way?)

    # TODO share default w/ fit_mb_model somehow?
    tune_on_hallem = model_kws.get('tune_on_hallem', False)
    if tune_on_hallem:
        tune_from = 'hallem'
    else:
        tune_from = my_data
    del my_data

    # TODO share defaults w/ fit_mb_model somehow?
    pn2kc_connections = model_kws.get('pn2kc_connections', 'hemibrain')
    variable_n_claws = pn2kc_connections in variable_n_claw_options
    use_connectome_APL_weights = model_kws.get('use_connectome_APL_weights', False)

    # responses_to handled below, circa def of param_dir
    param_abbrevs = {
        'tune_on_hallem': 'hallem-tune',
        'pn2kc_connections': 'pn2kc',
        'target_sparsity': 'target_sp',
        'target_sparsity_factor_pre_APL': 'sp_factor_pre_APL',
        '_drop_glom_with_plus': 'drop-plusgloms',
        'use_connectome_APL_weights': 'connectome-APL',
    }

    # excluded from param_str and params_for_csv
    exclude_params = (
        'orn_deltas',
        'title',
        'repro_preprint_s1d',
        '_plot_example_dynamics',
        'return_dynamics',
        '_multiresponder_mask',
    )

    # TODO just use default values (from fit_mb_model def, via introspection? how else?)
    # for these instead?
    #
    # will be excluded from param_str (and thus created param_dir names) if values match
    # those in this dict. to remove clutter in these names. keys should be full param
    # names, not the abbreviated values in param_abbrevs.
    exclude_if_value_matches = {
        'tune_on_hallem': False,
    }

    # TODO sort params first? (so changing order in code doesn't cause
    # cache miss...)
    # TODO why adding [''] again? why not just prepend ', ' to output if i want?
    param_str = ', '.join([''] + [
        f'{param_abbrevs[k] if k in param_abbrevs else k}={v}'
        for k, v in model_kws.items() if k not in exclude_params and
        (k not in exclude_if_value_matches or v != exclude_if_value_matches[k])
    ])
    if fixed_thr is not None or wAPLKC is not None:
        assert fixed_thr is not None and wAPLKC is not None

        # TODO maybe only do if _in_sens_analysis. don't think i actually want in
        # hemibrain case (other than within sens analysis subcalls)
        #
        # TODO need to support int type too (in both of the two isinstance calls below)?
        # isinstance(<int>, float) is False
        #
        # in n_seeds > 1 case, fixed_thr/wAPLKC will be lists of floats, and will be too
        # cumbersome to format into this
        if n_seeds == 1:
            if isinstance(fixed_thr, float):
                fixed_thr_str = f'fixed_thr={fixed_thr:.0f}'

            # TODO TODO or format type2thr if that is passed? (and if it is, should be
            # used to define vector fixed_thr. initial fixed_thr should be None if in
            # that case)
            elif isinstance(fixed_thr, np.ndarray):
                # TODO or just format type2thr dict? was just trying to still be useful
                # for sensitivity analysis dir names, without making them too long
                fixed_thr_str = f'mean_thr={fixed_thr.mean():.0f}'

            # TODO at least do something for vector/dict fixed_thr (assuming i continue
            # to need/support both)? this only used for dir names, right?
            else:
                raise ValueError('unexpected fixed_thr type: {type(fixed_thr)}')

            param_str += f', {fixed_thr_str}, wAPLKC={wAPLKC:.2f}'

    if n_seeds > 1:
        param_str += f', n_seeds={n_seeds}'

    # TODO clean up / refactor. hack to make filename not atrocious when these are
    # 'pebbled_\$\\Delta_F_F\$'
    if responses_to.startswith('pebbled'):
        responses_to = 'pebbled'

    if tune_from.startswith('pebbled'):
        tune_from = 'pebbled'

    # this way it will also be included in params_for_csv, and we won't need to manually
    # pass to all fit_mb_model calls
    model_kws['drop_silent_cells_before_analyses'] = drop_silent_cells_before_analyses

    # TODO refactor so param_str defined from this, and then f-str below (+ for_dirname
    # def) doesn't separately specify {responses_to=}?
    params_for_csv = {
        'responses_to': responses_to,
        'tune_from': tune_from,
    }
    params_for_csv.update(
        {k: v for k, v in model_kws.items() if k not in exclude_params}
    )
    # prefix defaults to empty str
    title = title_prefix
    if _in_sens_analysis:
        # TODO also assert wAPLKC is a (scalar) float (and not a vector float array from
        # use_connectome_APL_weight=True code)?
        assert fixed_thr is not None and wAPLKC is not None

        # assumed to be passed in (but not created by) sensitivity analysis calls
        # (recursive calls below)
        #
        # the parent directory of this should have plot_dir_prefix in it, and don't feel
        # the need to also include here.
        param_dir = plot_dir

        # TODO delete? should always be redefed below...
        # (if so, then why is this code even here?)
        # TODO refactor this thr str handling?
        if isinstance(fixed_thr, float):
            title += f'thr={fixed_thr:.2f}, wAPLKC={wAPLKC:.2f}'
        else:
            assert isinstance(fixed_thr, np.ndarray)
            title += f'mean_thr={fixed_thr.mean():.2f}, wAPLKC={wAPLKC:.2f}'

        title_including_silent_cells = title
    else:
        # TODO one hardcode flag to control whether these are dropped or not?
        # TODO TODO start excluding parts from dirname unless they are different from
        # some default? parts to consider excluding for default values (hardly change):
        # - dff_scale-to-avg-max
        # - data_pebbled
        # - hallem-tune_False
        # - target-sp_0.0915

        # TODO refactor for_dirname handling to not specialcase responses_to/others?
        # possible to have simple code not split by fixed_thr/wAPLKC None or not?
        # TODO need to pass thru util.to_filename / simliar normalization myself now
        # (since i'm putting this in a dirname now, not the final filename of the plot)
        for_dirname = ''
        # NOTE: responses_to set to 'pebbled' above if orn_deltas is passed, so could be
        # confusing if hallem data passed in as orn_deltas
        if responses_to != 'pebbled':
            for_dirname = f'data_{responses_to}'

        if len(param_str) > 0:
            if len(for_dirname) > 0:
                for_dirname += '__'

            # TODO factor this into some fn? single flag (for_fname?) to
            # util.format_params to enable this kind of behavior?
            for_dirname += param_str.strip(', ').replace('_','-').replace(', ','__'
                ).replace('=','_')

        # TODO rename plot_dir + this to be more clear?
        # plot_dir contains all modelling (mb_modeling)
        # param_dir contains outputs from model run w/ specific choice of params
        # (and only contains stuff downstream of dF/F -> spiking model
        # creation/application)
        param_dir_name = f'{param_dir_prefix}{for_dirname}'
        param_dir = plot_dir / param_dir_name

        # TODO delete after renaming all i want
        #
        # TODO TODO do i even want to do this? won't params.csv have wrong output_name?
        # do i care? (renaming for now, and can deal with that later if i care)
        #
        # hack to rename dirs from old, overly-verbose format like:
        # dff_scale-to-avg-max__data_pebbled__hallem-tune_False__pn2kc_hemibrain__weight-divisor_20__drop-plusgloms_False__target-sp_0.0915
        # to new format like:
        # pn2kc_hemibrain__weight-divisor_20__drop-plusgloms_False__target-sp_0.0915
        if not param_dir.exists():
            old_prefix = 'dff_scale-to-avg-max__data_pebbled__hallem-tune_False__'

            old_dir = plot_dir / f'{param_dir_prefix}{old_prefix}{for_dirname}'
            if old_dir.exists():
                warn(f'(under {param_dir.parent}) renaming\n{old_dir.name}'
                    f'\n->\n{param_dir.name}'
                )

                # this does not change mtime of directory, consistent w/ what would
                # happen using `mv` CLI tool (directory mtimes normally get updated when
                # files are added/removed from dir automatically, and not sure it's
                # actually stored separately from the mtimes of files within...)
                os.rename(old_dir, param_dir)

                assert param_dir.exists()
                assert not old_dir.exists()
        #

        del for_dirname

        # TODO delete
        print()

        if tune_from != 'pebbled':
            title += f'KC thresh [/APL inh] from: {tune_from}\n'

        if responses_to != 'pebbled':
            # TODO even need this one? were hallem / pebbled (i.e. megamat) plots ever
            # possible to confuse?
            title += f'responses to: {responses_to}\n'

        title += (
            f'wPNKC: {pn2kc_connections}\n'
        )
        # TODO TODO change below so same params used for dirnames (which happens
        # automatically for new fit_mb_model kwargs) are also in titles (don't want to
        # have to keep manually adding new params in title string creating code here)

        weight_divisor = model_kws.get('weight_divisor')
        if weight_divisor is not None:
            title += f'weight_divisor: {weight_divisor:.1f}\n'

        if use_connectome_APL_weights:
            title += f'use_connectome_APL_weights: True\n'

        if model_kws.get('homeostatic_thrs'):
            title += f'homeostatic_thrs: True\n'

        if model_kws.get('equalize_kc_type_sparsity'):
            # TODO reword to be clear it's changing per-type thresholds to do this?
            title += f'equalize_kc_type_sparsity: True\n'

        ab_prime_response_rate_target = model_kws.get('ab_prime_response_rate_target')
        if ab_prime_response_rate_target is not None:
            title += (
                # TODO refactor sparsity formatting?
                f'ab_prime_response_rate_target: {ab_prime_response_rate_target:.3g}\n'
            )

        if fixed_thr is not None or wAPLKC is not None:
            assert fixed_thr is not None and wAPLKC is not None
            # TODO assert target_sparsity_factor_pre_APL is None?

            # in n_seeds > 1 case, fixed_thr/wAPLKC will be lists of floats, and will be
            # too cumbersome to format into this
            #
            # TODO need to support int type too? isinstance(<int>, float) is False
            if n_seeds == 1:
                if isinstance(fixed_thr, float):
                    title += f'fixed_thr={fixed_thr:.0f}, wAPLKC={wAPLKC:.2f}\n'
                else:
                    assert isinstance(fixed_thr, np.ndarray)
                    title += f'mean_thr={fixed_thr.mean():.0f}, wAPLKC={wAPLKC:.2f}\n'
        else:
            if 'target_sparsity' in model_kws:
                assert model_kws['target_sparsity'] is not None
                target_sparsity = model_kws['target_sparsity']
            else:
                target_sparsity = 0.1
                # TODO replace .3g w/ a format_sparsity fn? (doing .3g [or .2g?] if
                # there are 0s after decimal point, and maybe .2f otherwise? some way to
                # accomplish something like that within f-str syntax?)
                warn(f'using default target_sparsity of {target_sparsity:.3g}')

            # TODO include something else for case where fixed_thr is vector (which
            # currently requires wAPLKC set, to a float as before)?
            assert fixed_thr is None and wAPLKC is None
            # .3g will show up to 3 sig figs (regardless of their position wrt decimal
            # point), but also strip any trailing 0s (0.0915 -> '0.0915', 0.1 -> '0.1')
            title += f'target_sparsity: {target_sparsity:.3g}\n'

        # NOTE: this is for analyses that either always include or always drop silent
        # cells, regardless of value of `drop_silent_cells_before_analyses`
        # (e.g. should be used for analyses using `responses_including_silent_cells`)
        # TODO move this below too? (to where title is updated w/ silent cells suffix)
        title_including_silent_cells = title

        # to save plots of internal ORN / PN matrices (and their correlations, etc),
        # exactly as used to run model
        model_kws['plot_dir'] = param_dir
        model_kws['title'] = title
    #

    params_for_csv['output_dir'] = param_dir.name

    model_responses_cache = param_dir / model_responses_cache_name
    model_spikecounts_cache = param_dir / model_spikecounts_cache_name
    # TODO rename this to have "fit"/"tuned" in name or something (and change
    # model_mb_responses `tuned` var/outputs to not), since this is all tuned, and
    # latter is a mix (stuff from this, but also stuff hardcoded from above / output
    # statistics)
    param_cache_name = 'params_for_csv.p'
    param_dict_cache = param_dir / param_cache_name
    wPNKC_cache_name = 'wPNKC.p'
    wPNKC_cache = param_dir / wPNKC_cache_name

    # TODO TODO also save kc_spont_in / vector wAPLKC/wKCAPL as CSVs? wPNKC (don't
    # already have?)?
    kc_spont_in_cache = param_dir / 'kc_spont_in.p'

    # NOTE: these two only used for vector values (specifically, just the
    # use_connectome_APL_weights=True case, which should always produce such values,
    # unlike any other current path). If they are a scalar (including a whole vector
    # with just one value repeated), these two params will be saved as elements of usual
    # param pickle+CSV outputs.
    # TODO doc what happens in variable_n_claws cases (prob going to also pop + pickle
    # like in connectome APL weights case)
    # TODO also save these as CSVs too (so i have a better chance of actually loading in
    # future if needed)?
    wAPLKC_cache = param_dir / 'wAPLKC.p'
    wKCAPL_cache = param_dir / 'wKCAPL.p'

    extra_responses_cache_name = 'extra_responses.p'
    extra_responses_cache = param_dir / extra_responses_cache_name
    extra_responses = None

    extra_spikecounts_cache_name = 'extra_spikecounts.p'
    extra_spikecounts_cache = param_dir / extra_spikecounts_cache_name
    extra_spikecounts = None

    use_cache = try_cache and (not should_ignore_existing('model')) and (
        # checking both since i had previously only been returning+saving the 1st
        model_responses_cache.exists() and model_spikecounts_cache.exists()
    )

    made_param_dir = False

    tuning_output_dir = None
    # TODO delete? or implement somewhere else? (maybe just add flag to force ignore on
    # certain calls, and handle in model_mb...?)
    # TODO refactor def of 'tuning_output_dir' str
    if (extra_params is not None and 'tuning_output_dir' in extra_params and
        # NOTE: currently code in this conditional not working on _in_sens_analysis=True
        # subcalls, and we don't need anything defined in here in any of those cases
        # anyway
        not _in_sens_analysis):

        assert 'tuning_panels' in extra_params
        tuning_panels_str = extra_params['tuning_panels']

        # e.g. plot_dir=PosixPath('pebbled_6f/pdf/ijroi/mb_modeling/kiwi') ->
        # tuning_panel_dir=PosixPath('pebbled_6f/pdf/ijroi/mb_modeling/control-kiwi')
        tuning_panel_dir = plot_dir.parent / tuning_panels_str
        # NOTE: before i added `not _in_sens_analysis` condition, this was tripped in
        # those subcalls
        assert tuning_panel_dir.is_dir()

        tuning_output_dir = tuning_panel_dir / extra_params['tuning_output_dir']
        assert tuning_output_dir.is_dir()

        tuning_responses_cache = tuning_output_dir / model_responses_cache_name
        assert tuning_responses_cache.exists()

        # TODO delete? doesn't really matter unless fixed_thr/wAPLKC actually changed,
        # right? isn't that what i should be testing?
        if model_responses_cache.exists():
            curr_cache_mtime = getmtime(model_responses_cache)
            tuning_cache_mtime = getmtime(tuning_responses_cache)

            if tuning_cache_mtime >= curr_cache_mtime:
                warn(f'{tuning_responses_cache} was newer than {model_responses_cache}'
                    '! setting use_cache=False!'
                )
                use_cache = False

        if param_dict_cache.exists():
            param_dict = read_pickle(param_dict_cache)

            if 'wAPLKC' in param_dict:
                assert 'wAPLKC_scale' not in param_dict
                cached_wAPLKC = param_dict['wAPLKC']
            else:
                assert use_connectome_APL_weights
                assert 'wAPLKC' not in param_dict
                cached_wAPLKC = param_dict['wAPLKC_scale']

            # np.array_equal works with both float and list-of-float inputs
            if (not np.array_equal(fixed_thr, param_dict['fixed_thr']) or
                not np.array_equal(wAPLKC, cached_wAPLKC)
                ):

                warn(f'{param_dict_cache} fixed_thr/wAPLKC did not match current '
                    'inputs! setting use_cache=False!'
                )
                use_cache = False
        else:
            assert not use_cache

        # TODO also check that cached params references same tuning_output_dir (and set
        # use_cache = False if not)? or just assert it's same if already in cache?
        # NOTE: would have to load the param CSV instead of the pickle. the pickle
        # doesn't have those extra params
    #

    # TODO give better explanation as to why this is here.
    # to make sure we are accounting for all parameters we might vary in filename
    if param_dir in _fit_and_plot_seen_param_dirs:
        # otherwise, param_dir being in seen set would indicate an error
        assert _only_return_params, f'{param_dir=} already seen!'
        use_cache = True

    _fit_and_plot_seen_param_dirs.add(param_dir)

    # NOTE: this currently will cause -c/-C checks to fail
    # TODO TODO want to fix that (i.e. remove this from that output, but still keep long
    # enough to use for what i wanted? possible?)?
    params_for_csv['used_model_cache'] = use_cache

    print()
    # TODO TODO default to also skipping any plots made before returning? maybe add
    # another ignore-existing option ('model-plots'?) if i really want to be able to
    # remake plots w/o changing model outputs? takes a lot of time to make plots on all
    # the model outputs...
    if use_cache:
        print(f'loading model responses (+params) from cache {model_responses_cache}')
        # TODO why using my read_pickle wrapper for only some of these?
        responses = pd.read_pickle(model_responses_cache)
        spike_counts = pd.read_pickle(model_spikecounts_cache)
        param_dict = read_pickle(param_dict_cache)

        if extra_responses_cache.exists():
            extra_responses = pd.read_pickle(extra_responses_cache)

        if extra_spikecounts_cache.exists():
            extra_spikecounts = pd.read_pickle(extra_spikecounts_cache)
    else:
        # doesn't necessarily matter if it already existed. will be deleted if sparsity
        # outside bounds (and inside a sensitivity analysis call)
        made_param_dir = True

        # TODO use makedirs instead? (so if empty at end, will be deleted?)
        param_dir.mkdir(exist_ok=True, parents=True)

        print(f'fitting model ({responses_to=}{param_str})...', flush=True)

        # TODO check i can replace model_test.py portion like this w/ this
        # implementation?
        if n_seeds > 1:
            assert fixed_thr is None or type(fixed_thr) is list
            assert wAPLKC is None or type(wAPLKC) is list

            # only to regenerate model internal plots (which only ever are saved on the
            # first seed, in cases where there would be multiple runs w/ diff seeds)
            # without waiting for rest of seed runs to finish. will NOT write to
            # responses cache or make any plots based on output responses in this case!
            #first_seed_only = True
            first_seed_only = False
            if first_seed_only:
                # first_seed_only=True only intended for regenerating these internal
                # plots. probably a mistake if it's True any other time.
                assert 'plot_dir' in model_kws

            # TODO make kwarg
            # same seed Matt starts at in
            # matt-modeling/docs/independent-draw-reference.html
            initial_seed = 94894 + 1

            # TODO get good desc for tqdm
            #desc=f'{draw_type} ({n_claws=})'
            seeds = []
            responses_list = []
            spikecounts_list = []
            param_dict_list = []
            first_param_dict = None
            wPNKC_list = []

            _fixed_thr = None
            _wAPLKC = None

            if fixed_thr is not None:
                # this branch should not run in any sensitivity analyis subcalls, as
                # currently only doing that for n_seeds=1 (i.e. hemibrain) case
                # (otherwise, we would need to test if tuning_output_dir is None / etc)
                assert not _in_sens_analysis

                assert len(fixed_thr) == len(wAPLKC) == n_seeds

                assert tuning_output_dir is not None

                tuning_wPNKC_cache = tuning_output_dir / wPNKC_cache_name
                assert tuning_wPNKC_cache.exists()

                tuning_wPNKC = read_pickle(tuning_wPNKC_cache)
                # assuming all entries of a given seed are at adjacent indices in the
                # seed level values (should never be False given how i'm implementing
                # things)
                tuning_seeds = tuning_wPNKC.index.get_level_values('seed').unique()

            # TODO TODO include at least pn2kc_... in progress bar
            # TODO some way to have a nested progress bar, so that outer on (in
            # model_mb_... i'm imagining) increments for each model type, and this inner
            # one increments for each seed? or do something else to indicate outer
            # progress?
            for i in tqdm(range(n_seeds), unit='seed'):
                seed = initial_seed + i
                seeds.append(seed)
                assert 'seed' not in model_kws

                if fixed_thr is not None:
                    _fixed_thr = fixed_thr[i]
                    _wAPLKC = wAPLKC[i]
                    # would need to use same seed sequence if this ever failed
                    assert seed == tuning_seeds[i]

                responses, spike_counts, wPNKC, param_dict = fit_mb_model(
                    # TODO or can i handle fixed_thr/wAPLKC thru model_kws (prob not)?
                    # (maybe i will soon be able to, if i'm gonna replace some of their
                    # usage with a flag to indicate whether we are in a sensitivity
                    # analysis subcall...)
                    sim_odors=sim_odors, fixed_thr=_fixed_thr, wAPLKC=_wAPLKC,
                    seed=seed,
                    # ORN/PN plots would be redundant, and overwrite each other.
                    # currently those are the only plots I'm making in here.
                    make_plots=(i == 0), **model_kws
                )

                if fixed_thr is not None:
                    # could prob delete. should be sufficienet to check the seeds equal,
                    # as we are doing above
                    assert tuning_wPNKC.loc[seed].equals(wPNKC)

                if first_seed_only:
                    warn('stopping after model run with first seed '
                        '(first_seed_only=True)! model response caches / downstream '
                        'plots not updated!'
                    )
                    return None

                responses = util.addlevel(responses, 'seed', seed)
                spike_counts = util.addlevel(spike_counts, 'seed', seed)

                # TODO assert order of wPNKC columns same in each?
                wPNKC = util.addlevel(wPNKC, 'seed', seed)

                if first_param_dict is None:
                    first_param_dict = param_dict
                else:
                    assert param_dict.keys() == first_param_dict.keys()

                responses_list.append(responses)
                spikecounts_list.append(spike_counts)
                param_dict_list.append(param_dict)

                wPNKC_list.append(wPNKC)

            responses = pd.concat(responses_list, verify_integrity=True)
            spike_counts = pd.concat(spikecounts_list, verify_integrity=True)
            wPNKC = pd.concat(wPNKC_list, verify_integrity=True)

            param_dict = {
                k: [x[k] for x in param_dict_list] for k in first_param_dict.keys()
            }
        else:
            # TODO need to support int type too (in both of the two isinstance calls
            # below)? isinstance(<int>, float) is False!!!

            # isinstance works w/ both float and scalar np.float64 (but not int)
            # TODO update to include ndarray
            #assert fixed_thr is None or isinstance(fixed_thr, float)

            # NOTE: wKCAPL is set from wAPLKC, if only wAPLKC is passed. The reverse is
            # not true though, so if only one is passed, it must be wAPLKC.
            # TODO need to support int type too (in both of the two isinstance calls
            # below)? isinstance(<int>, float) is False
            assert wAPLKC is None or isinstance(wAPLKC, float)

            # TODO rename param_dict everywhere -> tuned_params?
            responses, spike_counts, wPNKC, param_dict = fit_mb_model(
                sim_odors=sim_odors, fixed_thr=fixed_thr, wAPLKC=wAPLKC, **model_kws
            )

        print('done', flush=True)

        orn_deltas = None
        if responses_to != 'hallem':
            orn_deltas = model_kws['orn_deltas']
            input_odors = orn_deltas.columns
        else:
            # NOTE: not saving model input (the Hallem ORN deltas) here, b/c it's added
            # by fit_mb_model internally, and it should be safe to assume this will not
            # change across runs. If it does change, hopefully the history of that is
            # accurately reflected in commit history of my drosolf repo.
            # TODO maybe refactor so i can define orn_deltas for this case too (and thus
            # so it's also saved below in that case)?
            n_hallem_odors = 110
            assert responses.shape[1] >= n_hallem_odors
            input_odors = responses.columns[:n_hallem_odors]

        # remove any odors added by `extra_orn_deltas` code (internal to fit_mb_model)
        if len(input_odors) < responses.shape[1]:
            if 'panel' in input_odors.names:
                input_odors = input_odors.droplevel('panel')

            assert responses.columns[:len(input_odors)].equals(input_odors)
            # (defined as None above)
            extra_responses = responses.iloc[:, len(input_odors):].copy()
            extra_spikecounts = spike_counts.iloc[:, len(input_odors):].copy()

            responses = responses.iloc[:, :len(input_odors)].copy()
            spike_counts = spike_counts.iloc[:, :len(input_odors)].copy()

        del input_odors

        # TODO TODO also pass in + save a copy of full input ORN data (same as in
        # ij_certain-roi_stats.[csv|p], maybe just load that in here, to not need to
        # pass? assuming mtime is since the start of run?). or just shutil copy
        # ij_certain-roi_stats.[csv+p]?
        if orn_deltas is not None:
            # just saving these for manual reference, or for use in -c check.
            # not loaded elsewhere in the code.
            to_pickle(orn_deltas, param_dir / 'orn_deltas.p')

            # TODO also save a hemibrain-filled version of this?
            #
            # current format like:
            # panel	megamat	         megamat          ...
            # odor	2h @ -3	         IaA @ -3         ...
            # glomerulus
            # D	40.845711426286  37.2453183810278 ...
            # DA2	15.325702916103	 11.4666387062239 ...
            # ...
            to_csv(orn_deltas, param_dir / 'orn_deltas.csv')

        # NOTE: saving raw (unsorted, etc) responses to cache for now, so i can modify
        # that bit. CSV saving is currently after all sorting / post-processing.
        to_pickle(responses, model_responses_cache)
        to_pickle(spike_counts, model_spikecounts_cache)
        to_pickle(wPNKC, wPNKC_cache)

        # TODO if i start using return_dynamics=True (w/ automatic xarray saving
        # discussed in comment below), prob default to (/always) return_dynamics=False
        # for sensitivity analysis subcalls? or is it not enough data that's really that
        # much of an issue? what size we talking?
        # TODO some nice interchange (so, not pickle) format for xarray? netcdf?
        # [also] use that?
        #
        # TODO TODO automatically pop and save anything that's a
        # np.ndarray/pd.[Series|DataFrame] [/xarray, if i end up using that for model
        # dynamics?], and save as a pickle under the name of the key? (maybe just
        # warning if it's not on a list of expected things, w/ message about which
        # variable to add the name to?
        # (-> use for this [+ wAPLKC/wKCAPL, in use_connectome_APL_weights=True case,
        # where they are vector]?)
        # (would then also be useful if i sometimes return model dynamics, like vm_sims,
        # using the same dict)
        # NOTE: might break some of new vector-fixed_thr code if i start popping that
        # (but might want to still save separately there, as not being saved correctly
        # in params.csv/similar there)
        #
        _warned = False
        for k in list(param_dict.keys()):
            v = param_dict[k]
            # TODO also do for np.ndarray / Series / DataFrame?
            if isinstance(v, xr.DataArray):
                if not _in_sens_analysis:
                    pickle_path = param_dir / f'{k}.p'
                    # for just panel=control, the biggest of these files
                    # (spike_recordings.p / vm_sims.p) are just under a GB (768M)
                    to_pickle(v, pickle_path)

                    # TODO switch to netcdf? would just need to reformat the index
                    # surrounding IO (prob don't wanna do both given the sizes, but
                    # could. ig it's just a factor of 2...)
                else:
                    if not _warned:
                        warn('not saving dynamics for sensitivity analysis sub-calls,'
                            ' to save on storage space'
                        )
                        # not just `break`-ing, since i still want to pop all these from
                        # param_dict
                        _warned = True

                del param_dict[k]

        # popping to have this make old outputs trip -c/-C checks, but also the param
        # CSVs/etc would almost certainly not handle array/series values, at least not
        # without extra work
        kc_spont_in = param_dict.pop('kc_spont_in')
        to_pickle(kc_spont_in, kc_spont_in_cache)

        # currently just assuming that both will be in same format
        # (both either np.arrays/pd.Series [depending on which i end up settling on
        # for implementation] in only use_connectome_APL_weights=True case)
        wAPLKC = param_dict.get('wAPLKC', None)
        # TODO need to support int type too (in all isinstance calls below)?
        # isinstance(<int>, float) is False
        if wAPLKC is not None and not isinstance(wAPLKC, float):
            # only want to pop anything in this branch, cause other code depends on
            # these values still being in param_dict
            # TODO TODO is that true for any variable_n_claws cases? any of those depend
            # on them still being in param dict?
            wAPLKC = param_dict.pop('wAPLKC')
            wKCAPL = param_dict.pop('wKCAPL')

            if not variable_n_claws:
                # TODO will this always be true? added after other assertions here
                assert use_connectome_APL_weights
                #
                assert hasattr(wAPLKC, 'shape') and len(wAPLKC.shape) == 1

                assert 'wAPLKC_scale' in param_dict
                assert 'wKCAPL_scale' in param_dict

                assert wKCAPL.shape == wAPLKC.shape
            else:
                # may work as-is, but then it'd be a list of arrays? would need to test
                assert not use_connectome_APL_weights

                assert 'wAPLKC_scale' not in param_dict
                assert 'wKCAPL_scale' not in param_dict

                assert type(wAPLKC) is list and all(
                    isinstance(x, float) for x in wAPLKC
                )
                # TODO i assume lists cause same issues as arrays, if left in
                # param_dict?
                # TODO TODO want to pickle the lists as-is in variable_n_claws case, or
                # something else?

            to_pickle(wAPLKC, wAPLKC_cache)
            to_pickle(wKCAPL, wKCAPL_cache)
        else:
            # in this branch, wAPLKC/wKCAPL should be in a format (e.g. single
            # scalar floats) where they don't cause issues if saved as part of
            # param_dict, so we don't need to separately save to w[APLKC|KCAPL]_cache

            wKCAPL = param_dict['wKCAPL']
            # TODO need to support int type too (in both of the two isinstance calls
            # below)? isinstance(<int>, float) is False
            assert wKCAPL is None or isinstance(wKCAPL, float)

        # In n_seeds=1 case, param_dict keys are:
        # 'fixed_thr', 'wAPLKC', and 'wKCAPL' (all w/ scalar values)
        # ...as well as several other values relevant for APL tuning.
        #
        # In use_connectome_APL_weights=True case:
        # 1. param_dict also contains ['wAPLKC_scale', 'wKCAPL_scale'] which are scalars
        #    that were used to scale wAPLKC/wKCAPL during APL tuning.
        #
        # 2. wAPLKC/wKCAPL are scaled connectome weight vectors now, which will be
        #    popped from params below (before params saved to CSV/pickle), and pickled
        #    separately.
        #
        # in n_seeds > 1 case, should be same keys, but list values (of length equal to
        # n_seeds)
        to_pickle(param_dict, param_dict_cache)

        # TODO don't save in sensitivity analysis subcalls? as this should not change
        # across those
        to_csv(wPNKC, param_dir / 'wPNKC.csv', verbose=(not _in_sens_analysis))

        # saving after all the other things, so that (if script run w/ -c) checks
        # against old/new outputs have an opportunity to trip and fail before this is
        # written
        if extra_responses is not None:
            assert extra_spikecounts is not None
            to_pickle(extra_responses, extra_responses_cache)
            to_pickle(extra_spikecounts, extra_spikecounts_cache)
        else:
            assert extra_spikecounts is None

            # delete any existing extra_responses pickles
            # (don't want stale versions of these being loaded alongside newer
            # responses.p data)
            if extra_responses_cache.exists():
                extra_responses_cache.unlink()

            if extra_spikecounts_cache.exists():
                extra_spikecounts_cache.unlink()

    # param_dict should include 'fixed_thr', 'wAPLKC' and 'wKCAPL' parameters, as they
    # are at the end of the model run (either tuned or hardcoded-from-the-beginning).
    #
    # In use_connectome_APL_weights=True case, wAPLKC/wKCAPL were vector, and have
    # already been popped from param_dict and pickled above. w[APLKC|KCAPL]_scale are
    # scalars in that case (used to multiply by unit-mean vector wAPLKC/wKCAPL), which
    # can be used/interpreted similarly to scalar wAPLKC/wKCAPL we get from other cases.
    assert not any(k in params_for_csv for k in param_dict.keys())
    params_for_csv.update(param_dict)

    # NOTE: if there were ever different number of cells for the different seeds (in the
    # cases where the row index has a 'seed' level, in addition to the 'cell' level,
    # e.g. the pn2kc_connections='uniform' case), then we'd want to compute sparsities
    # within seeds and then average those (to not weight different MB instantiations
    # differently, which is consistent w/ how Remy mean sparsity computed on real fly
    # data).
    sparsity = (responses > 0).mean().mean()
    params_for_csv['sparsity'] = sparsity

    # TODO factor out this subsetting to (internal?) fn? or just use megamat_responses
    # directly below?
    # TODO .get_level_values if i restore panel level preservation thru fit_mb_model
    megamat_mask = responses.columns.map(odor_is_megamat)

    # should be true in both hallem (which has ~110 odors, including all the 17
    # megamat) and pebbled-megamat input cases
    have_megamat = megamat_mask.values.sum() >= 17

    if have_megamat:
        megamat_responses = responses.loc[:, megamat_mask]
        megamat_sparsity = (megamat_responses > 0).mean().mean()
        del megamat_responses
        params_for_csv['megamat_sparsity'] = megamat_sparsity

    if extra_params is not None:
        assert not any(k in params_for_csv for k in extra_params.keys())
        params_for_csv.update(extra_params)

    # TODO does param_series have anything useful for repro that we dont have in
    # params_for_csv.p (param_dict_cache, saved earlier)?
    param_series = pd.Series(params_for_csv)
    try:
        # just to manually inspect all relevant parameters for outputs in a given
        # param_dir
        to_csv(param_series, param_dir / 'params.csv', header=False,
            # NOTE: only ignoring b/c adding the use_cache=True/False component of these
            # is now causing -c/-C checks to fail when I otherwise don't really want
            # them too.
            # TODO also build in a way to only ignore the changes if the change matches
            # what we expect (i.e. just a change in this use_cache=True/False line)?
            # TODO maybe replace w/ just saving the use_cache value to its own file?
            ignore_output_change_check='warn',
            #
            verbose=(not _in_sens_analysis)
        )

    # TODO change code to avoid this happening in the first place?
    # (should only happen on second call used for getting inh params on a panel set, to
    # then run a model with a single panel and those inh params later)
    except MultipleSavesPerRunException:
        if _only_return_params:
            return params_for_csv
        else:
            raise

    del param_series

    # TODO even need to rename at this point? anything downstream actually not work with
    # 'odor' instead of 'odor1'?
    # TODO just fix natmix.plot_corr to also work w/ level named 'odor'?
    # (or maybe odor_corr_frame_to_dataarray?)
    #
    # even if input to fit_mb_model has a 'panel' level on odor index, the output will
    # not
    assert len(responses.columns.shape) == 1 and responses.columns.name == 'odor'
    responses.columns.name = 'odor1'

    # TODO fix (when called from model_banana_iaa_concs.py). need a panel level?
    assert len(spike_counts.columns.shape) == 1 and spike_counts.columns.name == 'odor'
    spike_counts.columns.name = 'odor1'

    panel = None
    if responses_to == 'hallem':
        assert have_megamat
        # the non-megamat odors will just be sorted to end
        panel = 'megamat'
    else:
        orn_deltas = model_kws['orn_deltas']
        assert 'panel' in orn_deltas.columns.names

        panels = set(orn_deltas.columns.get_level_values('panel'))
        del orn_deltas

        if len(panels) == 1:
            panel = panels.pop()
            assert type(panel) is str
        else:
            # should currently only be true in the calls w/ multiple panel inputs (e.g.
            # for pre-tuning on kiwi+control, to then run this fn w/ just kiwi input).
            # just gonna return early w/ params, skipping this stuff, fow now.
            panel = None

    if panel is not None:
        responses = sort_odors(responses, panel=panel, warn=False)
        spike_counts = sort_odors(spike_counts, panel=panel, warn=False)

    # TODO update these wrappers to also make dir if not exist (if they don't already)
    to_csv(responses, param_dir / 'responses.csv', verbose=(not _in_sens_analysis))
    to_csv(spike_counts, param_dir / 'spike_counts.csv',
        verbose=(not _in_sens_analysis)
    )

    if _only_return_params:
        return params_for_csv

    # TODO delete? should be handled by _only_return_params (cases they are triggered
    # should be the same)
    if panel is None:
        # TODO is there any code below that actually doesn't work w/ multiple panels?
        # care to get plots (prob not)?
        warn('returning from fit_and_plot_model before making plots, because input had'
            ' multiple panels (currently unsupported)'
        )
        return params_for_csv
    #

    # TODO use one/both of these col defs outside of just for s1d?
    odor_col = 'odor1'
    sparsity_col = 'response rate'

    def _per_odor_tidy_model_response_rates(responses: pd.DataFrame) -> pd.DataFrame:
        """Returns dataframe with [odor_col, sparsity_col [, 'seed']] columns.

        Returned dataframe also has a 'seed' column, if input index has a 'seed' level,
        with response rates computed within each 'seed' value in input.
        """
        # TODO warn / err if there are no silent cells in responses (would almost
        # certainly indicate mistake in calling code)?

        if 'seed' in responses.index.names:
            response_rates = responses.groupby('seed', sort=False).mean()
            assert response_rates.columns.name == odor_col
            assert response_rates.index.name == 'seed'

            response_rates = response_rates.melt(value_name=sparsity_col,
                # ignore_index=False to keep seed
                ignore_index=False
            ).reset_index()

            assert 'seed' in response_rates.columns
            assert odor_col in response_rates.columns
        else:
            response_rates = responses.mean()
            assert response_rates.index.name == odor_col
            response_rates = response_rates.reset_index(name=sparsity_col)

        return response_rates


    # TODO rename to plot_and_save... / something? consistent way to indicate which of
    # my plotting fns (also) save, and which do not?
    # TODO refactor to use this for s1d (maybe w/ boxplot=True option or something?
    # requiring box plot if there are multiple seeds on input?)?
    # TODO move def outside of fit_and_plot... (near plot_n_odors_per_cell def?)?
    def plot_sparsity_per_odor(sparsity_per_odor, comparison_sparsity_per_odor, suffix,
        *, ylim=None) -> Tuple[Figure, Axes]:

        fig, ax = plt.subplots()
        # TODO rename sparsity -> response_fraction in all variables / col names too
        # (or 'response rate'/response_rate, now in col def for s1d?)
        ylabel = 'response fraction'

        title = title_including_silent_cells

        err_kws = dict()
        if 'seed' in sparsity_per_odor.columns:
            assert n_first_seeds_for_errorbar is None, 'implement here if using'

            # TODO factor (subset of?) these kws into a seed_errorbar_style_kws or
            # something? to share these w/ plot_n_odors_per_cell (+ other places that
            # should use same errorbar style)
            #
            # TODO have markerfacecolor='None', whether or not we want to show
            # errorbars (maybe after a -c check that hemibrain stuff unchanged w/o)?
            err_kws = dict(markerfacecolor='white', errorbar=seed_errorbar,
                seed=bootstrap_seed, err_style='bars'
            )
            # TODO refactor to share w/ place copied from (plot_n_odors_per_cell)?
            if title is None:
                title = seed_err_text
            else:
                title += f'\n{seed_err_text}'

        color = 'blue'
        sns.lineplot(sparsity_per_odor, x=odor_col, y=sparsity_col, color=color,
            marker='o', markeredgecolor=color, legend=False, label=ylabel, ax=ax,
            **err_kws
        )
        if comparison_sparsity_per_odor is not None:
            # TODO how to label this? label='tuned'?
            color = 'gray'
            sns.lineplot(comparison_sparsity_per_odor, x=odor_col, y=sparsity_col,
                color=color, marker='o', markeredgecolor=color, legend=False,
                label=f'{ylabel} (tuned)', ax=ax, **err_kws
            )

        # renaming from column name odor_col
        ax.set_xlabel('odor'
            f'\nmean response rate: {sparsity_per_odor[sparsity_col].mean():.3g}'
        )

        # TODO add dotted line for target sparsity, when applicable?

        rotate_xticklabels(ax, 90)

        ax.set_title(title)
        ax.set_ylabel(ylabel)

        # TODO assert no NaN (closer to start of fn? why not def this up there?)?
        response_rates = sparsity_per_odor[sparsity_col]

        if ylim is not None:
            ymin, ymax = ylim
            assert (response_rates <= ymax).all(), f'{response_rates.max()=}'
        else:
            ymin = 0
            ymax = response_rates.max()

        assert (response_rates >= ymin).all(), f'{response_rates.min()=}'

        if comparison_sparsity_per_odor is not None:
            comparison_response_rates = comparison_sparsity_per_odor[sparsity_col]

            if ylim is None:
                ymax = max(ymax, comparison_response_rates.max())
            else:
                assert (comparison_response_rates >= ymin).all(), \
                    f'{comparison_response_rates.min()=}'

                # TODO just warn and increase max in cases where this would fail
                assert (comparison_response_rates <= ymax).all(), \
                    f'{comparison_response_rates.max()=}'

        ax.set_ylim([ymin, ymax])

        savefig(fig, param_dir, f'sparsity_per_odor{suffix}')
        return fig, ax


    repro_preprint_s1d = model_kws.get('repro_preprint_s1d', False)

    eb_mask = responses.columns.get_level_values(odor_col).str.startswith('eb @')
    try:
        assert eb_mask.sum() <= 1
    # TODO TODO fix. sum is 2, but why? or why isn't it always in
    # repro_preprint_s1d=True case?
    #
    # ipdb> responses.shape
    # (1630, 110)
    # ipdb> responses.columns.get_level_values(odor_col)[eb_mask]
    # Index(['eb @ -2', 'eb @ -2'], dtype='object', name='odor1')
    except AssertionError:
        import ipdb; ipdb.set_trace()

    # should only be true if panel is validation2 (pebbled/megamat or hallem should
    # both have it)
    if repro_preprint_s1d and eb_mask.sum() == 0:
        repro_preprint_s1d = False

    if repro_preprint_s1d:
        assert extra_responses is not None

        s1d_responses = pd.concat([extra_responses, responses.loc[:, eb_mask]],
            axis='columns', verify_integrity=True
        )
        # (extra_responses still had 'odor' and responses had 'odor1' at time of concat)
        s1d_responses.columns.name = odor_col

        s1d_sparsities = _per_odor_tidy_model_response_rates(s1d_responses)

        # TODO delete 1 of these 2 plots below?

        fig, ax = plt.subplots()
        # TODO TODO adjust formatting so outlier points don't overlap (reduce alpha /
        # jitter?) (see pebbled/hemidraw one, which may be the one we want to use)
        sns.boxplot(data=s1d_sparsities, x=odor_col, y=sparsity_col, ax=ax, color='k',
            fill=False, flierprops=dict(alpha=0.175)
        )
        ax.set_title(title_including_silent_cells)
        savefig(fig, param_dir, 's1d_private_odor_sparsity')

        # TODO rewrite plot_sparsity... to make these 2nd arg optional?
        plot_sparsity_per_odor(s1d_sparsities, None, '_s1d')


    responses_including_silent = responses.copy()
    # TODO TODO what did Ann do for this?
    # (Matt did not drop silent cells. not sure about what Ann did.)
    if drop_silent_cells_before_analyses:
        # NOTE: important this happens after def of sparsity above
        responses = drop_silent_model_cells(responses)
        # TODO in n_seeds > 1 case, use old suffix w/o saying total numbers of cells?
        # (or some other format?)
        title += _get_silent_cell_suffix(responses_including_silent, responses)

    # TODO delete (/ move up before early return, right after sparsity calc)
    # TODO is there a big mismatch betweeen target_sparsity and sparsity (yes, see
    # below)?
    # TODO err / warn if differs much at all
    # TODO inspect cases where it differs (including olfsysm log)
    # (seems like nearly every case differs somewhat seriously)
    # ...
    # fitting model (responses_to='pebbled', tune_on_hallem=True,
    #   drop_receptors_not_in_hallem=True, pn2kc_connections=hemibrain,
    #   target_sparsity=0.1)...
    # ...
    # model_kws.get("target_sparsity")=0.1
    # sparsity=0.1804732780428448
    # ...
    # fitting model (responses_to='pebbled', tune_on_hallem=True,
    #   drop_receptors_not_in_hallem=True, pn2kc_connections=hemibrain,
    #   target_sparsity=0.05)...
    # ...
    # fixed_thr: 221.8443262928323
    # wAPLKC: 5.523460576698389
    # wKCAPL: 0.0030067831119751703
    # done
    # responses.shape=(1837, 17)
    # model_kws.get("target_sparsity")=0.05
    # sparsity=0.08511319606775754
    #
    # TODO TODO anything i can change to make tuning converge better?
    # relevant parameters:
    # rv.kc.tuning_iters (not a cap tho, just to keep track of it?)
    # mp.kc.max_iters (a cap for above) (default=10)
    # mp.kc.apltune_subsample (default=1)
    # mp.kc.sp_lr_coeff (initial learning rate, from which subsequent iteration learning
    #     rates decrease w/ sqrt num iters i think) (default=10.0)
    #
    #     ...
    #     double lr = p.kc.sp_lr_coeff / sqrt(double(rv.kc.tuning_iters));
    #     double delta = (sp - p.kc.sp_target) * lr/p.kc.sp_target;
    #     rv.kc.wAPLKC.array() += delta;
    #     ...
    #
    # mp.kc.sp_acc (the tolerance acceptable) (default=0.1)
    #     "the fraction +/- of the given target that is considered an acceptable
    #     sparsity"
    #
    # tuning proceeds while: ( (abs(sp-p.kc.sp_target)>(p.kc.sp_acc*p.kc.sp_target)) &&
    # (rv.kc.tuning_iters <= p.kc.max_iters) )
    if 'target_sparsity' in model_kws:
        target_sparsity = model_kws['target_sparsity']
        print()
        print(f'target_sparsity={target_sparsity:.3g}')
        print(f'sparsity={sparsity:.3g}')

        adiff = sparsity - target_sparsity
        rdiff = adiff / target_sparsity
        # TODO TODO use to inspect improvement when increasing tuning time (+ also
        # time model running, to see how much extra time extra tuning adds)
        print(f'{(rdiff * 100):.1f}% rel sparsity diff')
        print(f'{adiff:.2g} abs sparsity diff')

        # TODO TODO assert one/both below some threshold? warn above some thresh?

        # TODO delete?
        # TODO what fraction is passing atol=0.005? should i make it higher? .01?
        # (at least for target_sparsity=.1, w/ other params in the single choice i
        # actually do sens analysis on, it's only off by ~.009...)
        #if not np.isclose(sparsity, model_kws['target_sparsity'], atol=0.005):
        #    import ipdb; ipdb.set_trace()

        if have_megamat:
            if not np.isclose(megamat_sparsity, sparsity):
                print(f'megamat_sparsity={megamat_sparsity:.3g}')

        print()
    #

    # TODO drop panel here (before computing) if need be (after switching to pass input
    # that has that as a level on odor axis)
    if responses.index.name is None and 'seed' in responses.index.names:
        # TODO TODO refactor to use new mean_of_fly_corrs (passing in 'seed' for id
        # level)?
        corr_list = []
        seeds = []
        # level=<x> vs <x> didn't seem to matter here (at least, checking seed_corrs
        # after concat)
        for seed, seed_df in responses.groupby(level='seed', sort=False):
            seeds.append(seed)

            # each element of list is a Series now, w/ a 2-level multiindex for odor
            # combinations
            # NOTE: odor levels currently ('odor1', 'odor1') (SAME NAME, which might
            # cause problems...)
            corr_list.append(corr_triangular(seed_df.corr()))

        seed_corrs = pd.concat(corr_list, axis=1, keys=seeds, names='seed',
            verify_integrity=True
        )
        assert list(seed_corrs.columns) == seeds

        # converts from (row=['odor1','odor2'] X col='seed') to
        # row=['odor1','odor2','seed'] series
        # TODO TODO TODO has adding dropna=False broken anything? it was to fix odor
        # pairs not matching up in merge in comparison_orns code below
        # (only was triggered in hallem/uniform case)
        seed_corr_ser = seed_corrs.stack(dropna=False)

        # TODO can i convert below comment to an assertion / delete then (seems from
        # parenthetical below i felt i had figured it out)
        # TODO why is len(seed_corr_ser) (or len(model_corr_df)) == 56290, while
        # seed_corrs.size == 59950 (= n_seeds (10) * 5995 (= [110**2 - 110]/2) )
        # ipdb> seed_corrs.size - seed_corrs.isna().sum().sum()
        # 56290
        # (so it's just NaN elements that are the issue)
        seed_corr_ser.name = 'model_corr'
        model_corr_df = seed_corr_ser.reset_index()

        # TODO rename to 'odor_a', 'odor_b'? (here and in *corr_triangular?)? assuming
        # 'odor2' here isn't the for-mixtures 'odor2' i often have in odor
        # multiindices...
        odor_levels = ['odor1', 'odor2']
        mean_pearson_ser = seed_corr_ser.groupby(level=odor_levels, sort=False).mean()

        # TODO below 2 comments still an issue?
        # TODO TODO fix! (only in hallem/uniform, after no longer only passing
        # megamat odors as sim_odors)
        # TODO TODO check at input of this what is reducing length of
        # triangular series below expected shape. missing at least (in either order):
        # a='g-decalactone @ -2'
        # b='glycerol @ -2'
        try:
            # TODO rename _index kwarg?
            # TODO TODO +fix so i don't need to pass it (what was the purpose of
            # passing it again? doc in comment) (doesn't seem to still be triggering?)
            pearson = invert_corr_triangular(mean_pearson_ser, _index=seed_corrs.index)
        except AssertionError:
            print()
            traceback.print_exc()
            print()
            import ipdb; ipdb.set_trace()
    else:
        pearson = responses.corr()

        corr_ser = corr_triangular(pearson)
        corr_ser.name = 'model_corr'
        model_corr_df = corr_ser.reset_index()

        # TODO just start w/ 'odor_a', 'odor_b' here, to avoid issues later?
        # or even 'odor_row', 'odor_col'?
        #
        # just to match invert_corr_triangular output above (from 'odor1' for both here)
        pearson.index.name = 'odor'
        pearson.columns.name = 'odor'

    pearson = _resort_corr(pearson, panel,
        warn=False if responses_to == 'hallem' else True
    )

    # TODO TODO try deleting this and checking i can remake all the same
    # megamat/validation plots? feel like i might not need this anymore (or maybe i want
    # to stop needing it anyway... could then support mix dilutions for kiwi/control)
    # TODO refactor to share w/ other places?
    def _strip_index_and_col_concs(df):
        assert df.index.name.startswith('odor')
        assert df.columns.name.startswith('odor')

        # assuming no duplicate odors in input
        assert len(set(df.index)) == len(df.index)
        assert len(set(df.columns)) == len(df.columns)

        # TODO just use hong2p.olf.parse_odor_name instead of all this?
        delim = ' @ '
        assert df.index.str.contains(delim).all()
        assert df.columns.str.contains(delim).all()
        df = df.copy()
        df.index = df.index.map(lambda x: x.split(delim)[0])
        df.columns = df.columns.map(lambda x: x.split(delim)[0])
        #

        # TODO delete try/except (did i not rename diag 'ms @ -3' appropriately?)
        try:
            # assuming dropping concentration info hasn't created duplicates
            # (which would happen if input has any 1 odor presented at >1 conc...)
            assert len(set(df.index)) == len(df.index)

        # TODO TODO fix how this now trips from scripts/model_banana_iaa_concs.py
        except AssertionError:
            # TODO deal with other odors duplicated
            # (either by also mangling before, like 'ms @ -3' -> 'diag ms @ -3', or by
            # subsetting after?)
            # ipdb> df.index.value_counts()
            # 2h         2
            # t2h        2
            # aphe       2
            # 2-but      2
            # va         2
            # 1-6ol      2
            print(f'{len(set(df.index))=}')
            print(f'{len(df.index)=}')

            # TODO also, why are 'pfo' row / col NaN here (including identity...)? data?
            # mishandling? want to drop pfo anyway?

            # TODO TODO has air mix been handled appropriately up until here?
            # seeems like we may have just dropped odor2 and lumped them in w/ ea/oct,
            # which would be bad. prob want to keep air mix? could also drop and just
            # use in-vial 2-component mix

            raise
            # (not currently an issue since i added the hack to move conc info to name
            # part for those odors)
            # TODO fix for new kiwi vs control data
            # (seems to be caused by dilutions of mixture. just drop those first? could
            # call the natmix fn for that)
            #import ipdb; ipdb.set_trace()

        assert len(set(df.columns)) == len(df.columns)
        return df

    try:
        pearson = _strip_index_and_col_concs(pearson)
    except AssertionError:
        warn('_strip_index_and_col_concs failed with AssertionError! probably have '
            'multiple concs for some odors. skipping rest of plots.'
        )
        return params_for_csv

    if _in_sens_analysis:
        assert fixed_thr is not None and wAPLKC is not None

        if use_connectome_APL_weights:
            wAPLKC = params_for_csv['wAPLKC_scale']
            assert wAPLKC is not None

            wKCAPL = params_for_csv['wKCAPL_scale']
            assert wKCAPL is not None

        if ((min_sparsity is not None and sparsity < min_sparsity) or
            (max_sparsity is not None and sparsity > max_sparsity)):

            warn(f'sparsity out of [{min_sparsity}, {max_sparsity}] bounds! returning '
                'without making plots!'
            )

            # TODO register atexit instead (use some kind of wrapped dir creation fn
            # that handles that for me automatically? factor out of savefig/whatever i
            # have that currently does something like that?)?
            if made_param_dir:
                # TODO err here if -c CLI arg passed?
                print('deleting {param_dir}!')
                shutil.rmtree(param_dir)

            return params_for_csv

        # don't think i wanted to return this for stuff outside sparsity bounds
        # (return above)
        params_for_csv['pearson'] = pearson

        if n_seeds == 1:
            # TODO refactor all this thr str handling? duplicated a fair bit now...
            if isinstance(fixed_thr, float):
                thr_str = f'thr={fixed_thr:.2f}'
            else:
                assert isinstance(fixed_thr, np.ndarray)
                thr_str = f'mean_thr={fixed_thr.mean():.2f}'

            title = (
                f'{thr_str}, wAPLKC={wAPLKC:.2f} (sparsity={sparsity:.3g})'
            )
        else:
            title = f'sparsity={sparsity:.3g}'

    plot_corr(pearson, param_dir, 'corr', xlabel=title)

    if responses_to == 'hallem':
        # TODO factor to use len(megamat_odor_names) / something instead of 17...
        #
        # all megamat odors should have been sorted before other hallem odors, so we
        # should be able to get the megamat17 subset by indexing this way
        plot_corr(pearson.iloc[:17, :17], param_dir, 'corr_megamat', xlabel=title)
    #

    def _compare_model_kc_to_orn_data(comparison_orns, desc=None):
        # TODO assert input odors match comparison_orns odors exactly?
        # (currently stripping conc in at least corr diff case?)
        # (or assert around merge below, that we have all same odor pairs in both
        # dataframes being merged)

        if desc is None:
            orn_fname_part = 'orn'
            # might cause some confusion if comparison_orns are hallem data...
            orn_label_part = 'ORN'
        else:
            # assuming we don't need to normalize desc for filename
            orn_fname_part = f'orn-{desc}'
            orn_label_part = f'ORN ({desc})'

        # TODO switch to checking if ['date', 'fly_num'] (or 'fly_id') in column levels,
        # maybe adding an assertion columns.name == 'glomerulus' if not? might make it
        # nicer to refactor into plot_corr (for deciding whether to call
        # mean_of_fly_corrs)
        if comparison_orns.columns.name == 'glomerulus':
            mean_orn_corrs = corr_triangular(comparison_orns.T.corr())
        else:
            assert comparison_orns.columns.names == ['date', 'fly_num', 'roi']
            # will exclude NaN (e.g. va/aa in first 2 megamat flies)
            mean_orn_corrs = mean_of_fly_corrs(comparison_orns, square=False)

        mean_orn_corrs.name = 'orn_corr'

        model_corr_df_odor_pairs = set(
            model_corr_df.set_index(['odor1', 'odor2']).index
        )
        orn_odor_pairs = set(mean_orn_corrs.index)

        # NOTE: changing abbrev_hallem_odor_index will likely cause this to fail if
        # model outputs are not also regenerated (via CLI arg `-i model`)
        assert model_corr_df_odor_pairs == orn_odor_pairs

        # TODO delete? seems like it would fail if any NaN...
        assert len(mean_orn_corrs.values) == len(np.unique(mean_orn_corrs.values))

        df = model_corr_df.merge(mean_orn_corrs, on=['odor1', 'odor2'])

        # TODO any reason to think this is actually an issue? couldn't we just
        # have bona fide duplicate corrs (yea, we prob do)?
        #
        # 2024-05-17: still an issue (seemingly only in hallem/uniform case, not
        # pebbled/uniform or hallem/hemibrain)
        #
        # TODO fix to work w/ some NaN corr values?
        # TODO was this actually caused by duplicate correlat
        # TODO why just failing in hallem/uniform, and not hallem/hemibrain,
        # case? both have some NaN kc corrs... (i think it was probably more a matter of
        # one having duplicate corrs...)
        # TODO TODO was this actually duplicate corrs though? that would make more sense
        # for KC outputs w/ small number of inputs (maybe?), but in ORN inputs?
        try:
            assert len(mean_orn_corrs.values) == len(np.unique(df['orn_corr']))
        except AssertionError:
            # TODO actually summarize these if i want to keep warn here at all?
            # or just delete?
            warn('some duplicate corrs! (may not actually be an issue...)')
            # ipdb> len(mean_orn_corrs.values)
            # 5995
            # 2024-05-20: this is now 5886 (one NaN? no)
            # ipdb> len(np.unique(df['orn_corr']))
            # 5885
            #import ipdb; ipdb.set_trace()

        # converting to correlation distance, like in matt's
        df['model_corr_dist'] = 1 - df['model_corr']
        df['orn_corr_dist'] = 1 - df['orn_corr']

        # TODO only do in megamat case
        df['odor1_is_megamat'] = df.odor1.map(odor_is_megamat)
        df['odor2_is_megamat'] = df.odor2.map(odor_is_megamat)
        df['pair_is_megamat'] = df[['odor1_is_megamat','odor2_is_megamat']
            ].all(axis='columns')

        if n_first_seeds_for_errorbar is not None and 'seed' in df.columns:
            df = select_first_n_seeds(df)

        def _save_kc_vs_orn_corr_scatterplot(metric_name: str) -> None:
            # to recreate preprint fig 3B

            if metric_name == 'correlation distance':
                col_suffix = '_corr_dist'

                # TODO rename dists -> dist (to share w/ col_suffix -> deleting this
                # after)?
                fname_suffix = '_corr_dists'

                # TODO double check language
                help_str = 'top-left: decorrelated, bottom-right: correlated'

                # TODO just derive bounds for either corr or corr-dist version from the
                # other -> consolidate to share assertion?
                # (/ refactor some other way...)
                plot_max = 1.5
                plot_min = 0.0

            elif metric_name == 'correlation':
                col_suffix = '_corr'
                fname_suffix = '_corr'

                # confident in language on this one
                help_str = 'top-left: correlated, bottom-right: decorrelated'

                plot_max = 1
                plot_min = -.5
            else:
                assert False, 'only above 2 metric_name values supported'

            if 'seed' in df.columns:
                errorbar = seed_errorbar
            else:
                # no seeds to compute CI over here. sns.lineplot would generate a
                # RuntimeWarning (about an all-NaN axis), if I tried to generate error
                # bars same way.
                errorbar = None

            if not df.pair_is_megamat.all():
                # just removing errorbar b/c was taking a long time and don't really
                # care about this plot anymore... (shouldn't take long if not using
                # bootstrapped CI, if i change errorbar)
                errorbar = None

                color_kws = dict(
                    hue='pair_is_megamat', hue_order=[False, True],
                    # TODO also try to have diff err/marker alphas here? prob not worth
                    # it, considering i don't really use this version of the plots...
                    palette={True: to_rgba('red', 0.7), False: to_rgba('black', 0.1)}
                )
            else:
                color_kws = dict(color='black')

            fig, ax = plt.subplots()
            add_unity_line(ax)

            orn_col = f'orn{col_suffix}'
            model_col = f'model{col_suffix}'

            lineplot_kws = dict(
                ax=ax, data=df, x=orn_col, y=model_col, linestyle='None',
            )
            lineplot_kws = {**lineplot_kws, **color_kws}

            marker_only_kws = dict(
                markers=True, marker='o', errorbar=None,

                # to remove white edge of markers (were not respecting alpha)
                # (seem to work file w/ alpha, at least when set in non-'palette' case
                # below... was probably an issue when using hue/palette?)
                markeredgecolor='none',
            )
            # TODO should point / error display not be consistent between this and S1C /
            # 2E?
            err_only_kws = dict(
                markers=False, errorbar=errorbar, err_style='bars', seed=bootstrap_seed,
                # TODO make these thinner (to not need such fine tuning on alpha?)?
            )
            # more trouble than worth w/ palette (where values are 4 tuples w/ alpha)
            if 'palette' not in color_kws:
                # seems to default to white otherwise
                marker_only_kws['markeredgecolor'] = color_kws['color']
                # TODO if i like, refactor to share w/ other seed_errorbar plots?
                # TODO TODO like 'None' more than 'white' here? for some other pltos
                # (mainly those w/ lines thru them too), i liked 'white' more.
                marker_only_kws['markerfacecolor'] = 'None'

                # TODO still want some alpha < 1, when just showing edge (not face) of
                # markers?
                #
                # .3 too high, .2 pretty good, .15 maybe too low
                marker_only_kws['alpha'] = 0.175

                # 0.5 maybe verging on too low by itself, but still bit too crowded when
                # overlapping. .4 pretty good
                err_only_kws['alpha'] = 0.35

            # no other way I could find to get separate alpha for markers and errorbars,
            # other than to make 2 calls. setting alpha in kws led to a duplicate kwarg
            # error (rather than overwriting one from general kwargs).

            # plot points
            sns.lineplot(**lineplot_kws, **marker_only_kws)

            if errorbar is not None:
                # plot errorbars
                sns.lineplot(**lineplot_kws, **err_only_kws)

            ax.set_xlabel(f'{metric_name} of {orn_label_part} tuning (observed)'
                f'\n{help_str}'
            )
            if 'pn2kc_connections' in model_kws:
                ax.set_ylabel(
                    f'{metric_name} of {model_kws["pn2kc_connections"]} model KCs'
                )
            else:
                ax.set_ylabel(f'{metric_name} of model KCs')

            metric_max = max(df[model_col].max(), df[orn_col].max())
            metric_min = min(df[model_col].min(), df[orn_col].min())

            assert metric_max <= plot_max, \
                f'{param_dir}\n{desc=}: {metric_max=} > {plot_max=}'
            assert metric_min >= plot_min, \
                f'{param_dir}\n{desc=}: {metric_min=} < {plot_min=}'

            ax.set_xlim([plot_min, plot_max])
            ax.set_ylim([plot_min, plot_max])

            # should give us an Axes that is of square size in figure coordinates
            ax.set_box_aspect(1)

            if 'seed' in df.columns:
                # averaging correlations over seed, before calculating bootstrapped
                # spearman (so that CI is correct. otherwise showed no error)
                for_spearman = df.groupby(['odor1','odor2'])[[model_col,orn_col]].mean()
            else:
                for_spearman = df.copy()

            spear_text, _, _, _, _ = bootstrapped_corr(for_spearman, model_col, orn_col,
                # TODO delete (for debugging)
                # don't want to do for 'orn-est-spike-delta' case, as would need code
                # changes and don't care about that
                _plot_dir=param_dir if orn_fname_part == 'orn-raw-dff' else None,
                #
            )

            if errorbar is None:
                ax.set_title(f'{title}\n\n{spear_text}')
            else:
                ax.set_title(f'{title}\n\n{seed_err_text}\n{spear_text}')

            savefig(fig, param_dir, f'model_vs_{orn_fname_part}{fname_suffix}')


        _save_kc_vs_orn_corr_scatterplot('correlation distance')
        _save_kc_vs_orn_corr_scatterplot('correlation')


        # TODO will probably need to pass _index here to have invert_corr_triangular
        # work.... (doesn't seem like we've been failing w/ same AssertionError i had
        # needed to catch in other place...)
        square_mean_orn_corrs = _resort_corr(invert_corr_triangular(mean_orn_corrs),
            panel, warn=False if responses_to == 'hallem' else True
        )

        # stripping conc to match processing of `pearson` above
        square_mean_orn_corrs = _strip_index_and_col_concs(square_mean_orn_corrs)
        try:
            assert pearson.index.equals(square_mean_orn_corrs.index)
            assert pearson.columns.equals(square_mean_orn_corrs.columns)
        # TODO still reachable? delete?
        except AssertionError:
            # TODO care enough to find intersection and just take diff there?
            # (or dropna and resort?)
            print(f'not plotting corr diff wrt {orn_label_part} (index mismatch)')
            return

        corr_diff = pearson - square_mean_orn_corrs
        plot_corr(corr_diff, param_dir, f'model_vs_{orn_fname_part}_corr_diff',
            title=title, xlabel=f'model KC corr - {orn_label_part} corr'
        )
        # square_mean_corrs should be plotted elsewhere (potentially in diff places
        # depending on whether input is Hallem vs pebbled data?)
        # TODO check + comment where each should be saved?


    if comparison_orns is not None:
        if type(comparison_orns) is dict:
            for desc, comparison_data in comparison_orns.items():
                _compare_model_kc_to_orn_data(comparison_data, desc)
        else:
            _compare_model_kc_to_orn_data(comparison_orns)


    if comparison_kc_corrs is not None:
        # TODO assert input odors match comparison_kc_corrs odors exactly?

        # TODO just do this unconditionally like in comparison_orns code? or make that
        # part explicit too?
        if _strip_concs_comparison_kc_corrs:
            comparison_kc_corrs = _strip_index_and_col_concs(comparison_kc_corrs)

            n_combos_before = len(model_corr_df[['odor1', 'odor2']].drop_duplicates())
            # TODO use parse_odor_name in other stripping fn here too?
            model_corr_df['odor1'] = model_corr_df.odor1.apply(olf.parse_odor_name)
            model_corr_df['odor2'] = model_corr_df.odor2.apply(olf.parse_odor_name)

            n_combos_after = len(model_corr_df[['odor1', 'odor2']].drop_duplicates())
            assert n_combos_before == n_combos_after

        kc_corrs = corr_triangular(comparison_kc_corrs)
        kc_corrs.name = 'observed_kc_corr'

        df = model_corr_df.merge(kc_corrs, on=['odor1', 'odor2'])

        # converting to correlation distance, like in matt's
        df['model_corr_dist'] = 1 - df['model_corr']
        df['observed_kc_corr_dist'] = 1 - df['observed_kc_corr']

        fig, ax = plt.subplots()

        # doing this first so everything else gets plotted over it
        # TODO why do points from call below seem to be plotted under this? way to force
        # a certain Z order?
        add_unity_line(ax)

        sns.regplot(data=df, x='observed_kc_corr_dist', y='model_corr_dist',
            x_estimator=np.mean, x_ci=None, color='black', scatter_kws=dict(alpha=0.3),
            fit_reg=False
        )

        # averaging over 'seed' level to get mean correlation for each pair, because we
        # don't show error for each point in this plot (i.e. error across seeds). we
        # only show a CI for the regression line shown (handled in regplot call below)
        if 'seed' in df.columns:
            df = df.groupby(['odor1','odor2']).mean().reset_index()

        # TODO assert len(df) always n_choose_2(n_odors) at this point?
        # (seems true in pebbled/hemibrain at least. check uniform)

        corr_dist_max = max(df.model_corr_dist.max(), df.observed_kc_corr_dist.max())
        corr_dist_min = min(df.model_corr_dist.min(), df.observed_kc_corr_dist.min())
        plot_max = 1.3
        plot_min = 0.0
        assert corr_dist_max <= plot_max, f'{param_dir}\n{corr_dist_max=} > {plot_max=}'
        assert corr_dist_min >= plot_min, f'{param_dir}\n{corr_dist_min=} < {plot_min=}'

        # need to set these before regplot call below (which makes regression line +
        # CI), so that the line actually goes to these limits.
        ax.set_xlim([plot_min, plot_max])
        ax.set_ylim([plot_min, plot_max])

        # NOTE: none of the KC vs model KC scatter plots in preprint have seed-error
        # shown, so not including errorbar=seed_errorbar here. just want error on
        # regression line in this plot, which we have (and we are happy w/ default 95%
        # CI on mean for that)
        sns.regplot(data=df, x='observed_kc_corr_dist', y='model_corr_dist',
            color='black', scatter=False, truncate=False, seed=bootstrap_seed
        )

        spear_text, _, _, _, _ = bootstrapped_corr(df, 'model_corr_dist',
            'observed_kc_corr_dist', method='spearman',
            # TODO delete (for debugging)
            _plot_dir=param_dir,
            #
        )
        ax.set_title(f'{title}\n\n{spear_text}')

        ax.set_xlabel('KC correlation distance (observed)')
        ax.set_ylabel('model KC correlation distance')

        # should give us an Axes that is of square size in figure coordionates
        ax.set_box_aspect(1)

        # TODO rename to indicate they are corr-dists, not just corrs (no other version
        # of the plot tho...)?
        #
        # to reproduce preprint figures 3 Di/Dii
        savefig(fig, param_dir, 'model_vs_kc_corrs')


    # TODO why am i getting the following error w/ my current viz.clustermap usage?
    # 3625, in _dendrogram_calculate_info
    #     _dendrogram_calculate_info(
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/scipy/cluster/hierarchy.py", line 3658, in _dendrogram_calculate_info
    #     _dendrogram_calculate_info(
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/scipy/cluster/hierarchy.py", line 3625, in _dendrogram_calculate_info
    #     _dendrogram_calculate_info(
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/scipy/cluster/hierarchy.py", line 3625, in _dendrogram_calculate_info
    #     _dendrogram_calculate_info(
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/scipy/cluster/hierarchy.py", line 3555, in _dendrogram_calculate_info
    #     _append_singleton_leaf_node(Z, p, n, level, lvs, ivl,
    #   File "/home/tom/src/al_analysis/venv/lib/python3.8/site-packages/scipy/cluster/hierarchy.py", line 3433, in _append_singleton_leaf_node
    #     ivl.append(str(int(i)))
    # RecursionError: maximum recursion depth exceeded while getting the str of an object

    # https://github.com/scipy/scipy/issues/7271
    # https://github.com/MaayanLab/clustergrammer/issues/34
    sys.setrecursionlimit(100000)
    # TODO maybe don't need to change sys setrecursionlimit now that i'm dropping silent
    # cells?

    # TODO try a version of this using first N (< n_seeds) seeds? try all (i assume it'd
    # be much too slow, and also unreadable [assuming we try to show all cells, and not
    # cluster means / similar reduction])?
    #
    # only including silent here so we can count them in line below
    to_cluster = responses_including_silent
    clust_suffix = ''

    if n_seeds > 1:
        first_seed = to_cluster.index.get_level_values('seed')[0]
        to_cluster = to_cluster.loc[first_seed]
        clust_suffix = '_first-seed-only'

    silent_cells = (to_cluster == 0).all(axis='columns')

    if silent_cells.all():
        # TODO also return before generating the corr plots (+ any others) above?
        # TODO err instead?
        #
        # TODO why was* (can not currently repro) this the case for ALL attempts in
        # 'kiwi' case now?  really need steps so different from 'megamat' case? if so,
        # why? or am i just not calling it right at all for some reason (related to
        # that failing check to repro output w/ fixed wAPLKC/fixed_thr?)
        warn('all model cells were silent! returning before generating further plots!')
        return params_for_csv

    row_colors = None
    # TODO TODO another version separately clustering for each kc_type?
    if KC_TYPE in to_cluster.index.names:
        response_rate_by_type = to_cluster.groupby(KC_TYPE).apply(
            lambda x: x.mean().mean()
        )
        fig, ax = plt.subplots()
        # TODO drop unknown?
        # TODO use colors consistent w/ elsewhere?
        # TODO fixed scale?
        sns.barplot(response_rate_by_type, ax=ax)
        savefig(fig, param_dir, 'response_rate_by_type')

        # TODO need to do anything to get palette consistent w/ histograms?
        # (seems so, if i care)
        kc_type_palette = sns.color_palette(n_colors=len(kc_type_hue_order))

        type2color = dict(zip(kc_type_hue_order, kc_type_palette))

        row_colors = to_cluster.index.get_level_values(KC_TYPE).to_series(
            ).map(type2color)

        # seems this might be necessary
        row_colors.index = to_cluster.index

        # TODO can i add labels here (as opposed to separtely passing dict in legend
        # call below)?
        handles = [Patch(facecolor=color) for type, color in type2color.items()]

    # ~30" height worked for ~1837 cells, but don't need all that when not plotting
    # silent cells
    cg = cluster_rois(to_cluster[~ silent_cells].T, odor_sort=False, figsize=(7, 12),
        row_colors=row_colors
    )

    if KC_TYPE in to_cluster.index.names:
        # TODO include counts in parens by default?
        # TODO factor all this legend creation into cluster_rois (-> also use for
        # fly_colors stuff)?
        cg.fig.legend(handles, type2color, title='KC subtype', loc='center right')

    cg.fig.suptitle(f'{title_including_silent_cells}\n\n'
        # TODO just define n_silent_cells alongside responses_including_silent/responses
        # def, then remove separate use of `silent_cells` here (+ use responses instead
        # of responses_including_silent)?
        # (doing it earlier would be complicated/impossible in n_seeds > 1 case
        # though...)
        f'{silent_cells.sum()} silent cells / {len(to_cluster)} total'
    )
    savefig(cg, param_dir, f'responses_nosilent{clust_suffix}')

    # TODO TODO TODO also plot in order of clustered ROIs from pre-tuned control+kiwi
    # panel, so that we can concat side-by-side after boosting APL, to show effect on
    # responses across both panels at once (can't boost APL while doing the pre-tuning,
    # so we won't have responses on both panels as currently run, unless we explicitly
    # added a call to run on both panels [in a separate step after pre-tuning])

    # TODO TODO also version that shows any mask used for apl boosting, for row colors
    # (maybe in addition to KC_TYPE colors, if easily possible, in which case it
    # wouldn't need to be in separate plot(s))

    # TODO TODO also make a plot that is clustering on spike_counts, and showing
    # subtypes when available, just as natmix_data does (could maybe just move that code
    # here? don't need in two places)

    # TODO also plot wPNKC (clustered?) for matts + my stuff?
    # TODO same for other model vars? thresholds?

    # TODO corr diff plot too (even if B doesn't want to plot it for now)?

    # TODO and (maybe later) correlation diffs wrt model w/ tuned params

    # TODO assert no sparsity (/ value) goes outside cbar/scale limits
    # (do in sparsity plotting fn?)

    sparsity_per_odor = _per_odor_tidy_model_response_rates(responses_including_silent
        ).set_index(odor_col)

    if comparison_responses is not None:
        comparison_sparsity_per_odor = _per_odor_tidy_model_response_rates(
            comparison_responses
        )
        comparison_sparsity_per_odor = comparison_sparsity_per_odor.sort_values(
            sparsity_col
        )
        # TODO also sort correlation odors by same order?
        # TODO assert set of odors are the same first
        sparsity_per_odor = sparsity_per_odor.loc[comparison_sparsity_per_odor.odor1]
    else:
        comparison_sparsity_per_odor = None

    sparsity_per_odor = sparsity_per_odor.reset_index()

    sparsity_per_odor.odor1 = sparsity_per_odor.odor1.map(lambda x: x.split(' @ ')[0])

    if comparison_responses is not None:
        # TODO need (just to remove diff numbering in index, wrt sparsity_per_odor, in
        # case that changes behavior of some plotting...)?
        # TODO why drop=True here, but not in sparsity_per_odor.reset_index() above?
        comparison_sparsity_per_odor = comparison_sparsity_per_odor.reset_index(
            drop=True
        )
        # TODO refactor (duped above)?
        comparison_sparsity_per_odor.odor1 = comparison_sparsity_per_odor.odor1.map(
            lambda x: x.split(' @ ')[0]
        )
        assert comparison_sparsity_per_odor.odor1.equals(sparsity_per_odor.odor1)

    if responses_to == 'hallem':
        # assuming megamat for now (otherwise this would be empty)
        megamat_sparsity_per_odor = sparsity_per_odor.loc[
            sparsity_per_odor.odor1.isin(panel2name_order['megamat'])
        ]
        # this is only used in sensitivity analysis now anyway. would need to also
        # subset this if not.
        assert comparison_sparsity_per_odor is None
        plot_sparsity_per_odor(megamat_sparsity_per_odor, comparison_sparsity_per_odor,
            '_megamat'
        )

    panel2sparsity_ylims = {
        # TODO add one for megamat? (only sensitivity analysis currently has these figs
        # in paper for megamat, but maybe betty will end up wanting these plots alone
        # anyway? in both cases, just need to find a range that works).
        #
        # 0.21 not enough for some.
        'validation2': [0, 0.22],
        # could prob do [0, 2], but might as well keep same as validation2. could just
        # hardcode this in general (or at least as long as the data is within limit?)?
        # TODO TODO fix (+ update validation?) actually some stuff is past this
        # apparently... (oh, it was actually on hallem data that it was failing, in the
        # uniform model)
        # TODO TODO fix so we fall back to no scale set (w/ warning), or so hallem isn't
        # considered megamat here (almost certainly former)?
        #'megamat': [0, 0.22],
    }
    # ylim=None will let plot_sparsity_per_odor set it
    ylim = panel2sparsity_ylims.get(panel)
    combined_fig, sparsity_ax = plot_sparsity_per_odor(sparsity_per_odor,
        comparison_sparsity_per_odor, '', ylim=ylim
    )

    #sparsity_ylim_max = 0.5
    # to exceed .706 in (fixed_thr=120.85, wAPLKC=0.0) param case
    sparsity_ylim_max = 0.71
    # TODO TODO are these the ylims used for validation2 modelling plots in current
    # (2025-02-18) modeling.svg for paper? are any other plots in paper using this?
    # maybe for sensitivity analysis?
    sparsity_ax.set_ylim([0, sparsity_ylim_max])
    # TODO TODO fix sensitivity analysis to not give us stuff outside this
    # comparison_sparsity_per_odor isn't being pushed to the same extreme, and should be
    # well within this limit.
    #assert not (sparsity_per_odor[sparsity_col] > sparsity_ylim_max).any()

    # https://stackoverflow.com/questions/33264624
    # NOTE: without other fiddling, need to keep references to both of these axes, as
    # the Axes created by `ax.twinx()` is what we need to control the ylabel
    # https://stackoverflow.com/questions/54718818
    n_odor_ax_for_ylabel = sparsity_ax.twinx()
    n_odor_ax = n_odor_ax_for_ylabel.twiny()

    fig, ax = plt.subplots()
    plot_n_odors_per_cell(responses_including_silent, ax,
        title=title_including_silent_cells
    )
    if comparison_responses is not None:
        plot_n_odors_per_cell(comparison_responses, ax, label_suffix=' (tuned)',
            color='gray', title=title_including_silent_cells
        )

    savefig(fig, param_dir, 'n_odors_per_cell')

    if responses_to == 'hallem':
        fig, ax = plt.subplots()
        # TODO assert this is getting just megamat odors (/reimplement so it only could)
        # (b/c prior sorting, that should have put all them before rest of hallem odors,
        # they should be)
        # TODO factor out + use megamat subsetting fn here
        plot_n_odors_per_cell(responses_including_silent.iloc[:, :17], ax,
            title=title_including_silent_cells
        )

        assert comparison_responses is None
        # TODO delete?
        # if assertion fails, will also need to subset comparison_responses to megamat
        # odors (in commented code below)
        #if comparison_responses is not None:
        #    plot_n_odors_per_cell(comparison_responses, ax, label_suffix=' (tuned)',
        #        color='gray', title=title_including_silent_cells
        #    )

        savefig(fig, param_dir, 'n_odors_per_cell_megamat')

    # only currently running sensitivity analysis in pebbled/hemibrain case.
    # some of code below (all of which should deal with sensitivity analysis in some
    # way, from here on) may not work w/ multiple seeds. could delete this early return
    # and try though.
    if n_seeds > 1:
        assert not sensitivity_analysis
        return params_for_csv

    # only want to save this combined plot in case of senstivity analysis
    # (where we need as much space as we can save)
    if _in_sens_analysis:
        assert fixed_thr is not None and wAPLKC is not None

        plot_n_odors_per_cell(responses_including_silent, n_odor_ax,
            ax_for_ylabel=n_odor_ax_for_ylabel, linestyle='dashed', log_yscale=True
        )

        if comparison_responses is not None:
            plot_n_odors_per_cell(comparison_responses, n_odor_ax,
                ax_for_ylabel=n_odor_ax_for_ylabel, label_suffix=' (tuned)',
                color='gray', linestyle='dashed', log_yscale=True
            )

        # TODO figure out how to build one legend from the two axes?
        if _add_combined_plot_legend:
            # planning to manually adjust when assembling figure
            sparsity_ax.legend(loc='upper right')
            n_odor_ax.legend(loc='center right')

        savefig(combined_fig, param_dir, 'combined_odors-per-cell_and_sparsity')

    if sensitivity_analysis:
        # TODO (still an issue?) where are dirs like
        # <panel>/tuned-on_control-kiwi__dff_scale-to-avg-max__data_pebbled__hallem-tune_False__pn2kc_hemibrain__fixed-thr_0__wAPLKC_0.00
        # coming from??? something not working right?

        shared_model_kws = {k: v for k, v in model_kws.items() if k not in (
            # plot_dir would conflict with first positional arg of
            # fit_and_plot_mb_model, and we don't want plots for sensitivity analysis
            # subcalls anyway (could fix if we did want those plots).
            'plot_dir',
            # excluding target_sparsity b/c that is mutually exclusive w/ fixing
            # threshold and KC<->APL inhibition, as all these calls will.
            'target_sparsity',

            # this factor only relevant (+ should only be passed if) we are also passing
            # target_sparsity.
            'target_sparsity_factor_pre_APL',

            'equalize_kc_type_sparsity',
            'ab_prime_response_rate_target',

            # TODO actually support varying just APL in this case? or still varying
            # vector thrs too?
            'homeostatic_thrs',

            # will default to False (via fit_mb_model default) once I remove this, which
            # is what I want
            'repro_preprint_s1d',

            # TODO add return_dynamics/_plot_example_dynamics? (to make default to
            # False)?
        )}

        # TODO TODO TODO how to support vector fixed_thr?
        # (also, probably remove line above setting vector fixed_thr=None in
        # equalize*=True case, so this branch also works on initial equalize*=True
        # calls)
        tuned_fixed_thr = param_dict['fixed_thr']

        if not use_connectome_APL_weights:
            tuned_wAPLKC = param_dict['wAPLKC']
        else:
            # TODO also check/use wKCAPL_scale (possible it isn't trivially computable
            # from wAPLKC_scale?)? what if i add a param to change scale between
            # wKCAPL_scale and wAPLKC_scale?
            tuned_wAPLKC = param_dict['wAPLKC_scale']

        # TODO assert wKCAPL (/ wKCAPL_scale) is ~ (wAPLKC / <#-KCs>)?
        # (or otherwise handle case where we also have that separately?)

        assert tuned_fixed_thr is not None and tuned_wAPLKC is not None

        checks = True
        # TODO want to keep after i finish test_mb_model.test_fixed_inh_params?
        # probably, just to be sure it would work in this context (args might be
        # slightly diff)
        if checks:
            print('checking we can recreate responses by hardcoding tuned '
                'fixed_thr/wAPLKC...', end=''
            )
            # TODO figure out why this wasn't working on some runs of
            # kiwi/control data (re-running w/ `-i model` seemed to fix it, but unclear
            # on why that would be. using cache after break it again?) (doesn't seem
            # like it...) (encountered again 2025-02-20. going to re-run w/ `-i model`,
            # but do have a recent backup of whole mb_modeling dir, if i want to compare
            # outputs) (likely this has been resolved. delete comment.)
            # TODO why *was* responses2.sum().sum() == 0 in kiwi/control case???
            # (prob same reason sens analysis failing there)
            # (not sure i can repro, same as w/ failing assertion below)
            #
            # TODO silence output here? makes surrounding prints hard to follow
            # TODO also check spike_counts (2nd / 4 returned values)?
            responses2, _, _, _ = fit_mb_model(sim_odors=sim_odors,
                fixed_thr=tuned_fixed_thr, wAPLKC=tuned_wAPLKC, **shared_model_kws
            )
            # NOTE: this can fail if loading responses from cache (where values are the
            # same, but new output also has KC_TYPE in index)
            assert responses_including_silent.equals(responses2)
            print(' we can!\n')

        parent_output_dir = param_dir / 'sensitivity_analysis'

        # deleting this directory (and all contents) before run, to clear plot dirs from
        # param choices only in previous sweeps (and tried.csv with same)
        if parent_output_dir.exists():
            # TODO TODO warn / err if -c (can't check new plots against existing if we
            # are deleting whole dir...)?
            # TODO make a rmtree wrapper (->use here and elsewhere) and always warn/err
            # if -c?
            warn(f'deleting {parent_output_dir} and all contents!')
            shutil.rmtree(parent_output_dir)

        # savefig will generally do this for us below
        parent_output_dir.mkdir(exist_ok=True)

        tried_param_cache = parent_output_dir / 'tried.csv'
        # should never exist as we're currently deleting parent dir above
        # (may change to not delete above though, so keeping this)
        if tried_param_cache.exists():
            tried = pd.read_csv(tried_param_cache)
            # TODO assert columns are same as below (refactor col def above conditional)
        else:
            # TODO TODO switch all mean_fixed_thr stuff below back to rel_fixed_thr?
            # that code was a lot simpler... and some interpretability benefits too (w/
            # tradeoffs)
            #tried = pd.DataFrame(columns=['rel_fixed_thr', 'wAPLKC', 'sparsity'])
            if isinstance(tuned_fixed_thr, float):
                tried = pd.DataFrame(columns=['fixed_thr', 'wAPLKC', 'sparsity'])
            else:
                assert isinstance(tuned_fixed_thr, np.ndarray)
                tried = pd.DataFrame(columns=['mean_fixed_thr', 'wAPLKC', 'sparsity'])

        sens_analysis_kw_defaults = dict(
            n_steps=3,
            fixed_thr_param_lim_factor=0.5,
            wAPLKC_param_lim_factor=5.0,
            drop_nonpositive_fixed_thr=True,
            drop_negative_wAPLKC=True,
        )
        if sens_analysis_kws is None:
            sens_analysis_kws = dict()
        else:
            assert all(k in sens_analysis_kw_defaults for k in sens_analysis_kws.keys())

        sens_analysis_kws = {**sens_analysis_kw_defaults, **sens_analysis_kws}

        # TODO TODO try implementing alternative means of specifying bounds of sens
        # analysis: try sweeping each parameter until we reach some 2nd target response
        # rate (e.g. 2-5%, << typical target response rate when tuning both params of
        # ~10%) (then go the same distance [relative?] the other way? or what? not sure
        # this works...)
        #
        # want to avoid trial-and-error setting of below parameters such that corners of
        # grid each see similarly low/extreme response rates
        # TODO TODO TODO easier to implement such a thing by just slightly modifying
        # olfsysm C++ code?

        # needs to be odd so grid has tuned values (that produce outputs used elsewhere
        # in paper) as center.
        n_steps = sens_analysis_kws['n_steps']
        assert n_steps % 2 == 1, f'n_steps must be odd (got {n_steps=})'

        # TODO might need to be <1 to have lower end be reasonable?  but that prob won't
        # be enough (meaning? delete comment or elaborate) for upper ends...
        #
        # had previously tried up to at least 3, as well (not sure how it compared now
        # though...)
        #
        # for getting upper left 3x3 from original 4x4 (which was generated w/ this
        # param doubled, and n_steps=5 rather than 3)
        fixed_thr_param_lim_factor = sens_analysis_kws['fixed_thr_param_lim_factor']

        # TODO try seeing if we can push this high enough to start getting missing
        # correlations. 1000? why only getting those for high fixed_thr? and where
        # exactly do they come from?
        #
        # NOTE: was not seemingly able to get odors w/ no cells responding to them by
        # increasing this param (up to 100.0)...
        # 10.0 was used for most of early versions of this
        wAPLKC_param_lim_factor = sens_analysis_kws['wAPLKC_param_lim_factor']

        drop_nonpositive_fixed_thr = sens_analysis_kws['drop_nonpositive_fixed_thr']
        drop_negative_wAPLKC = sens_analysis_kws['drop_negative_wAPLKC']

        # TODO try 0 for min of fixed_thr_steps (remove drop_zero=True, and tweak step
        # size to get at least 1 <=0) (current steps not clipped by it)?
        # is 0 the lowest value that maximizes response rate? or are negative vals
        # meaningful given how this is implemented?
        # (would allow me to simplify code slightly if this could be handled as wAPLKC)
        fixed_thr_steps = step_around(tuned_fixed_thr, fixed_thr_param_lim_factor,
            'fixed_thr', n_steps=n_steps, drop_negative=True,
            drop_zero=drop_nonpositive_fixed_thr
        )

        # TODO delete
        ## TODO TODO also get this to work for scalar input case (+ switch all outputs /
        ## plots to using these relative descriptions?) (test whether it already does?)
        ## TODO also handle wAPLKC steps this way, for consistency?
        #rel_fixed_thr_steps = (fixed_thr_steps / tuned_fixed_thr)

        #if fixed_thr_steps.ndim > 1:
        #    firstcell_rel_fixed_thr_steps = rel_fixed_thr_steps[:,0]
        #    assert np.allclose(
        #        np.stack([firstcell_rel_fixed_thr_steps] * len(tuned_fixed_thr)).T,
        #        rel_fixed_thr_steps
        #    )
        #    rel_fixed_thr_steps = firstcell_rel_fixed_thr_steps

        wAPLKC_steps = step_around(tuned_wAPLKC, wAPLKC_param_lim_factor, 'wAPLKC',
            n_steps=n_steps, drop_negative=drop_negative_wAPLKC
        )

        print(f'{tuned_fixed_thr=}')
        print(f'{tuned_wAPLKC=}')
        print()
        print('parameter steps around sparsity-tuned values (above):')

        if isinstance(tuned_fixed_thr, float):
            print(f'{fixed_thr_steps=}')
        else:
            assert isinstance(tuned_fixed_thr, np.ndarray)
            # e.g. from:
            # array([[129.39, 129.39, 129.39, ..., 129.39, 129.39, 158.97],
            #        [258.79, 258.79, 258.79, ..., 258.79, 258.79, 317.94],
            #        [388.18, 388.18, 388.18, ..., 388.18, 388.18, 476.91]])
            # ...to:
            # array([133.81, 267.61, 401.42])
            mean_fixed_thr_steps = fixed_thr_steps.mean(axis=1)
            print(f'{mean_fixed_thr_steps=}')

        print(f'{wAPLKC_steps=}')
        # TODO delete
        #print(f'(relative to tuned) {rel_fixed_thr_steps=}')
        #print(f'(absolute) {wAPLKC_steps=}')
        print()

        step_choice_param_dict = {
            'tuned_fixed_thr': tuned_fixed_thr,
            'tuned_wAPLKC': tuned_wAPLKC,

            'n_steps': n_steps,
            'fixed_thr_param_lim_factor': fixed_thr_param_lim_factor,
            'wAPLKC_param_lim_factor': wAPLKC_param_lim_factor,
            'drop_negative_wAPLKC': drop_negative_wAPLKC,
            'drop_nonpositive_fixed_thr': drop_nonpositive_fixed_thr,
        }


        if isinstance(tuned_fixed_thr, float):
            step_choice_param_dict['fixed_thr_steps'] = fixed_thr_steps
        else:
            assert isinstance(tuned_fixed_thr, np.ndarray)
            # should be fully determined by above, but just including for easier
            # inspection
            #step_choice_param_dict['rel_fixed_thr_steps'] = rel_fixed_thr_steps
            step_choice_param_dict['mean_fixed_thr_steps'] = mean_fixed_thr_steps

        step_choice_param_dict['wAPLKC_steps'] = wAPLKC_steps
        step_choice_params = pd.Series(step_choice_param_dict)

        to_csv(step_choice_params, parent_output_dir / 'step_choices.csv',
            # so column name '0' doesn't get added (also added if doing ser.to_frame())
            header=False
        )

        # TODO delete
        #tried_wide = pd.DataFrame(data=float('nan'), columns=rel_fixed_thr_steps,
        #    index=wAPLKC_steps
        #)
        #tried_wide.columns.name = 'rel_fixed_thr'
        if isinstance(tuned_fixed_thr, float):
            tried_wide = pd.DataFrame(data=float('nan'), columns=fixed_thr_steps,
                index=wAPLKC_steps
            )
        else:
            assert isinstance(tuned_fixed_thr, np.ndarray)
            tried_wide = pd.DataFrame(data=float('nan'), columns=mean_fixed_thr_steps,
                index=wAPLKC_steps
            )

        tried_wide.columns.name = 'mean_fixed_thr'
        tried_wide.index.name = 'wAPLKC'

        # should be something that won't appear in actual computed values. NaN may
        # appear in computed values. after loop, we check that we no longer have any of
        # these.
        corr_placeholder = 10

        # TODO delete
        #row_index = pd.MultiIndex.from_product([rel_fixed_thr_steps, wAPLKC_steps],
        #    names=['rel_fixed_thr', 'wAPLKC']
        #)
        if isinstance(tuned_fixed_thr, float):
            row_index = pd.MultiIndex.from_product([fixed_thr_steps, wAPLKC_steps],
                names=['fixed_thr', 'wAPLKC']
            )
        else:
            assert isinstance(tuned_fixed_thr, np.ndarray)
            row_index = pd.MultiIndex.from_product([mean_fixed_thr_steps, wAPLKC_steps],
                names=['mean_fixed_thr', 'wAPLKC']
            )

        col_index = corr_triangular(pearson).index
        pearson_at_each_param_combo = pd.DataFrame(index=row_index, columns=col_index,
            data=corr_placeholder
        )
        del row_index, col_index

        # TODO any point in having this if we are deleting root of all these above?
        # delete?
        ignore_existing = True

        _add_combined_plot_legend = True

        for fixed_thr, wAPLKC in tqdm(itertools.product(fixed_thr_steps, wAPLKC_steps),
            total=len(fixed_thr_steps) * len(wAPLKC_steps),
            unit='fixed_thr+wAPLKC combos'):


            print(f'{fixed_thr=}')
            # TODO delete
            #rel_fixed_thr = _single_unique_val(fixed_thr / tuned_fixed_thr, exact=False)

            #print(f'{rel_fixed_thr=}')
            #
            print(f'{wAPLKC=}')

            # TODO rename 'thr' prefix to 'rthr' or something, now that it's relative?
            # or otherwise distinguish outputs? (+ relabel plots and stuff)
            # TODO delete
            #dirname = f'thr{rel_fixed_thr:.2f}_wAPLKC{wAPLKC:.2f}'
            mean_fixed_thr = None
            if isinstance(fixed_thr, float):
                dirname = f'thr{fixed_thr:.2f}_wAPLKC{wAPLKC:.2f}'
            else:
                mean_fixed_thr = fixed_thr.mean()
                dirname = f'mean-thr{mean_fixed_thr:.2f}_wAPLKC{wAPLKC:.2f}'

            # NOTE: created by inner fit_and_plot... call below
            output_dir = parent_output_dir / dirname

            if output_dir.exists() and not ignore_existing:
                print(f'{output_dir} already existed. skipping!')
                continue

            # TODO delete? (if i want to restore, and don't want to use rel instead of
            # mean fixed thr, would prob need an outer conditional here, and would get
            # even uglier)
            '''
            #
            #if ((tried.rel_fixed_thr <= rel_fixed_thr) & (tried.wAPLKC <= wAPLKC) &
            if ((tried.mean_fixed_thr <= mean_fixed_thr) & (tried.wAPLKC <= wAPLKC) &
                (tried.sparsity < min_sparsity)).any():

                print(f'sparsity would be < {min_sparsity=}')
                continue

            #elif ((tried.rel_fixed_thr >= rel_fixed_thr) & (tried.wAPLKC >= wAPLKC) &
            elif ((tried.mean_fixed_thr >= mean_fixed_thr) & (tried.wAPLKC >= wAPLKC) &
                    (tried.sparsity > max_sparsity)).any():

                print(f'sparsity would be > {max_sparsity=}')
                continue
            '''
            #

            curr_params = fit_and_plot_mb_model(output_dir,
                comparison_responses=responses_including_silent,
                sim_odors=sim_odors, sensitivity_analysis=False, _in_sens_analysis=True,
                # this should be the only place we use fixed_thr instead of
                # [rel|mean]_fixed_thr, inside this loop (b/c fixed_thr can now
                # sometimes be a vector of length equal to # of KCs, which makes it
                # mostly unusable for plot/column labels / etc)
                fixed_thr=fixed_thr, wAPLKC=wAPLKC,
                _add_combined_plot_legend=_add_combined_plot_legend,
                # not passing param_dir_prefix here, b/c that should be in parent
                # directory, and should be easy enough to keep track of from that
                extra_params=extra_params,
                **shared_model_kws
            )
            # shouldn't need to call _write_inputs_for_reproducibility here, as should
            # also be in parent dir

            # should only be None in first_seed_only=True case, but not doing any
            # multi-seed runs w/ sensitivity analysis. only doing sensitivity analysis
            # for hemibrain + pebbled case currently.
            assert curr_params is not None

            # (added only if wAPLKC/fixed_thr passed)
            pearson = curr_params['pearson']

            pearson_ser = corr_triangular(pearson)
            assert pearson_ser.index.equals(pearson_at_each_param_combo.columns)
            # TODO need to assert this thr value is IN index already?
            if mean_fixed_thr is None:
                pearson_at_each_param_combo.loc[fixed_thr, wAPLKC] = pearson_ser
            else:
                pearson_at_each_param_combo.loc[mean_fixed_thr, wAPLKC] = pearson_ser
            # TODO delete
            #pearson_at_each_param_combo.loc[rel_fixed_thr, wAPLKC] = pearson_ser

            sparsity = curr_params['sparsity']
            print(f'sparsity={sparsity:.3g}')

            if output_dir.exists():
                # TODO need to assert this thr value is IN index already?
                if mean_fixed_thr is None:
                    tried_wide.loc[wAPLKC, fixed_thr] = sparsity
                else:
                    tried_wide.loc[wAPLKC, mean_fixed_thr] = sparsity
                # TODO delete
                #tried_wide.loc[wAPLKC, rel_fixed_thr] = sparsity

                # only want for first plot
                if _add_combined_plot_legend:
                    _add_combined_plot_legend = False

            if mean_fixed_thr is None:
                for_tried = {
                    # TODO delete
                    #'rel_fixed_thr': rel_fixed_thr, 'wAPLKC': wAPLKC,
                    'fixed_thr': fixed_thr, 'wAPLKC': wAPLKC, 'sparsity': sparsity
                }
            else:
                for_tried = {
                    # TODO delete
                    #'rel_fixed_thr': rel_fixed_thr, 'wAPLKC': wAPLKC,
                    'mean_fixed_thr': mean_fixed_thr,
                    'wAPLKC': wAPLKC, 'sparsity': sparsity
                }
            # replaced old .append w/ this hacky concat usage, to silence future warning
            # about append being removed
            tried = pd.concat([tried, pd.Series(for_tried).to_frame().T],
                ignore_index=True
            )
            # TODO delete
            #tried = tried.sort_values(['rel_fixed_thr', 'wAPLKC'])
            if mean_fixed_thr is None:
                tried = tried.sort_values(['fixed_thr', 'wAPLKC'])
            else:
                tried = tried.sort_values(['mean_fixed_thr', 'wAPLKC'])

            # can't use my to_csv as it currently errs if same CSV would get written >1
            # time in a given run
            tried.to_csv(tried_param_cache, index=False)

            print()

        # to make rows=rel_fixed_thr, cols=wAPLKC (consistent w/ how i had been laying
        # out the figure grids)
        tried_wide = tried_wide.T

        # (this, but not columns.name, makes it into CSV. it will be top left element.)
        # TODO delete
        #tried_wide.index.name = 'rows=rel_fixed_thr, cols=wAPLKC'
        if isinstance(tuned_fixed_thr, float):
            tried_wide.index.name = 'rows=fixed_thr, cols=wAPLKC'
        else:
            assert isinstance(tuned_fixed_thr, np.ndarray)
            tried_wide.index.name = 'rows=mean_fixed_thr, cols=wAPLKC'

        # TODO rename var to match csv name (~similar)
        # TODO also add row / col index levels for what param_lim_factor we'd need to
        # get each of those steps?
        to_csv(tried_wide, parent_output_dir / 'sparsities_by_params_wide.csv')

        # NOTE: `not in set(...)` check probably doesn't work as intended w/ NaN,
        # but assuming corr_placeholder is not NaN, should be fine
        assert corr_placeholder not in set(
            np.unique(pearson_at_each_param_combo.values)
        )

        # TODO TODO how to deal w/ NaNs prior to spearman calc? do spearman calc in
        # a way that ignores NaN (pretty sure that's default behavior)?
        # TODO save one version w/ dropna first (to keep # of non-NaN input correlations
        # same across corrs that might or might not have NaN)?

        # after transposing, output corr will be of shape:
        # (# param combos, # param combos)
        spearman_of_pearsons = pearson_at_each_param_combo.T.corr(method='spearman')

        # TODO how to get text over (/to side of) ticklabels (to label full name of 2
        # params)? add support to viz.matshow for that?

        group_text = True

        if isinstance(tuned_fixed_thr, float):
            level_fn = lambda d: d['fixed_thr']
        else:
            assert isinstance(tuned_fixed_thr, np.ndarray)
            level_fn = lambda d: d['mean_fixed_thr']

        format_fixed_thr = lambda x: f'{x:.0f}'
        # TODO delete
        #level_fn = lambda d: d['rel_fixed_thr']
        #format_rel_fixed_thr = lambda x: f'{x:.2f}'

        # trying to just use this to format last row/col index level (wAPLKC).
        # fixed_thr should be handled by group_text stuff, which i might want to change
        # handling of inside hong2p
        format_wAPLKC = lambda x: f'{x[1]:.1f}'
        xticklabels = format_wAPLKC
        yticklabels = format_wAPLKC

        fig, _ = viz.matshow(spearman_of_pearsons,
            cmap=diverging_cmap,
            vmin=-1.0, vmax=1.0, levels_from_labels=False,
            hline_level_fn=level_fn, vline_level_fn=level_fn,
            hline_group_text=group_text, vline_group_text=group_text,
            group_fontsize=10, xtickrotation='horizontal',
            # TODO change hong2p.viz to have any levels not used to group formatted into
            # label?
            xticklabels=xticklabels, yticklabels=yticklabels,
            vgroup_formatter=format_fixed_thr, hgroup_formatter=format_fixed_thr
            # TODO delete
            #vgroup_formatter=format_rel_fixed_thr,
            #hgroup_formatter=format_rel_fixed_thr
        )
        fig.suptitle("Spearman of odor X odor Pearson correlations")
        savefig(fig, parent_output_dir, 'spearman_of_pearsons')

    return params_for_csv


# TODO factor out? replace w/ [light wrapper around] sklearn's minmax_scale fn?
def minmax_scale(data: pd.Series) -> pd.Series:
    scaled = data.copy()
    scaled -= scaled.min()
    scaled /= scaled.max()

    assert np.isclose(scaled.min(), 0)
    assert np.isclose(scaled.max(), 1)

    # TODO delete
    s2 = pd.Series(index=data.index, name=data.name, data=sk_minmax_scale(data))
    # not .equals, but this assertion is true
    assert np.allclose(s2, scaled)
    #
    return scaled


def maxabs_scale(data: pd.Series) -> pd.Series:
    # sklearn.preprocessing.maxabs_scale does not preserve Series input
    # (returns a numpy array)
    return pd.Series(index=data.index, name=data.name, data=sk_maxabs_scale(data))


@produces_output(verbose=False)
# TODO correct type hint for model?
# (statsmodels.regression.linear_model.RegressionResultsWrapper, but maybe something
# more general / not the wrapper?)
def save_model(model, path: Path) -> None:
    model.save(path)


# TODO modify to accept csv path for certain_df too (if that makes it easier to get some
# basic versions of the model runnable for other people)? either way, want to commit
# some example AL data to use.
# TODO rename certain_df to just df (or something less loaded)
# TODO TODO add kwarg to hardcode a dF/F -> spike delta scaling factor (or a
# general fn), and have it bypass the computation of this fn / related plotting/cache.
# (-> use for simple example uses of this fn, hardcoding scale factor = 127 from
# Remy-paper)
def model_mb_responses(certain_df: pd.DataFrame, parent_plot_dir: Path, *,
    roi_depths=None, skip_sensitivity_analysis: bool = False,
    skip_models_with_seeds: bool = False, skip_hallem_models: bool = False,
    first_model_kws_only: bool = False) -> None:
    # TODO when is it ok for certain_df to have NaNs? does seem current input has
    # some NaNs, which are only for some odors [for which no odors is NaN for all
    # fly-glomeruli]. any restrictions (if none, why was sam having issues?)
    # TODO allow passing in model_kw_list?
    """Passes input through dF/F -> est spike delta function, runs through MB model.

    Calls `fit_and_plot_mb_model` for each of several parameter options for the model,
    currently defined below in `model_kw_list`. Each call will have a directory created
    with model outputs (under `parent_plot_dir / 'mb_modeling/<panel>/<param_dir>'`).

    Some outputs under `parent_plot_dir / 'mb_modeling'` and `<panel>` sub-directories
    describe dF/F -> est spike delta function, parameters, and outputs.

    Args:
        certain_df: dataframe of shape (# odors [including repeats], # fly-glomeruli),
            with dF/F values from [potentially multiple] flies.

            Column index names should be ['date', 'fly_num', 'roi' (i.e. glomerulus
            name)].

            Row index names should be ['panel', 'is_pair', 'odor1', 'odor2', 'repeat']
            (possible that not all are required, but 'panel' and 'odor1' should be)

        parent_plot_dir: where a 'mb_modeling' subdirectory will be created to contain
            any model output directories (and other across-model plots).

            In typical use from `al_analysis.py`, this might be 'pebbled_6f/pdf/ijroi'.

        first_model_kws_only: only runs the model with the first set of parameters (in
            `model_kw_list` in this function), to more quickly test changes to model.
    """
    # TODO (not using roi_depths really, so not a big deal) why do roi_depths seem to
    # have one row per panel, rather than per recording?  current input has column
    # levels ['date', 'fly_num', 'roi'] and row levels ['panel', 'is_pair'])

    # TODO delete. for debugging.
    global _spear_inputs2dfs
    #

    # TODO make and use a subdir in plot_dir (for everything in here, including
    # fit_and_plot... calls)

    plot_dir = parent_plot_dir / 'mb_modeling'

    # TODO w/ a verbose flag to say which odors / glomeruli overlapped

    # I think deltas make more sense to fit than absolute rates, as both can go negative
    # and then we could better filter out points from non-responsive (odor, glomerulus)
    # combinations, if we wanted to.
    hallem_delta = orns.orns(columns='glomerulus', add_sfr=False)

    hallem_delta = abbrev_hallem_odor_index(hallem_delta)

    #our_odors = {olf.parse_odor_name(x) for x in certain_df.index.unique('odor1')}

    # TODO delete?
    # TODO TODO TODO or print intersection of these w/ stuff here (or at least stuff
    # that also matches some nearness criteria on the concentration? where is that
    # currently handled, if it is at all?)
    #hallem_odors = set(hallem_delta.index)

    # as of odors in experiments in the months before 2023-06-30, checked all these
    # are actually not in hallem.
    #
    # this could be a mix of stuff actually not in Hallem and stuff we dont have an
    # abbreviation mapping from full Hallem name. want to rule out the latter.
    # TODO still always print these?
    # TODO delete?
    #unmatched_odors = our_odors - hallem_odors

    # TODO delete
    #validation_odors = {olf.parse_odor_name(x) for x in
    #    certain_df.loc['validation2'].index.unique('odor1')
    #}
    #print(f'{len(validation_odors)=}')
    #print(f'{validation_odors & hallem_odors=}')
    ## (len 7 as expected)
    #print(f'{len(validation_odors & hallem_odors)=}')
    #

    # TODO TODO TODO match glomeruli up to hallem names
    # (may need to make some small decisions)
    # (basically, are there any that are currently unmatched that can be salveaged?)

    # TODO TODO TODO also check which of our_odors are in hallem lower conc data
    # TODO TODO may want to first fix drosolf so it gives us that too
    # (or just read a csv here myself?)
    #
    # odors w/ conc series in Hallem '06 (whether or not we have data):
    # - ea
    # - pa
    # - eb
    # - ms
    # - 1-6ol
    # - 1o3ol
    # - E2-hexenal (t2h)
    # - 2,3-b (i use -5 for this? same question as w/ ga below)
    # - 2h
    # - ga (treat -5 as -6? -4? interpolate?)
    #
    # (each has -2, -4, -6, -8)

    our_glomeruli = set(certain_df.columns.unique('roi'))

    assert hallem_delta.columns.name == 'glomerulus'
    hallem_glomeruli = set(hallem_delta.columns)

    # TODO delete. (after actually checking...)
    # TODO check no naming issues
    # {'DM3+DM5', 'DA4m' (2a), 'VA1d' (88a), 'DA4l' (43a), 'DA3' (23a), 'VA1v' (47b),
    # 'DL3' (65a, 65b, 65c), 'DL4' (49a, 85f)}
    print(f'{(hallem_glomeruli - our_glomeruli)=}')
    #

    # TODO delete. (after actually checking...)
    # TODO TODO check pdf receptor names matches what i get from drosolf w/o passing
    # columns='glomerulus', then use drosolf receptors to check these
    # TODO TODO check receptors of all these are not in hallem
    # TODO TODO TODO print this out and check again. not clear on why DM3 was ever
    # here...
    # - VA2 (92a)
    # - DP1m (Ir64a)
    # - VA4 (85d)
    # - DC2 (13a)
    # - VA7m (UNK)
    # - DA2 (56a, 33a)
    # - VL2a (Ir84a)
    # - DM1 (42b)
    # - VC1 (33c, 85e)
    # - VC2 (71a)
    # - VA7l (46a)
    # - VL1 (Ir75d)
    # - VM7d (42a)
    # - DC4 (Ir64a)
    # - DL2v (Ir75c)
    # - VL2p (Ir31a)
    # - V (Gr21a, Gr63a)
    # - D (69aA, 69aB)
    # - VM7v ("1") (59c)
    # - VC5 (Ir41a)
    # - DL2d (Ir75b)
    # - DP1l (Ir75a)
    # - VA3 (67b)
    # - DC3 (83c)
    print(f'{(our_glomeruli - hallem_glomeruli)=}')
    #

    glomerulus2receptors = orns.task_glomerulus2receptors()

    hallem_glomeruli = np.array(sorted(hallem_glomeruli))
    hallem_glomeruli_in_task = np.array([
        x in glomerulus2receptors.keys() for x in hallem_glomeruli
    ])
    assert set(hallem_glomeruli[~ hallem_glomeruli_in_task]) == {'DM3+DM5'}

    our_glomeruli = np.array(sorted(our_glomeruli))
    our_glomeruli_in_task = np.array([
        x in glomerulus2receptors.keys() for x in our_glomeruli
    ])
    # True for now, but may not always be?
    assert our_glomeruli_in_task.all()

    unmodified_orn_dff_input_df = certain_df.copy()

    # TODO TODO assert that 'is_pair' is all False? maybe drop it in a separate step
    # before this? (want to also drop is_pair for roi_depths in a consistent way.
    assert (certain_df.index.get_level_values('is_pair') == False).all()
    certain_df = certain_df.droplevel('is_pair', axis='index')
    if roi_depths is not None:
        assert (roi_depths.index.get_level_values('is_pair') == False).all()
        roi_depths = roi_depths.droplevel('is_pair', axis='index')

    drop_pfo = True
    # shouldn't be in megamat/validation/diagnostic data. added for new kiwi/control
    # data.
    if drop_pfo:
        odor_names = certain_df.index.get_level_values('odor1').map(
            olf.parse_odor_name
        )
        odor_concs = certain_df.index.get_level_values('odor1').map(
            olf.parse_log10_conc
        )

        pfo_mask = odor_names == 'pfo'
        if pfo_mask.any():
            pfo_conc_set = set(odor_concs[pfo_mask])

            # TODO if this gets triggered by None/NaN, adapt to also include None/NaN
            # (if there are any negative float concs, that would indicate a bug)
            #
            # NOTE: {0.0} == {0} is True
            assert pfo_conc_set == {0}

            # TODO warn that we are dropping (if any actually dropped)
            certain_df = certain_df.loc[~pfo_mask].copy()


    index_df = certain_df.index.to_frame(index=False)

    odor1_names = index_df.odor1.apply(olf.parse_odor_name)
    mix_strs = (
        odor1_names + '+' +
        index_df.odor2.apply(olf.parse_odor_name) + ' (air mix) @ 0'
    )
    # TODO work as-is (seems to...)? need to subset RHS to be same shape?
    # (could add assertions that other part, i.e. `index_df.odor2 == solvent_str`
    # doesn't change)
    index_df.loc[index_df.odor2 != solvent_str, 'odor1'] = mix_strs

    # NOTE: see panel2name_order modifications in natmix.olf.panel2name_order, which
    # define order of these hacky new "odors" ('kmix0','kmix-1',...'cmix0','cmix-1',...)
    #
    # e.g. 'kmix @ 0' -> 'kmix0' (so concentration not recognized as such, and thus it
    # should work in modelling code that currently strips that)
    hack_strs_to_fix_mix_dilutions = (
        odor1_names + index_df.odor1.apply(olf.parse_log10_conc).map(
            lambda x: f'{x:.0f}'
        )
    )
    # expecting all these to get stripped off in modelling code
    hack_strs_to_fix_mix_dilutions = hack_strs_to_fix_mix_dilutions + ' @ 0'

    index_df.loc[odor1_names.str.endswith('mix'), 'odor1'] = \
        hack_strs_to_fix_mix_dilutions

    certain_df.index = pd.MultiIndex.from_frame(index_df)
    del index_df

    # after above two hacks, for kiwi/control data, sort_odors should order odors as:
    # pfo, components, 2-component mix, 2-component air mix, 5-component mix, dilutions
    # of 5-component mix (with more dilute mixtures further towards the end)
    certain_df = sort_odors(certain_df)

    # TODO TODO may want to preserve panel just so i can fit dF/F -> spike delta fn
    # on all, then subset to specific panels for certain plots
    #
    # TODO maybe ['panel', 'odor1']? or just drop diagnostic panel 'ms @ -3'?
    # TODO sort=False? (since i didn't have that pre-panel support, may need to sort to
    # compare to that output, regardless...)
    fly_mean_df = certain_df.groupby(['panel', 'odor1'], sort=False).mean()
    # TODO delete? restore and change code to expect 'odor' instead of 'odor1'?
    # this is just to rename 'odor1' -> 'odor'
    fly_mean_df.index.names = ['panel', 'odor']

    n_before = num_notnull(fly_mean_df)
    shape_before = fly_mean_df.shape

    # TODO actually helpful to drop ['date', 'fly_num'] cols? keeping could make
    # summarizing model input easier later... (storing alongside in fly_ids for now)
    fly_mean_df = util.add_group_id(fly_mean_df.T.reset_index(), ['date', 'fly_num'],
        name='fly_id'
    )

    fly_ids = fly_mean_df[['fly_id','date','fly_num']].drop_duplicates()
    # column level names kinda non-sensical at this intermediate ['panel', 'odor'], but
    # I think it's all fine again by end of reshaping (shape, #-not-null, and set of
    # dtypes don't change)
    fly_ids = fly_ids.droplevel('odor', axis='columns')
    # nulling out nonsensical 'panel' name
    fly_ids.columns.name = None

    fly_ids = fly_ids.set_index('fly_id')

    fly_mean_df = fly_mean_df.set_index(['fly_id', 'roi']).drop(
        columns=['date', 'fly_num'], level=0).T

    # TODO replace w/ call just renaming 'roi'->'glomerulus'
    assert 'fly_id' == fly_mean_df.columns.names[0]
    # TODO also assert len of names and/or names[1] is 'roi'?
    fly_mean_df.columns.names = ['fly_id', 'glomerulus']

    assert num_notnull(fly_mean_df) == n_before
    assert fly_mean_df.shape == shape_before
    assert set(fly_mean_df.dtypes) == {np.dtype('float64')}

    # TODO delete? here and elsewhere? (was before fly_mean_df code)
    mean_df = fly_mean_df.groupby('glomerulus', axis='columns').mean()

    # TODO factor out?
    def melt_odor_by_glom_responses(df, value_name):
        n_before = num_notnull(df)
        df = df.melt(value_name=value_name, ignore_index=False)
        assert num_notnull(df[value_name]) == n_before
        return df

    # TODO factor into fn alongside current abbrev handling
    #
    # TODO actually check this? reason to think this? why did remy originally choose to
    # do -3 for everything? PID?
    # (don't think it was b/c they had reason to think that was the best intensity-match
    # of the Hallem olfactometer... think it might have just been fear of
    # contamination...)?
    #
    # TODO make adjustments for everything else then?
    # TODO TODO guess-and-check scalar adjustment factor to decrease all hallem spike
    # deltas to make more like our -3? or not matter / scalar not helpful?
    hope_hallem_minus2_is_our_minus3 = True
    if hope_hallem_minus2_is_our_minus3:
        warn('treating all Hallem data as if -2 on their olfactometer is comparable to'
            ' -3 on ours (for estimating dF/F -> spike rate fn)'
        )
        # TODO TODO pass abbreved + conc added hallem to model_mb... fn? (to not
        # recompute there...)
        # TODO maybe it'd be more natural to pass in our data, and round all concs to:
        # -2,-4,-6,-8? might simplify consideration across this case + hallem conc
        # series case?
        hallem_delta.index += ' @ -3'
    else:
        raise NotImplementedError('no alternative at the moment...')

    # TODO TODO allow slop of +/- 1 order of magnitude in general for merging w/
    # hallem (for validation stuff in particular)?

    dff_col = 'delta_f_over_f'
    spike_delta_col = 'delta_spike_rate'
    est_spike_delta_col = f'est_{spike_delta_col}'

    # TODO TODO delete all mean_df stuff if i get fly_mean_df version working
    # (which i think i have?)?
    # (or just scale w/in each fly before reducing fly_mean_df -> mean_df)
    # (or make choice to take mean right before plotting (to switch easier?)?
    # plus then it would work post-scaling, which is what i would want)
    mean_df = melt_odor_by_glom_responses(mean_df, dff_col)
    #

    n_notnull_before = num_notnull(fly_mean_df)
    n_null_before = num_null(fly_mean_df)

    if roi_depths is not None:
        assert fly_mean_df.columns.get_level_values('glomerulus').equals(
            roi_depths.columns.get_level_values('roi')
        )
        # to also replace the ['date','fly_num'] levels w/ 'fly_id, as was done to
        # fly_mean_df above
        roi_depths.columns = fly_mean_df.columns.copy()

    fly_mean_df = melt_odor_by_glom_responses(fly_mean_df, dff_col)

    roi_depth_col = 'roi_depth_um'

    if roi_depths is not None:
        # should be ['panel', 'odor']
        index_levels_before = fly_mean_df.index.names
        shape_before = fly_mean_df.shape

        roi_depths = melt_odor_by_glom_responses(roi_depths, roi_depth_col
            ).reset_index()

        fly_mean_df = fly_mean_df.reset_index().merge(roi_depths,
            on=['panel', 'fly_id', 'glomerulus']
        )

        fly_mean_df = fly_mean_df.set_index(index_levels_before)

        assert fly_mean_df.shape[0] == shape_before[0]
        assert fly_mean_df.shape[-1] == (shape_before[-1] + 1)

    assert num_notnull(fly_mean_df[dff_col]) == n_notnull_before
    assert num_null(fly_mean_df[dff_col]) == n_null_before

    fly_mean_df = fly_mean_df.dropna(subset=[dff_col])
    if roi_depths is not None:
        # TODO and should i also check we aren't dropping stuff that's non-NaN in depth
        # col (by dropna on dff_col) (no, some odors are nulled before)?
        #
        # this should be defined whenever dff_col is
        assert not fly_mean_df[roi_depth_col].isna().any()

    assert num_notnull(fly_mean_df[dff_col]) == n_notnull_before
    assert num_null(fly_mean_df) == 0

    # TODO delete if ends up being easier (in terms of less postprocessing) to subset
    # out + reshape stuff from merged tidy df
    hallem_delta_wide = hallem_delta.copy()
    #
    hallem_delta = melt_odor_by_glom_responses(hallem_delta, spike_delta_col)


    def scaling_method_to_col(method: Optional[str]) -> str:
        if method is None:
            return dff_col
        else:
            return f'{method}_scaled_{dff_col}'


    # quantile 0 = min, 1 = max. after unstacking, columns will be quantiles.
    fly_quantiles = fly_mean_df.groupby('fly_id')[dff_col].quantile(
        [0, 0.01, 0.05, 0.5, 0.95, 0.99, 1]).unstack()

    avg_flymin = fly_quantiles[0].mean()
    avg_flymax = fly_quantiles[1].mean()

    # NOTE: seems to be more variation in upper end than in inhibitory values
    # maybe i should be scaling the two sides diff then? (didn't seem worth it)
    #
    #             0.00      0.01      0.05      0.50      0.95      0.99      1.00
    # fly_id
    # 1      -0.393723 -0.185341 -0.066075  0.088996  0.771770  1.408845  2.061222
    # 2      -0.265394 -0.113677 -0.023615  0.075681  0.546017  0.915291  1.209619
    # 3      -0.290391 -0.151183 -0.032448  0.082085  0.541723  0.831624  1.747735
    # 4      -0.284210 -0.142273 -0.026323  0.103612  0.690146  1.038761  2.208872
    # 5      -0.450574 -0.142619 -0.033605  0.135551  1.006864  1.508309  2.735914
    # 6      -0.469455 -0.135344 -0.033547  0.091594  0.722606  1.246020  1.969335
    # 7      -0.301425 -0.172252 -0.039677  0.121347  0.739866  1.235905  3.101158
    # 8      -0.377237 -0.180162 -0.048570  0.114664  0.958002  1.807228  2.692789
    # 9      -0.316237 -0.066018 -0.021773  0.058443  0.525360  0.952334  1.579931
    # 10     -0.449154 -0.238127 -0.077457  0.091946  0.841725  1.547193  2.411627
    # 11     -0.444483 -0.228012 -0.073913  0.121594  0.808650  1.315351  2.476759
    # 12     -0.524139 -0.212304 -0.065836  0.079312  0.683135  1.259982  2.623360
    # 13     -0.373534 -0.193339 -0.057145  0.141604  1.019016  1.895920  3.960306
    # 14     -0.351293 -0.218182 -0.056444  0.093895  0.878827  1.745915  2.475087

    # TODO share w/ plots from model fitting below?
    # TODO TODO use one of newer strs in al_analysis.py for this (-> move to al_util?)?
    # might this ever be 'Z-scored F' instead of dF/F?
    dff_desc = f'mean glomerulus {dff_latex}'
    # TODO refactor to preprend dff_desc inside loop (rather than manually for each
    # of these)
    scaling_method2desc = {
        None: dff_desc,

        #'minmax': f'{dff_desc}\n[0,1] scaled within fly',

        'zscore': f'{dff_desc}\nZ-scored within fly',

        'maxabs': dff_desc + '\n$fly_{max} \\rightarrow 1$, 0-preserved',

        # TODO check adding escaped '\\' in front of 'overline' (still? did it ever
        # w/o escaping the '\'?) produces what i want
        'to-avg-max':
            dff_desc + '\n$fly_{max} \\rightarrow \\overline{fly_{max}}$, 0-preserved',

        'split-minmax':
            # TODO latex working yet?
            f'{dff_desc}\n$+ \\rightarrow [0, 1]$\n$- \\rightarrow [-1, 0]$',

        'split-minmax-to-avg': (dff_desc +
            # TODO latex working yet?
            '\n$+ \\rightarrow [0, \\overline{fly_{max}}]$\n'
            '$- \\rightarrow [\\overline{fly_{min}}, 0]$'
        ),
    }

    # TODO factor out?
    # TODO rename to "add_scaled_dff_col" or something?
    def scale_one_fly(gdf: pd.DataFrame, method: str = 'to-avg-max'):
        """Adds <method>_scaled_<dff_col> column with scaled <dff_col> values.

        Does not change any existing columns of input.
        """
        assert not gdf.fly_id.isna().any() and gdf.fly_id.nunique() == 1
        col_to_scale = dff_col
        to_scale = gdf[col_to_scale]
        n_nan_before = to_scale.isna().sum()

        new_dff_col = scaling_method_to_col(method)
        assert new_dff_col not in gdf.columns

        if method == 'minmax':
            scaled = minmax_scale(to_scale)

        elif method == 'zscore':
            scaled = (to_scale - to_scale.mean()) / to_scale.std()

        # TODO maybe try a variant of 'zscore' where we dont subtract mean first? (b/c
        # want to preserve 0) (std() doesn't seem that related to fly maxes... not
        # encouraging for this strategy)

        # also preserves 0, like split-minmax* methods below, but just one scalar
        # applied to all data
        # (new min will be > -1 (and < 0), assuming abs(min) < abs(max) (and neg min))
        elif method in ('maxabs', 'to-avg-max'):
            scaled = maxabs_scale(to_scale)

            if method == 'to-avg-max':
                # in theory, max(abs) could come from negative values, but the data
                # should have larger positive dF/F, so that shouldn't happen
                assert np.isclose(scaled.max(), 1)
                scaled *= avg_flymax
                assert np.isclose(scaled.max(), avg_flymax)

        elif method in ('split-minmax', 'split-minmax-to-avg'):
            # TODO warn if no negative values in input (tho there should always be as
            # i'm currently using it) (prob fine to keep as assertion for now)
            assert (to_scale < 0).any()

            # NOTE: to_scale.index.duplicated().any() == True, so probably can't use
            # index as-is to split/re-combine data
            # TODO delete if not needed
            index = to_scale.index
            to_scale = to_scale.reset_index(drop=True)
            #

            neg = to_scale < 0
            nonneg = to_scale >= 0
            n_neg = neg.sum()
            assert len(to_scale) == (n_neg + nonneg.sum() + to_scale.isna().sum())

            scaled = to_scale.copy()
            scaled[nonneg] = minmax_scale(scaled[nonneg])

            # after minmax_scale, just scaled * (max - min) + min, to go to new range
            scaled[neg] = minmax_scale(scaled[neg]) - 1
            assert np.isclose(scaled.min(), -1)
            assert np.isclose(scaled[neg].max(), 0)

            if method == 'split-minmax-to-avg':
                scaled[nonneg] *= avg_flymax
                scaled[neg] *= abs(avg_flymin)

            # not true b/c some max of to_scale[neg] gets mapped to 0, presumably
            #assert n_neg == (scaled < 0).sum()
            # rhs here can also include 0 from min of to_scale[nonneg]
            assert n_neg <= (scaled <= 0).sum()
            assert (scaled < 0).any()

            # so it's not really re-ordering anything. that's good.
            assert np.array_equal(
                np.argsort(scaled[scaled != 0]),
                np.argsort(gdf.reset_index()[scaled != 0][col_to_scale])
            )

            # TODO delete if i remove related code changing index above
            scaled.index = index

        # TODO try pinning particular odor(s)? how?
        # TODO maybe use diags for the pinning, to share w/ validation panel flies more
        # easily?

        else:
            raise NotImplementedError(f'scaling {method=} not supported')

        assert scaled.isna().sum() == n_nan_before, 'scaling changed number of NaN'
        gdf[new_dff_col] = scaled
        return gdf

    columns_before = fly_mean_df.columns

    methods = [
        # TODO delete
        #'minmax',

        'zscore',
        'maxabs',
        'to-avg-max',
        'split-minmax',
        'split-minmax-to-avg',
    ]
    for method in methods:
        # each of these calls adds a new column, with a scaled version of dff_col.
        fly_mean_df = fly_mean_df.groupby('fly_id', sort=False, group_keys=False).apply(
            lambda x: scale_one_fly(x, method=method)
        )

    # TODO recompute and compare quartiles?
    # TODO replace w/ refactoring loop over scaling_method2desc.items() to loop over
    # scaling methods from added columns? (would need to track scaling methods for the
    # added cols, probably in scale_one_fly?)
    # (or just `continue` if column not in df...)
    # (OR now could prob use `methods` list above)
    scaled_cols = [c for c in fly_mean_df.columns if c not in columns_before]
    # to ensure we are making plots for each scaled column added
    assert (
        {scaling_method_to_col(x) for x in scaling_method2desc.keys()} ==
        {dff_col} | set(scaled_cols)
    )
    #

    # TODO delete
    # TODO better name for df... (or factor to fn so it doesn't matter)
    # (renamed fdf->merged_dff_and_hallem. need to also rename this, or probably just
    # delete it)
    #
    # doesn't seem to matter that odor is index and glomerulus is column. equiv to:
    # pd.merge(mean_df.reset_index(), hallem_delta.reset_index(),
    #     on=['odor', 'glomerulus']
    # )
    #df = mean_df.merge(hallem_delta, on=['odor', 'glomerulus']).reset_index()

    # TODO TODO decide how to handle panel when merging w/ hallem
    # (mean first for fitting dF/F -> spike delta fn, but then separately merge w/in
    # each panel for running model?)
    # (what is currently happening?)A

    # TODO TODO delete? or move to before odor2 level effectively dropped?
    # TODO gate behind there being and odor2 level?
    #
    # TODO to make this merging easier, might actually want to format mixtures down to
    # one str column, so that if [hypothetically, not in current data] odor1=solvent and
    # odor2 is in hallem, we can still match it up
    # TODO just rename hallem 'odor' -> 'odor1', and reset_index() on both
    # TODO add solvent odor2 to hallem and merge on=(odor_cols + ['glomerulus'])?
    #
    # if we only have odor2 odors for mixtures where odor1 is also an odor, we would
    # never want to merge those with hallem anyway, so we can just drop those rows
    # before merging
    '''
    odor1 = fly_mean_df.index.get_level_values('odor1')
    odor2 = fly_mean_df.index.get_level_values('odor2')
    # TODO TODO warn / err if any of this odor2 stuff is actually != solvent_str?
    # (since not currently supporting that, nor thinking that's the way i'll try to do
    # it...)
    assert not (odor1[odor2 != solvent_str] == solvent_str).any()
    # .reset_index() b/c left_on didn't seem to work w/ a mix of cols and index levels
    for_merging = fly_mean_df[odor2 == solvent_str].reset_index()

    merged_dff_and_hallem = for_merging.merge(hallem_delta,
    '''
    merged_dff_and_hallem = fly_mean_df.reset_index().merge(hallem_delta,
        left_on=['odor', 'glomerulus'], right_on=['odor', 'glomerulus']
    ).reset_index()

    assert not merged_dff_and_hallem[spike_delta_col].isna().any()

    # TODO delete
    # (note this was before 'odor'->odor_cols change)
    # TODO what's going on here? don't i have geraniol dF/F data?
    # (2024-05-09: can't repro, at least not passing all data as input. maybe passing
    # just validation2? not seeing geraniol at all now tho... that an issue?
    # can't repro w/ that input either. maybe if i don't use consensus df for input?
    # that'd probably still be dropped above tho...)
    #
    # must have been one that changed conc? after also excluding flies 2023-10-15/1,2
    # and 2023-10-19/2 (and 2024-01-05/4, not that I think this one mattered here), now
    # I'm getting the empty set for this (and geraniol not here anymore, as it's been -2
    # since 2023-11-19)
    #ipdb> set(merged_dff_and_hallem.odor.unique()) -
    # set(merged_dff_and_hallem.dropna().odor.unique())
    #{'ger @ -3'}

    # TODO print odors left after merging. something like
    # sorted(merged_dff_and_hallem.odor.unique())
    # TODO print # of (fly X glomeruli) combos (at least those that overlap w/
    # hallem) too, for each odor

    # TODO filter out low intensity stuff? (more points there + maybe more noise in
    # dF/F)
    # TODO fit from full matrix input rather than just each glomerulus as attempt at
    # ephaptic stuff?

    # TODO also print / save fly_id -> (date, fly_num) legend
    assert not merged_dff_and_hallem.fly_id.isna().any(), 'nunique does not count NaN'
    fly_palette = dict(zip(
        sorted(merged_dff_and_hallem.fly_id.unique()),
        sns.color_palette(cc.glasbey, merged_dff_and_hallem.fly_id.nunique())
    ))

    # still too hard to see density when many overlap, but 0.2 also has that issue, and
    # too hard to make out single fly colors at that point (when points arent
    # overlapping)
    scatterplot_alpha = 0.3
    # existing values in fly_palette are 3-tuples (color w/o alpha)
    fly_palette = {f: c + (scatterplot_alpha,) for f, c in fly_palette.items()}

    _cprint_color = 'blue'
    # hack to tell whether we should fit model (if input is megamat panel [which
    # overlaps well enough w/ hallem], and has at least 7 flies there, we should).
    # otherwise, we should try to load a saved model, and use that.
    try:
        # TODO delete
        '''
        if len(certain_df.loc['megamat'].dropna(axis='columns', how='all'
            ).columns.to_frame(index=False)[['date','fly_num']].drop_duplicates()
            ) >= 7:
        '''

        # TODO TODO TODO should i be recomputing now that i collected the new
        # kiwi/control data after the imaging system had a lot of time to drift?
        # check hists of dF/F / something (to compare old megamat/etc to new
        # kiwi/control data)?
        # TODO TODO maybe now i should switch to always z-scoring/similar the dF/F input
        # (before passing thru a fn to get spike deltas out), so that i can tune on one
        # panel and run on another more easily? (current attempt to tune on megamat and
        # run on control/kiwi had all silent cells in first call)

        # TODO TODO cleaner solution for this hack (probably involving preserving
        # panel throughout, and splitting each panel out before passing thru model, then
        # just always recompute model and do all in one run? now doing a prior run just
        # to save model, then later runs to pass each particular panel thru model)
        #
        # hack to only fit model if we are passing all panel (including validation)
        # data, on all flies (shape is 198x517 there)
        if (certain_df.shape[1] > 500 and len(certain_df) > 150 and

                set(certain_df.index.get_level_values('panel')) == {
                    'megamat', 'validation2', 'glomeruli_diagnostics'
                } and len(
                    certain_df.columns.to_frame(index=False)[['date','fly_num']
                        ].drop_duplicates()
                # NOTE: 9 final megamat flies and 5 final validation2 flies (after
                # dropping the 1 Betty wanted). see reproducing.md or
                # CSVs under data/sent_to_anoop/v1 for the specific flies.
                ) == (9 + 5)
            ):

            use_saved_dff_to_spiking_model = False
        else:
            use_saved_dff_to_spiking_model = True

    # TODO what exacty triggers this? doc in comment
    except KeyError:
        use_saved_dff_to_spiking_model = True

    # this option currently can't actually trigger recomputation that wouldn't happen
    # anyway... (always recomputed if input data is large enough, never otherwise)
    # TODO delete this option then?
    if use_saved_dff_to_spiking_model and should_ignore_existing('dff2spiking'):
        warn('would NOT have saved dff->spiking model, but requested regeneration of '
            'it!\n\nchange args to run on all data (so that model would get saved. see '
            'reproducing.md), OR remove `-i dff2spiking` option.'
            '\n\nexiting!'
        )
        sys.exit()

    # for histograms of dF/F, transformed versions, or estimated spike deltas derived
    # from one of the former
    n_bins = 50

    if not use_saved_dff_to_spiking_model:
        # just for histogram in loop below
        tidy_merged = merged_dff_and_hallem.reset_index()
        tidy_pebbled = fly_mean_df.reset_index()

        # TODO TODO may want to also plot on just panel subsets (here? or below, but
        # easier to do on diff scaling choices here, if i want that)
        # (only panel subsets for hist plots, not linear fit plots?)

        for scaling_method, col_desc in scaling_method2desc.items():
            curr_dff_col = scaling_method_to_col(scaling_method)
            assert curr_dff_col in merged_dff_and_hallem, f'missing {curr_dff_col}'

            # TODO put all these hists into a subdir? cluttering folder...

            fig, ax = plt.subplots()
            sns.histplot(data=tidy_merged, x=curr_dff_col, bins=n_bins, ax=ax)
            ax.set_title('pebbled (only odors & receptors also in Hallem)')
            # should be same subset of data used to fit dF/F->spiking model
            # (and same values, when scaling method matches scaling_method_to_use)
            savefig(fig, plot_dir, f'hist_pebbled_hallem-overlap_{curr_dff_col}')

            fig, ax = plt.subplots()
            sns.histplot(data=tidy_pebbled, x=curr_dff_col, bins=n_bins, ax=ax)
            ax.set_title('all pebbled')
            # TODO why this (and others) getting overwritten when being run w/ -C?
            # same w/ -c now (yes)? -P matter (don't think so)? seems to be a font
            # spacing issue for the most part? not sure why i'm just seeing it now
            # (2025)
            savefig(fig, plot_dir, f'hist_pebbled_{curr_dff_col}')

            # TODO also hist megamat subset of each of these? or at least of the pebbled
            # itself?
            # TODO or just loop over panels? easier below?


    # TODO iterate over options (just None and 'to-avg-max'? others worse) and verify
    # that what i'm using is actually the best (or not far off)?
    #scaling_method_to_use = None
    # 'to-avg-max'/'split-minmax-to-avg'/None all produce extremely visually similar
    # megamat/est_orn_spike_deltas*.pdf plots (including the correlation plots)
    # (as expected, since they keep 0)
    scaling_method_to_use = 'to-avg-max'

    add_constant = False

    # tested w/ None, 'split-minmax', and 'split-minmax-to-avg'. in all cases, the fit
    # on the negative dF/F data (and aligned subset of Hallem data) looked very bad (fit
    # was equivalent across the 2 cases, as expected). slope was negative, so more
    # negative dF/F meant less inhibition, which is nonsense.
    #
    # scaling methods were verified to not be re-ordering negative component of data.
    #
    # TODO maybe also plot just negative dF/F data (w/ aligned hallem data), to sanity
    # check the fact i was getting negative slopes?
    separate_inh_model = False

    col_to_fit = scaling_method_to_col(scaling_method_to_use)

    # TODO factor all model fitting + plotting (w/ CIs) into some hong2p fns?
    # TODO factor statsmodels fitting (+ plotting as matches seaborn)
    # into hong2p.viz (-> share w/ use in
    # natural_odors/scripts/kristina/lit_total_conc_est.py)

    # TODO refactor to move type of model to one place above?
    # NOTE: RegressionResults does not seem to be a subclass of
    # RegressionResultsWrapper. sad.
    # TODO move outside this fn
    def fit_dff2spiking_model(to_fit: pd.DataFrame) -> Tuple[RegressionResultsWrapper,
        Optional[RegressionResultsWrapper]]:

        # would need to dropna otherwise
        assert not to_fit.isna().any().any()
        to_fit = to_fit.copy()
        y_train = to_fit[spike_delta_col]

        # TODO try adding (0, 0) as as point, even if still using Ax+b as a model? is
        # that actually a valid practice? probably not, right?

        if add_constant:
            X_train = sm.add_constant(to_fit[col_to_fit])
        else:
            X_train = to_fit[col_to_fit].to_frame()

        if not separate_inh_model:
            # TODO why does this model produce a different result from the seaborn call
            # above (can tell by zooming in on upper right region of plot)??
            # TODO rename to "results"? technically the .fit() returns a results wrapper
            # or something (and do i only want to serialize the model part? can that
            # even store the parameters separately) (online info seems to say it should
            # return RegressionResults, so not sure why i'm getting
            # RegressionResultsWrapper...)
            model = sm.OLS(y_train, X_train).fit()
            inh_model = None
        else:
            nonneg = X_train[col_to_fit] >= 0
            neg = X_train[col_to_fit] < 0

            model = sm.OLS(y_train[nonneg], X_train[nonneg]).fit()
            inh_model = sm.OLS(y_train[neg], X_train[neg]).fit()

        return model, inh_model


    # TODO move outside this fn
    def predict_spiking_from_dff(df: pd.DataFrame, model: RegressionResultsWrapper,
        inh_model: Optional[RegressionResultsWrapper] = None, *, alpha=0.05,
        ) -> pd.DataFrame:
        """
        Returns dataframe with 3 additional columns: [est_spike_delta_col,
        <est_spike_delta_col>_ci_[lower|upper] ]
        """
        # TODO doc input requirements

        # TODO delete unless add_constant line below w/ series input might mutate df
        # (unlikely)
        df = df.copy()

        # would otherwise need to dropna
        assert not df.isna().any().any()

        # TODO assert saved model only has const term if add_constant?
        # do above where we load model + choices?

        # TODO see if this can be replaced w/ below (and do in other place if so)
        if add_constant:
            # returns a DataFrame w/ an extra 'const' col (=1.0 everywhere)
            X = sm.add_constant(df[col_to_fit])
        else:
            X = df[col_to_fit].to_frame()

        if not separate_inh_model:
            y_pred = model.get_prediction(X)

            # TODO what are obs_ci_[lower|upper] cols? i assume i'm right to use
            # mean_ci_[upper|lower] instead (seems so)?
            # https://stackoverflow.com/questions/60963178
            #
            # alpha=0.05 by default (in statsmodels, if not passed)
            pred_df = y_pred.summary_frame(alpha=alpha)

            predicted = y_pred.predicted
        else:
            # fly_mean_df input (call where important estimates get added) currently has
            # an index that would fail the verify_integrity=True checks below, so saving
            # this index to restore later.
            # TODO do i actually need to restore index tho?
            # TODO delete?
            #index = X.index
            X = X.reset_index(drop=True)

            nonneg = X[col_to_fit] >= 0
            neg = X[col_to_fit] < 0

            y_pred_nonneg = model.get_prediction(X[nonneg])
            y_pred_neg = inh_model.get_prediction(X[neg])

            pred_df_nonneg = y_pred_nonneg.summary_frame(alpha=alpha)
            pred_df_neg = y_pred_neg.summary_frame(alpha=alpha)

            predicted_nonneg = pd.Series(
                data=y_pred_nonneg.predicted, index=X[nonneg].index
            )
            predicted_neg = pd.Series(data=y_pred_neg.predicted, index=X[neg].index)

            pred_df = pd.concat([pred_df_nonneg, pred_df_neg], verify_integrity=True)

            # just on the RangeIndex of input (should have all consecutive indices from
            # start to end after concatenating)
            pred_df = pred_df.sort_index()
            assert pred_df.index.equals(X.index)

            predicted = pd.concat([predicted_nonneg, predicted_neg],
                verify_integrity=True
            )
            predicted = predicted.sort_index()
            assert predicted.index.equals(X.index)

            # TODO TODO restore (w/ above)? will this make predict_spiking_from_dff fn
            # return val make more sense? what was issue again?
            # TODO delete?
            #X.index = index

        # NOTE: .get_prediction(...) seems to return an object where more information is
        # available about the fit (e.g. confidence intervals, etc). .predict(...) will
        # just return simple output of model (same as <PredictionResult>.predicted).
        # (also seems to be same as pred_df['mean'])
        assert np.array_equal(predicted, pred_df['mean'])
        if not separate_inh_model:
            assert np.array_equal(predicted, model.predict(X))

        # TODO was this broken in separate inh case? (still think that case was
        # probably a dead end, so not necessarily worth fixing...)
        # (but megamat/est_orn_spike_deltas[_corr].pdf plots were all NaN it seems?)
        # (not sure i can repro)
        df[est_spike_delta_col] = predicted

        # TODO how are these CI's actually computed? how does that differ from how
        # seaborn computes them? why are they different?
        # TODO what are obs_ci_[lower|upper]? seems newer versions of statsmodels might
        # not have them anyway? or at least they aren't documented...
        for c in ('mean_ci_lower', 'mean_ci_upper'):
            df[f'{est_spike_delta_col}{c.replace("mean", "")}'] = pred_df[c]

        # TODO sort df by est_spike_delta_col before returning? would that make
        # plotting fn avoid need to do that? or prob just do in plotting fn...
        return df


    # TODO (reword to make accurate again) delete _model kwarg.
    # just using to test serialization of OLS model, since i can't figure out why this
    # equality check fails (no .equals avail):
    # > model.save('test_model.p')
    # > deserialized_model = sm.load('test_model.p')
    # > deserialized_model == model
    # False
    # > deserialized_model.remove_data()
    # > model.remove_data()
    # > deserialized_model == model
    # False
    def plot_dff2spiking_fit(df: pd.DataFrame, model: RegressionResultsWrapper,
        inh_model: Optional[RegressionResultsWrapper] = None, *, scatter=True,
        title_prefix=''):
        """
        Args:
            scatter: if True, scatterplot merged data w/ a hue for each fly. otherwise,
                plot a 2d histogram of data.
        """
        assert col_to_fit in df.columns
        assert spike_delta_col in df.columns

        ci_lower_col = f'{est_spike_delta_col}_ci_lower'
        ci_upper_col = f'{est_spike_delta_col}_ci_upper'
        est_cols = (est_spike_delta_col, ci_lower_col, ci_upper_col)
        assert all(x not in df.columns for x in est_cols)

        if separate_inh_model:
            assert inh_model is not None
        else:
            assert inh_model is None

        # functions passed to FacetGrid.map[_dataframe] must plot to current Axes
        ax = plt.gca()

        # TODO was seaborn results suggesting i wanted alpha 0.025 for 95% CI here?
        # (honestly, seaborn CI [which is supposedly 95%, tho bootstrapped] looks wider
        # in all cases)
        #
        # from looking at statsmodels code, I'm pretty sure their "95% CI" is centered
        # on estimate, w/ alpha/2 on either side (so 0.05 correct for 95%, not 0.025)
        alpha_for_ci = 0.05

        # TODO include what alpha is in name of cols returned from predict (-> delete
        # explicit pass-in here)?
        df = predict_spiking_from_dff(df, model, inh_model, alpha=alpha_for_ci)

        assert all(x in df.columns for x in est_cols)

        plot_kws = dict(ax=ax, data=df, y=spike_delta_col, x=col_to_fit)
        if scatter:
            sns.scatterplot(hue='fly_id', palette=fly_palette, legend='full',
                edgecolors='none', **plot_kws
            )
        else:
            # TODO set bins= (seems OK w/o)?
            #
            # default blue 2d hist color would probably not work well w/ current blue
            # fit line
            sns.histplot(color='red', cbar=True, **plot_kws)

        # TODO can i replace all est_df below w/ just df?

        xs = df[col_to_fit]
        if not separate_inh_model:
            est_df = df
        else:
            neg = df[col_to_fit] < 0
            nonneg = df[col_to_fit] >= 0

            est_df = df[nonneg]
            xs = xs[nonneg]

        # sorting was necessary for fill_between below to work correctly
        sorted_indices = np.argsort(xs).values
        xs = xs.iloc[sorted_indices]
        est_df = est_df.iloc[sorted_indices]

        color = 'blue'
        fill_between_kws = dict(alpha=0.2,
            # TODO each of these needed? try to recreate seaborn (set color_palette the
            # same / use that seaborn blue?)
            linestyle='None', linewidth=0, edgecolor='white'
        )
        ax.plot(xs, est_df[est_spike_delta_col], color=color)
        ax.fill_between(xs, est_df[ci_lower_col], est_df[ci_upper_col], color=color,
            **fill_between_kws
        )
        if separate_inh_model:
            inh_color = 'red'
            # pylint: disable=possibly-used-before-assignment
            xs = df[col_to_fit][neg]
            est_df = df[neg]

            # TODO refactor to share w/ above?
            sorted_indices = np.argsort(xs).values
            xs = xs.iloc[sorted_indices]
            est_df = est_df.iloc[sorted_indices]

            ax.plot(xs, est_df[est_spike_delta_col], color=inh_color)
            ax.fill_between(xs, est_df[ci_lower_col], est_df[ci_upper_col],
                color=inh_color, **fill_between_kws
            )

        if add_constant:
            # TODO refactor
            model_eq = (f'$\\Delta$ $spike$ $rate = {model.params[col_to_fit]:.1f} x + '
                f'{model.params["const"]:.1f}$'
            )
            # TODO assert no other parameters besides col_to_fit and const?
        else:
            model_eq = f'$\\Delta$ $spike$ $rate = {model.params[col_to_fit]:.1f} x$'
            # TODO assert no other parameters besides col_to_fit?

        if separate_inh_model:
            assert not add_constant, 'not yet implemented'
            model_eq = (f'{model_eq}\n$\\Delta$ '
                f'$spike$ $rate_{{inh}} = {inh_model.params[col_to_fit]:.1f} x$'
            )

        y_train = df[spike_delta_col]

        # https://en.wikipedia.org/wiki/Coefficient_of_determination
        ss_res = ((y_train - df[est_spike_delta_col])**2).sum()

        ss_tot = ((y_train - y_train.mean())**2).sum()

        # TODO make sense that this can be negative??? (for some of the glomerulus
        # specific fits. see by-glom_dff_vs_hallem__dff_scale-to-avg-max.pdf)
        # think so: https://stats.stackexchange.com/questions/12900
        # just means fit is worse than a horizontal line?
        #
        # using this R**2 just temporarily to be more comparable to values
        # reported for add_constant=True cases
        r_squared = 1 - ss_res / ss_tot

        if add_constant:
            assert np.isclose(r_squared, model.rsquared)

        # for why R**2 (as reported by model.rsquared) higher w/o intercept:
        # https://stats.stackexchange.com/questions/267325
        # https://stats.stackexchange.com/questions/26176

        # ...and some discussion about whether it makes sense to fit w/o intercept:
        # https://stats.stackexchange.com/questions/7948
        # https://stats.stackexchange.com/questions/102709

        # now only including this in title if we are able to recalculate R**2
        # (may be possible from model alone, but not sure how to access y_train from
        # model, if possible)
        #
        # TODO rsquared_adj useful in comparing these two models w/ diff # of
        # parameters?
        # TODO want anything else in here? don't really think p-val would be useful

        goodness_of_fit_str = (f'$R^2 = {r_squared:.4f}$'
            # TODO delete (or recalc for add_constant=False case, as w/ R**2
            # above)
            # TODO only include this if we have more than 1 param (i.e. if
            # add_constant=True). otherwise, R**2 should be equal to R**2_adj
            #f', $R^2_{{adj}} = {model.rsquared_adj:.4f}$'
        )
        ci_str = f'{((1 - alpha_for_ci) * 100):.3g}% CI on fit'
        title = f'{title_prefix}{model_eq}\n{goodness_of_fit_str}\n{ci_str}'
        ax.set_title(title)

        assert ax.get_xlabel() == col_to_fit
        desc = scaling_method2desc[scaling_method_to_use]
        ax.set_xlabel(f'{col_to_fit}\n{desc}')


    copy_to_model_dirs = []

    dff_to_spiking_model_path = plot_dir / 'dff2spiking_fit.p'
    copy_to_model_dirs.append(dff_to_spiking_model_path)

    if separate_inh_model:
        dff_to_spiking_inh_model_path = plot_dir / 'dff2spiking_inh_fit.p'
        copy_to_model_dirs.append(dff_to_spiking_inh_model_path)

    dff_to_spiking_data_csv = plot_dir / 'dff2spiking_model_input.csv'
    copy_to_model_dirs.append(dff_to_spiking_data_csv)

    # TODO move all fitting + plotting up above (~where current seaborn plotting
    # is), so i can do for all scaling choices, like w/ current seaborn plots (still
    # just doing modelling w/ one scaling choice)

    # so we have a record of which scaling choice we made (modelling plots already show
    # many parameters and this one isn't going to vary across modelling outputs from a
    # given run)
    # TODO TODO save this and other non-plot outputs we need to load saved dF/F->spiking
    # fit outside of plot dirs, so i can swap between png and pdf w/o issue...
    dff_to_spiking_model_choices_csv = plot_dir / 'dff2spiking_model_choices.csv'
    copy_to_model_dirs.append(dff_to_spiking_data_csv)

    def _write_inputs_for_reproducibility(plot_root: Path, param_dict: Dict[str, Any]
        ) -> None:
        # plot_root should be the panel plot dir,
        # e.g. pebbled_6f/pdf/ijroi/mb_modeling/megamat
        assert plot_root.is_dir()

        output_dir = plot_root / param_dict['output_dir']
        assert output_dir.is_dir()

        used_model_cache = param_dict.get('used_model_cache', True)
        # should be ok to write these files regardless of `-c`
        # (check_outputs_unchanged) flag value, because we must have made it
        # thru fit_and_plot... above w/o it tripping anything
        if used_model_cache:
            return

        if al_util.verbose:
            print(f'copying model inputs to {output_dir.name}:')

        for to_copy in copy_to_model_dirs:
            # would need to check copy2 behavior in this case, if wanted to support
            assert not to_copy.is_symlink()

            dst = output_dir / to_copy.name

            if al_util.verbose:
                print(f'copying {to_copy}')

            # TODO or load/save, using diff fns for this depending on ext? not sure i
            # gain anything from that...
            #
            # should preserve as much file metadata as possible (e.g. modification
            # time). will overwrite `dst`, if it already exists.
            shutil.copy2(to_copy, dst)

        # TODO refactor to share date_format= part w/ consensus_df saving i copied this
        # from? / delete? not sure it's even relevant if date is in index...
        to_csv(unmodified_orn_dff_input_df, output_dir / 'full_orn_dff_input.csv',
            date_format=date_fmt_str
        )
        to_pickle(unmodified_orn_dff_input_df, output_dir / 'full_orn_dff_input.p')


    # TODO anything else i need to include in this?
    dff_to_spiking_model_choices = pd.Series({
        # TODO None survive round trip here? use 'none' / NaN instead?
        'scaling_method_to_use': scaling_method_to_use,
        'add_constant': add_constant,
        'separate_inh_model': separate_inh_model,
    })

    def read_dff_to_spiking_model_choices():
        bool_params = ('add_constant', 'separate_inh_model')

        ser = read_series_csv(dff_to_spiking_model_choices_csv,
            # TODO some way to infer add_constant dtype correctly (as bool)
            # (this didn't work)
            #dtype={'add_constant': bool}
        )

        for x in bool_params:
            if not type(ser[x]) is bool:
                x_lower = ser[x].lower()
                assert x_lower in ('true', 'false')
                ser[x] = x_lower == 'true'

        return ser

    if not use_saved_dff_to_spiking_model:
        to_csv(dff_to_spiking_model_choices, dff_to_spiking_model_choices_csv,
            header=False
        )
        # to check no more dtype issues (and just that we saved correctly)
        saved = read_dff_to_spiking_model_choices()
        assert saved.equals(dff_to_spiking_model_choices)
        del saved

        # TODO also add depth col (when available) here?
        cols_to_save = ['fly_id', 'odor', 'glomerulus', dff_col]

        if col_to_fit != dff_col:
            cols_to_save.append(col_to_fit)

        cols_to_save.append(spike_delta_col)

        assert all(c in merged_dff_and_hallem.columns for c in cols_to_save)
        dff_to_spiking_data = merged_dff_and_hallem[cols_to_save].copy()

        dff_to_spiking_data = dff_to_spiking_data.rename({
                col_to_fit: f'{col_to_fit} (X_train)',
                spike_delta_col: f'hallem_{spike_delta_col} (y_train)',
            }, axis='columns'
        )
        shape_before = dff_to_spiking_data.shape

        dff_to_spiking_data = dff_to_spiking_data.merge(fly_ids, left_on='fly_id',
            right_index=True
        )
        assert dff_to_spiking_data.shape == (shape_before[0], shape_before[1] + 2)
        assert num_null(dff_to_spiking_data) == 0

        # NOTE: ['odor', 'fly_id', 'glomerulus'] would be unique if not for those few
        # odors that are in two panels in one fly (e.g. 'ms @ -3' in diag and megamat).
        # we don't currently have 'panel' info in this df, so may need to keep in mind
        # if using saved data.
        # TODO include panel? (would need to merge in a way that preserves that. don't
        # think i currently do... shouldn't really matter)

        # TODO also save hallem receptor in a col here?
        to_csv(dff_to_spiking_data, dff_to_spiking_data_csv, index=False,
            date_format=date_fmt_str
        )

        model, inh_model = fit_dff2spiking_model(merged_dff_and_hallem)

        # TODO also save model.summary() to text file?
        cprint(f'saving dF/F -> spike delta model to {dff_to_spiking_model_path}',
            _cprint_color
        )
        save_model(model, dff_to_spiking_model_path)

        if separate_inh_model:
            cprint(
                f'saving separate inhibition model to {dff_to_spiking_inh_model_path}',
                _cprint_color
            )
            save_model(model, dff_to_spiking_inh_model_path)

        # TODO delete / put behind checks flag
        #deserialized_model = sm.load(dff_to_spiking_model_path)
        # TODO other comparison that would work after model.remove_data()?
        # care to remove_data? probably not
        #
        # ok, this is true at least...
        # TODO why is this failing now (seems to only be a line containing Time, and
        # only in the time part of that line. doesn't matter.)
        # from diffing these:
        # Path('model_summary.txt').write_text(str(model.summary()))
        # Path('deser_model_summary.txt').write_text(str(deserialized_model.summary()))
        # tom@atlas:~/src/al_analysis$ diff model_summary.txt deser_model_summary.txt
        # 7c7
        # < Time:                        15:46:35   Log-Likelihood:                         -17078.
        # ---
        # > Time:                        15:46:46   Log-Likelihood:                         -17078.
        #
        # TODO find a replacement check?
        #assert str(deserialized_model.summary()) == str(model.summary())
        #

        # TODO (reword to update / delete) use _model kwarg in predict to check
        # serialized->deser model is behaving same (below, where predict is called)
    else:
        # TODO TODO print some short summary of this data (panels, numbers of flies,
        # etc)
        cprint(f'using saved dF/F -> spiking model {dff_to_spiking_model_path}',
            _cprint_color
        )
        if separate_inh_model:
            cprint(
                f'using separate inhibition model from {dff_to_spiking_inh_model_path}',
                _cprint_color
            )

        cached_model_choices = read_dff_to_spiking_model_choices()
        if not cached_model_choices.equals(dff_to_spiking_model_choices):
            # TODO reword. -i dff2spiking w/ input data < all of it will not actually do
            # anything (cause model only ever saved if all data passed in)
            warn('current hardcoded model choices did not match those from saved model!'
                '\nre-run, adding `-i dff2spiking` to overwrite cached model (or just '
                'w/ all data as input... see reproducing.md) exiting!'
            )
            sys.exit()

        # TODO TODO save this and other non-plot outputs we need to load saved
        # dF/F->spiking fit outside of plot dirs, so i can swap between png and pdf w/o
        # issue...
        #
        # possible this alone has the input data, but save/loading that in parallel,
        # since i couldn't figure out how to access from here
        model = sm.load(dff_to_spiking_model_path)
        if separate_inh_model:
            inh_model = sm.load(dff_to_spiking_inh_model_path)
        else:
            inh_model = None

        # TODO load + summarize model input data
        # TODO +also load+summarize model choices

    # TODO still show if verbose=True or something?
    #print('dF/F -> spike delta model summary:')
    #print(model.summary())

    X0_test = pd.DataFrame({col_to_fit: 0.0}, index=[0])
    if add_constant:
        X0_test = sm.add_constant(X0_test)

    y0 = model.get_prediction(X0_test).predicted
    if add_constant:
        # may be close, but unlikely to equal 0 exactly
        assert y0 != 0.0
    else:
        assert y0 == 0.0

    # don't want to clutter str w/ the most typical values of these
    exclude_param_for_vals = {
        # always want to show scaling_method_to_use value
        #
        # TODO when these are true, maybe just include the str (w/o the '-True' suffix)?
        'add_constant': False,
        'separate_inh_model': False,
    }
    assert all(k in dff_to_spiking_model_choices.keys() for k in exclude_param_for_vals)
    params_for_suffix = {k: v for k, v in dff_to_spiking_model_choices.items()
        if not (k in exclude_param_for_vals and v == exclude_param_for_vals[k])
    }

    param_abbrevs = {
        'scaling_method_to_use': 'dff_scale',
        'add_constant': 'add_const',
        'separate_inh_model': 'separate_inh',
    }
    # TODO also thread (something like) this thru to be included in titles?
    dff2spiking_choices_str = '__'.join([
        f'{param_abbrevs[k] if k in param_abbrevs else k}-{v}'
        for k, v in params_for_suffix.items()
    ])

    if not use_saved_dff_to_spiking_model:
        plot_fname = f'dff_vs_hallem__{dff2spiking_choices_str}'

        fig, _ = plt.subplots()
        # TODO factor into same fn that fits model?
        plot_dff2spiking_fit(merged_dff_and_hallem, model)
        # normalize_fname=False to prevent '__' from getting replaced w/ '_'
        # TODO TODO fix -c/-C failure here!
        # TODO add a to_csv(merged_dff_and_hallem, <some-path>) call first, to
        # sanity check input data not changing (pretty sure it's not)?
        # TODO need to change tolerance values in savefig (-c/-C) check of output
        # equivalence? or possible to make this completely deterministic (can i repro
        # this -c/-C failure on adjacent runs? maybe something actually did change?)?
        # sns.scatterplot and mpl.scatterplot (which former calls) both seem
        # deterministic though... or at least don't seem to have any seed kwargs / etc.
        # this was also the part of the plot that seemed (from the diff) like it had
        # changed...
        savefig(fig, plot_dir, plot_fname, normalize_fname=False)

        fig, _ = plt.subplots()
        # this one should plot fit over a 2d hist of data
        plot_dff2spiking_fit(merged_dff_and_hallem, model, scatter=False)
        savefig(fig, plot_dir, f'{plot_fname}_hist2d', normalize_fname=False)

        _seen_group_vals = set()
        def fit_and_plot_dff2spiking_model(*args, group_col=None, **kwargs):
            assert len(args) == 0
            assert 'label' not in kwargs
            # TODO OK to throw away color kwarg like this? my plotting fn uses
            # fly_palette internally...
            assert set(kwargs.keys()) == {'data', 'color'}

            df = kwargs['data']
            model, inh_model = fit_dff2spiking_model(df)

            group_vals = set(df[group_col].unique())
            assert len(group_vals) == 1
            group_val = group_vals.pop()
            group_tuple = (group_col, group_val)
            assert group_tuple not in _seen_group_vals, f'{group_tuple=} already seen'
            _seen_group_vals.add(group_tuple)

            assert group_col in ('glomerulus', 'depth_bin')
            if group_col == 'glomerulus':
                # TODO add receptors in parens after glom, for easy ref to hallem paper?
                if roi_depths is not None:
                    avg_depth_col = f'avg_{roi_depth_col}'
                    assert df[avg_depth_col].nunique() == 1
                    avg_roi_depth_um = df[avg_depth_col].unique()[0]

                    title_prefix = \
                        f'{group_val} (avg depth: {avg_roi_depth_um:.1f} $\\mu$m)\n'
                else:
                    title_prefix = f'{group_val}\n'

            elif group_col == 'depth_bin':
                title_prefix = f'{group_val} $\\mu$m\n'

            # pylint: disable-next=possibly-used-before-assignment
            plot_dff2spiking_fit(df, model, inh_model, title_prefix=title_prefix)


        if roi_depths is not None:
            avg_depth_per_glomerulus = merged_dff_and_hallem.groupby('glomerulus')[
                roi_depth_col].mean()
            avg_depth_per_glomerulus.name = f'avg_{roi_depth_col}'
            merged_dff_and_hallem = merged_dff_and_hallem.merge(
                avg_depth_per_glomerulus, left_on='glomerulus', right_index=True
            )

            merged_dff_and_hallem = merged_dff_and_hallem.sort_values(
                f'avg_{roi_depth_col}').reset_index(drop=True)

        else:
            merged_dff_and_hallem = merged_dff_and_hallem.sort_values('glomerulus'
                ).reset_index(drop=True)

        col = 'glomerulus'
        # TODO default behavior do this anyway? easier way?
        grid_len = int(np.ceil(np.sqrt(merged_dff_and_hallem[col].nunique())))

        # to remove warning 'The figure layout has changed to tight' otherwise generated
        # when each FacetGrid is contructed (b/c my mpl rcParams use constrained layout
        # by default).
        #
        # setting layout='tight' via FacetGrid subplot_kws didn't work to fix (produced
        # an error), nor could gridspec_kws, as those are ignored if col_wrap passed.
        with mpl.rc_context({'figure.constrained_layout.use': False}):
            g = sns.FacetGrid(data=merged_dff_and_hallem, col=col, col_wrap=grid_len)
            g.map_dataframe(fit_and_plot_dff2spiking_model, group_col=col)

            viz.fix_facetgrid_axis_labels(g)
            savefig(g, plot_dir, f'by-glom_{plot_fname}', normalize_fname=False)

        if roi_depths is not None:
            # TODO maybe also show list of glomeruli in each bin for plot below?
            # (would need to get wrapping to work in commented code above. too many to
            # list nicely in one line.)
            # TODO or least print these glomeruli (+ value_counts?)

            n_depth_bins_options = (2, 3, 4, 5)
            for n_depth_bins in n_depth_bins_options:
                # should be a series of length equal to merged_dff_and_hallem
                # (w/ CategoricalDtype)
                depth_bins = pd.cut(merged_dff_and_hallem[roi_depth_col], n_depth_bins)

                df = merged_dff_and_hallem.copy()

                df['depth_bin'] = depth_bins

                col = 'depth_bin'
                grid_len = int(np.ceil(np.sqrt(df[col].nunique())))

                with mpl.rc_context({'figure.constrained_layout.use': False}):
                    g = sns.FacetGrid(data=df, col=col, col_wrap=grid_len)
                    g.map_dataframe(fit_and_plot_dff2spiking_model, group_col=col)

                    viz.fix_facetgrid_axis_labels(g)
                    savefig(g, plot_dir, f'by-depth-bin-{n_depth_bins}_{plot_fname}',
                        normalize_fname=False
                    )

        # TODO try a depth specific model too (seems not worth, from depth binned plots)
        # (quite clear overall scale changes when i need to avoid strongest responding
        # plane b/c contamination. e.g. often VA4 has contamination p-cre response in
        # highest (strongest) plane, from one of the nearby/above glomeruli that
        # responds to that)
        #
        # TODO try directly estimating fn like:
        # A(B*depth*x)? how would be best?
        # since it's linear, couldn't i just do:
        # A*depth*x?
        # i guess i might like to try nonlinear fns of depth, or at least to make depth
        # scaling more interpretable, but idk...
        # TODO or maybe i want A(B*depth + x)?
        # either way, i want to make sure that 0 dff is always 0 est spike delta
        # (regardless of depth), so making me thing i dont want this additive model...
        # TODO try scipy optimization stuff?
        #
        # TODO also compare to just adding a param for depth in linear model
        # (but otherwise still using all data for fit)
        # TODO possible to have automated detection of outlier glomeruli? i.e. those
        # benefitting from different fits


    # TODO TODO histogram of est spike deltas this spits out
    # (to what extent is that already done in loop over panels below?)
    # TODO are only NaNs in the dff_col in here coming from setting-wrong-odors-NaN
    # above?
    # TODO can delete branches in predict only for plotting w/ this input (don't
    # actually care about the plot here)
    #
    # this predict(...) call is the one actually adding the estimated spike deltas,
    # computed from data to be modelled (which can be different from data originally
    # used to compute dF/F -> spike delta est fn).
    fly_mean_df = predict_spiking_from_dff(fly_mean_df, model, inh_model)

    # TODO also save fly_mean_df similar to how we save dff2spiking_model_input.csv
    # above (for other people to analyze arbitrary subsets of est spike deltas /
    # whatever) (maybe refactor above to share + use panel_prefix from below?)
    # TODO + do same under each panel dir, for each panels data?

    # TODO TODO test whether downstream code works fine w/o stopping here (at least
    # check equiv in megamat case. may want to hardcode a skip of the validation2 panel
    # by default anyway [w/ a flag])
    # TODO would checking megamat subset of fly_mean_df is same between two runs (w/ all
    # data vs just megamat flies) get us most/all of the way there?
    #
    # TODO delete hack (see corresponding hack above where this flag is defined)
    # (plus now rest of modeling code loops over panels anyway, no?)
    if not use_saved_dff_to_spiking_model:
        print('EXITING EARLY AFTER HAVING SAVED MODEL ON ALL DATA (analyze specific '
            'panels with additional al_analysis runs, restricting date range to only '
            'one panel)!'
        )
        sys.exit()
    #

    # TODO plot histogram of fly_mean_df[est_spike_delta_col] (maybe resting on the x
    # axis in the same kind of scatter plot of (x=dF/F, y=delta spike rate,
    # hue=fly_id)?)

    # TODO rename? it's a series here, not a df (tho that should change in next
    # re-assignment, the one where RHS is unstacked...)
    mean_est_df = fly_mean_df.reset_index().groupby(['panel', 'odor', 'glomerulus'],
        sort=False)[est_spike_delta_col].mean()

    # then odors will be columns and glomeruli will be rows, which is same as
    # orns.orns().T
    mean_est_df = mean_est_df.unstack(['panel', 'odor'])

    # TODO delete?
    # TODO why was this getting triggered when run w/ megamat data, but not w/
    # kiwi/control data? not sure it matters...
    # was gonna sort again here, but seems true already
    #assert mean_est_df.equals(sort_odors(mean_est_df))
    #
    mean_est_df = sort_odors(mean_est_df)

    # can fail -C/-c, cause this saves directly under:
    # <driver>_<indicator>/<plot_fmt>/ijroi/mb_modeling (instead of any panel-specific
    # subdirectory of `mb_modeling`), so multiple runs with different panels (typically
    # defined by start/end date args to `al_analysis.py`) will have different data here.
    to_csv(mean_est_df, plot_dir / 'mean_est_spike_deltas.csv',
        ignore_output_change_check=True
    )

    # TODO factor all dF/F -> spike delta fitting (above, ending ~here) into one fn in
    # here at least, to make model_mb_responses more readable

    # TODO TODO possible to get spike rates for any of the other door data sources?
    # available in their R package?

    # TODO TODO how to do an ephaptic model? possible to optimize one using my
    # data as input (where we never have the channels separated)? if using hallem, for
    # what fraction of sensilla do we have all / most contained ORN types?
    # TODO which data to use for ephaptic effects / how?
    # TODO plot ephaptic model adjusted dF/F (subtracting from other ORNs in sensilla)
    # vs spike rate?

    # TODO TODO plot mean_est_df vs same subset of hallem, just for sanity checking
    # (as a matrix in each case)
    # TODO TODO and do w/ my ORN input (untransformed by dF/F -> spike delta model?),
    # also my ORN input subset to hallem stuff
    # (computing correlation in each case, with nothing going thru MB model first)

    # TODO drop all non-megamat odors prior to running through fit_mb_model?
    # (no, want to model other stuff now too...) (am i not currently doing this tho?)
    # (diagnostics prob gonna produce much lower KC sparsity)
    # (are any of the non-HALLEM odors (which is probably most non-megamat odors?)
    # actually influencing model in fit_mb_model tho?)

    # TODO are relative sparsities recapitulating what remy seems? even broadly?

    # TODO TODO try fitting on hallem, and then running on my data passed thru
    # dF/F model (fitting on all hallem might produce very different thresholds from
    # fitting on the subset of odors remy uses!!!)

    hallem_for_comparison = hallem_delta_wide.copy()
    assert hallem_for_comparison.index.str.contains(' @ -3').all()
    # so things line up in comparison_orns path (fit_mb_model hallem data has '@ -2'
    # for each conc)
    hallem_for_comparison.index = hallem_for_comparison.index.str.replace(
        ' @ -3', ' @ -2'
    )
    # TODO delete? actually needed by anything?
    hallem_for_comparison.index.name = 'odor1'

    # TODO move all hallem version of this above loop over panels (done?)
    tidy_hallem = hallem_for_comparison.T.stack()
    # just to rename the second level from 'odor1'->'odor', to be consistent w/
    # above
    tidy_hallem.index.names = ['glomerulus', 'odor']
    tidy_hallem.name = spike_delta_col
    tidy_hallem = tidy_hallem.reset_index()
    fig, ax = plt.subplots()
    sns.histplot(data=tidy_hallem, x=spike_delta_col, bins=n_bins, ax=ax)
    ax.set_title('all Hallem')
    # TODO TODO fix -c failure (just a tolerance thing?)
    savefig(fig, plot_dir, 'hist_hallem')

    # TODO move inside loop (doing for every panel, not just megamat)?
    tidy_hallem_megamat = tidy_hallem.loc[
        tidy_hallem.odor.apply(odor_is_megamat)
    ].copy()

    fig, ax = plt.subplots()
    sns.histplot(data=tidy_hallem_megamat, x=spike_delta_col, bins=n_bins, ax=ax)
    ax.set_title('Hallem megamat')
    savefig(fig, plot_dir, 'hist_hallem_megamat')

    # TODO also include actual equation for scaling in this (just one constant w/
    # current choices)? currently just includes choices that influence that, but since
    # we aren't including full data in there (though we are copying it to each model dir
    # now), we can't quickly tell which scaling factor was used
    # (could refactor part of plotting code that gets `model_eq` for title, and use that
    # str equation here too? might want a bit more precision on some params, so maybe
    # include them [e.g. `model.params`] as well?)
    #
    # will be saved alongside later params, inside each model output dir
    # (for reproducibility)
    extra_params = {
        f'dff2spiking_{k}': v for k, v in dff_to_spiking_model_choices.to_dict().items()
    }

    # slightly nicer number (less sig figs) that is almost exactly the same as the
    # sparsity computed on remy's data (from binarized outputs she gave me on
    # 2024-04-03)
    remy_sparsity = 0.0915

    checks = True
    if checks:
        # TODO compute + use separate remy sparsity from validation data (not sure i'm
        # actually going to continue doing any modelling for the validation data. don't
        # think any of it is making it in to paper)? have what i need for that already,
        # or need something new from her?
        #
        # 0.091491682899149
        remy_sparsity_exact = remy_megamat_sparsity()

        # remy_sparsity_exact - remy_sparsity: -8.317100850752102e-06
        assert abs(remy_sparsity_exact - remy_sparsity) <= 1e-5

    # TODO TODO switch to using default of 0.1 for kiwi stuff. nicer number (and
    # close to this anyway) (maybe for anything unless panels is in megamat/validation2,
    # in which case i can override default in loop below)
    target_sparsities = (remy_sparsity,)

    # TODO hardcode list of panels to NOT run sensitivity analysis on (just
    # validation2?)?

    # TODO delete eventually
    assert mean_est_df.equals(sort_odors(mean_est_df))

    # TODO support list values (-> iterate over)? (as long as directories would have
    # diff names)
    #
    # which panel(s) to use to "tune" the model (i.e. set the two inhibitory
    # parameters), to achieve the target sparsity. if a panel is not included in keys
    # here, it will just be tuned on it's own data.
    panel2tuning_panels = {
        'kiwi': ('kiwi', 'control'),
        'control': ('kiwi', 'control'),

        # TODO any way to salvage this idea? check dF/F distributions between the two
        # first? maybe z-score first or something? currently getting all silent cells in
        # first model (control + hemibrain) run this way.
        # TODO TODO and how do the parameters compare across the panels again?
        # i thought they were in a similar range? different enough i guess?
        #
        # running w/ `./al_analysis.py -d pebbled -n 6f -t 2023-04-22` for this.
        # (certain_df only has the flies i expected, which is the 9 megamat +
        # 5 validation + 9 kiwi/control flies)
        #'kiwi': ('megamat',),
        #'control': ('megamat',),

        # TODO also try using 'megamat' tuning for 'validation', and see how that
        # affects things?

        # TODO delete? was to test pre-tuning code working as expected.
        # (used new script al_analysis/check_pretuned_vs_not.py to compare responses +
        # spike counts from each) (not seeing this script... move to test if i find it?)
        #
        # TODO TODO how to keep this in as an automated check? or move to a separate
        # test script (model_test.py, or something simliar?)? currently i need to
        # manually compare the outputs across the old/new dirs
        # (add panel2tuning_panels as kwarg of model_mb_responses -> make 2 calls?)
        #'megamat': ('megamat',)
        #
    }
    assert all(type(x) is tuple for x in panel2tuning_panels.values())
    # sorting so dir (which will include tuning panels) will always be the same
    panel2tuning_panels = {k: tuple(sorted(v)) for k, v in panel2tuning_panels.items()}

    tuning_panel_delim = '-'

    new_panels = {tuning_panel_delim.join(x) for x in panel2tuning_panels.values()}
    existing_panels = set(mean_est_df.columns.get_level_values('panel'))
    if any(x in existing_panels for x in new_panels):
        warn(f'some of {new_panels=} are already in {existing_panels=}! should only '
            'see this warning if testing that we can reproduce model output by '
            'pre-tuning with the same panel we later use to run the model!'
        )
    del new_panels, existing_panels

    # TODO want to drop the panel column level? or want to use it inside calls to
    # fit_and_plot...? groupby kwarg for dropping, if i want former?
    for panel, panel_est_df in mean_est_df.groupby('panel', axis='columns', sort=False):

        if panel == diag_panel_str:
            continue

        # TODO delete eventually
        assert panel_est_df.equals(sort_odors(panel_est_df))
        #
        # TODO delete (assertion above passing. seems we can rely on mean_est_df being
        # sorted)
        #panel_est_df = sort_odors(panel_est_df)

        panel_plot_dir = plot_dir / panel
        makedirs(panel_plot_dir)

        # these will have one row per model run, with all relevant parameters (as well
        # as a few other variables/statistics computed within model runs, e.g. sparsity)
        model_param_csv = panel_plot_dir / 'tuned_params.csv'
        model_params = None

        raw_dff_panel_df = sort_odors(certain_df.loc[panel], panel=panel)

        mean_fly_dff_corr = mean_of_fly_corrs(raw_dff_panel_df)

        # just checking that mean_of_fly_corrs isn't screwing up odor order, since
        # raw_dff_panel_df odors are sorted (and easier to check against panel_est_df,
        # as that doesn't have the repeats in it like raw_dff_panel_does, but the order
        # of the odors in the two should be the same)
        assert mean_fly_dff_corr.columns.equals(mean_fly_dff_corr.index)
        # this doesn't check .name, which is good, b/c mean_fly_dff_corr has 'odor1',
        # not 'odor'
        assert mean_fly_dff_corr.columns.equals(
            panel_est_df.columns.get_level_values('odor')
        )

        # TODO (just for ticklabels in plots) for kiwi/control at least (but maybe for
        # everything?) hide the '@ 0' part of conc strs [maybe unless there is another
        # odor w/ a diff conc, but may not matter]

        # TODO restore response matrix plot versions of these (i.e. plot responses in
        # addition to just corrs) (would technically be duped w/ ijroi versions, for
        # convenient comparison to 'est_orn_spike_deltas*' versions? or symlink to the
        # ijroi one?
        plot_corr(mean_fly_dff_corr, panel_plot_dir, 'orn_dff_corr',
            # TODO TODO use one of newer strs in al_analysis.py for this (-> move to
            # al_util?)? might this ever be 'Z-scored F' instead of dF/F?
            xlabel=f'ORN {dff_latex}'
        )

        fly_dff_hallem_subset = raw_dff_panel_df.loc[:,
            raw_dff_panel_df.columns.get_level_values('roi').isin(
                hallem_delta_wide.columns
            )
        ]
        mean_fly_dff_hallem_corr = mean_of_fly_corrs(fly_dff_hallem_subset)
        plot_corr(mean_fly_dff_hallem_corr, panel_plot_dir,
            'orn_dff_hallem-subset_corr',
            # TODO TODO use one of newer strs in al_analysis.py for this (-> move to
            # al_util?)? might this ever be 'Z-scored F' instead of dF/F?
            xlabel=f'ORN {dff_latex}\nHallem glomeruli only'
        )
        plot_corr(mean_fly_dff_hallem_corr, panel_plot_dir,
            'orn_dff_hallem-subset_corr-dist',
            # TODO TODO use one of newer strs in al_analysis.py for this (-> move to
            # al_util?)? might this ever be 'Z-scored F' instead of dF/F?
            xlabel=f'ORN {dff_latex}\nHallem glomeruli only', as_corr_dist=True
        )

        # TODO delete / move to al_analysis (get_gh146_glomeruli was only used in
        # al_analysis.py other than here, so didn't refactor it to al_util)
        '''
        gh146_glomeruli = get_gh146_glomeruli()
        # NOTE: true for megamat at least, may not be true for validation2
        if panel == 'validation2':
            assert {'VA4'} == (
                gh146_glomeruli - set(raw_dff_panel_df.columns.get_level_values('roi'))
            )
        else:
            # TODO TODO TODO commit a file that defines set of gh146 glomeruli under
            # data/ (-> use that)
            #
            # TODO TODO TODO relax to not err on new data? presumably this is what was
            # failing?
            # TODO TODO just warn instead? only do anything if we seem to be running on
            # the final megamat data?
            print('update / delete gh146 glomeruli checking code')
            #assert 0 == len(
            #    gh146_glomeruli - set(raw_dff_panel_df.columns.get_level_values('roi'))
            #)

        fly_dff_gh146_subset = raw_dff_panel_df.loc[:,
            raw_dff_panel_df.columns.get_level_values('roi').isin(gh146_glomeruli)
        ]
        mean_fly_dff_gh146_corr = mean_of_fly_corrs(fly_dff_gh146_subset)
        plot_corr(mean_fly_dff_gh146_corr, panel_plot_dir,
            'orn_dff_gh146-subset_corr',
            # TODO TODO use one of newer strs in al_analysis.py for this (-> move to
            # al_util?)? might this ever be 'Z-scored F' instead of dF/F?
            xlabel=f'ORN {dff_latex}\nGH146 glomeruli only'
        )
        plot_corr(mean_fly_dff_gh146_corr, panel_plot_dir,
            'orn_dff_gh146-subset_corr-dist',
            # TODO TODO use one of newer strs in al_analysis.py for this (-> move to
            # al_util?)? might this ever be 'Z-scored F' instead of dF/F?
            xlabel=f'ORN {dff_latex}\nGH146 glomeruli only', as_corr_dist=True
        )
        '''

        # should i also be passing each *individual fly* data thru dF/F -> est spike
        # delta fn (-> recomputing)? should i be doing that w/ all of modeling?
        # (no, Betty and i agreed it wasn't worth it for now)

        # TODO no need for copy, right?
        # TODO maybe i don't need to drop panel here?
        #
        # also, why the double transpose here? est_df used apart from for this plot?
        # (b/c usage as comparison_orns below)
        #
        # NOTE: this should currently be saved as a pickle+CSV under each model output
        # directory, at orn_deltas.[csv|p] (done by fit_and_plot...)
        est_df = panel_est_df.droplevel('panel', axis='columns').T.copy()

        # TODO TODO also plot hemibrain filled version(s) of this
        est_corr = plot_responses_and_corr(est_df.T, panel_plot_dir,
            f'est_orn_spike_deltas_{dff2spiking_choices_str}',
            # TODO maybe borrow final part from scaling_method2desc (but current strs
            # there have more info than i want)
            xlabel=('est. ORN spike deltas\n'
                # TODO TODO use one of newer strs in al_analysis.py for this (-> move to
                # al_util?)? might this ever be 'Z-scored F' instead of dF/F?
                f'{dff_latex} scaling: {scaling_method_to_use}'
            ),
        )
        del est_corr

        # TODO TODO plot responses + corrs for (est_orn_spike_deltas + sfr) and
        # (hallem_spike_deltas + sfr) too. compare to values from dynamic ORNs and
        # deltas alone. (probably do in fit_mb_model internals plotting?)
        #
        # (actually care about adding sfr? does it actually change corrs? if so, to a
        # meaningful degree?)

        # TODO or just move before loop over panels?
        if panel == 'megamat':
            hallem_megamat = hallem_delta_wide.loc[
                # get_level_values('odor') should work whether panel_est_df has 'odor'
                # as one level of a MultiIndex, or as single level of a regular Index
                panel_est_df.columns.get_level_values('odor')
            ].sort_index(axis='columns')

            # TODO label cbar w/ spike delta units
            plot_responses_and_corr(hallem_megamat.T, panel_plot_dir,
                'hallem_spike_deltas', xlabel='Hallem OR spike deltas'
            )

            # TODO TODO also NaN-fill Hallem to hemibrain, and plot those responses (if
            # i haven't already somewhere else). no need to plot corrs there, as they
            # should be same as raw hallem.

            # TODO TODO only zero fill just as in fitting tho (how is it diff? at least
            # add comment about how it's diff...)? current method also drops stuff like
            # DA3, which is in hallem but not in my data...
            # TODO TODO leave that to one of the model_internals plots in that case?
            # maybe just delete this then?
            #
            # TODO does this change correlation (yes, moderately increased)?
            # TODO plot delta corr wrt above?
            # TODO print about what the reindex is dropping (if verbose?)?
            zerofilled_hallem = hallem_megamat.reindex(panel_est_df.index,
                axis='columns').fillna(0)
            plot_responses_and_corr(zerofilled_hallem.T, panel_plot_dir,
                'hallem_spike_deltas_filled', xlabel='Hallem OR spike deltas\n'
                '(zero-filled to my consensus glomeruli)'
            )

        # TODO TODO and same thing with my raw data honestly. not sure i have that.
        # here might not be the place though (top-level ijroi stuff?)
        # TODO TODO matrix plot actually making my est spike deltas as comparable
        # as possible to the relevant subset of the hallem data (+ relevant subset of my
        # data)
        # (not here, but at least once for master version of hallem and pebbled data,
        # maybe just in megamat context)

        # TODO just use one of the previous things that was already tidy? and already
        # had hallem data?
        tidy_est = panel_est_df.droplevel('panel', axis='columns').stack()
        tidy_est.name = est_spike_delta_col
        tidy_est = tidy_est.reset_index()

        fig, ax = plt.subplots()
        # TODO TODO why did the xticks seem to change (comparing old vs new version of
        # dff_scale-to-avg-max_hist_est-spike-delta_validation2.pdf, highlighted by -C)?
        # shape of rest seems the same. something meaningful? diff input subset or
        # something?
        sns.histplot(data=tidy_est, x=est_spike_delta_col, bins=n_bins, ax=ax)
        ax.set_title(f'pebbled {panel}')
        # TODO or save in panel dir? this consistent w/ saving of hallem megamat stuff
        # above tho...
        savefig(fig, plot_dir,
            f'{dff2spiking_choices_str}__hist_est-spike-delta_{panel}'
        )
        del tidy_est

        pebbled_input_df = panel_est_df

        # TODO check outputs against those run previous way (without
        # explicitly passing inputs, when using + tuning on hallem)
        #hallem_input_df = hallem_for_comparison.T.copy()

        comparison_orns = None
        comparison_kc_corrs = None

        # TODO delete (still want this? or maybe for other panels, e.g. kiwi?)
        #if panel != 'megamat':
        #    print('GET COMPARISON_ORNS (+ COMPARISON_KCS) WORKING ON non-megamat DATA')
        #
        if panel == 'megamat':
            # TODO TODO don't i still want comparison_orns in validation case?
            # TODO TODO what about comparison_kcs in validation case? what betty
            # has said so far (re: validation modelling figures) is that we only want
            # sparsity + correlation, but not sure that'll remain true...
            comparison_orns = {
                'raw-dff': raw_dff_panel_df,

                # NOTE: this one does not have single fly data like raw_dff_panel_df
                # (it's just mean responses), so correlation computed not exactly
                # apples-to-apples with most others (but similar to how model output
                # corr computed, given model is run on mean data)
                'est-spike-delta': est_df,

                # TODO also a version zero-filling like fit_mb_model does internally
                # (happy enough w/ corr_diff plots i added in fit_mb_model?)
            }

            # TODO rename to comparison_kc_corrs or something? observed_mean_kc_corrs?
            #
            # this is a mean-of-fly-corrs (WAS for Remy's 4 final KC flies, but now
            # adapting to also load the older data too)
            comparison_kc_corrs = load_remy_megamat_mean_kc_corrs()

            # TODO replace these two lines w/ just sorting, if that works (would have to
            # add panel to both column and index, at least one manually...)
            # (name order already cluster order, in panel2name_order?)
            # (current strategy will probably no longer work w/ panel_est_df/est_df
            # having panel level...)
            assert set(est_df.index) == set(comparison_kc_corrs.index)
            comparison_kc_corrs = comparison_kc_corrs.loc[est_df.index, est_df.index
                ].copy()
            #

            # TODO also an as_corr_dist=True version of my mean ORN corrs (to finish off
            # fig 3 C)
            # TODO same for model corrs (corr.pdf under each model param dir)

            # TODO delete similar code in comparison_kc_corrs branch inside
            # fit_and_plot...
            #
            # TODO would probably need to redo diverging_cmap + vmin/vmax to work w/
            # correlation distance (this was from before i converted correlations to
            # correlation distances. could also move this before converting above...)
            # TODO or convert back to correlations, if currently as distances
            plot_corr(comparison_kc_corrs, panel_plot_dir, 'remy_kc_corr',
                xlabel='observed KCs'
            )
            plot_corr(comparison_kc_corrs, panel_plot_dir, 'remy_kc_corr-dist',
                xlabel='observed KCs', as_corr_dist=True
            )
            # TODO make corr diff plots wrt orn inputs
            # (probably just the raw dF/F, or maybe also the transformed stuff before
            # fitting?)
            # TODO compare uniform - hemibrain corr to experimental correlation change
            # from ORNs->KCs?
            # TODO load responses.[p|csv] from each dir -> compute corrs -> diff from
            # there (might just make a separate script for that...)?

            assert set(comparison_kc_corrs.index) == set(
                raw_dff_panel_df.index.get_level_values('odor1')
            )
            mean_orn_corrs = mean_of_fly_corrs(raw_dff_panel_df, square=False)
            mean_kc_corrs = corr_triangular(comparison_kc_corrs)

            assert mean_kc_corrs.index.equals(mean_orn_corrs.index)

            orn_col = 'mean_orn_corr'
            kc_col = 'mean_kc_corr'
            mean_orn_corrs.name = orn_col
            mean_kc_corrs.name = kc_col

            merged_corrs = pd.concat([mean_orn_corrs, mean_kc_corrs], axis='columns')

            # TODO TODO refactor to share w/ where i copied from
            fig, ax = plt.subplots()
            add_unity_line(ax)
            lineplot_kws = dict(
                ax=ax, data=merged_corrs, x=orn_col, y=kc_col, linestyle='None',
                color='black'
            )
            marker_only_kws = dict(
                markers=True, marker='o', errorbar=None,

                # seems to default to white otherwise
                markeredgecolor='black',

                markerfacecolor='None',
                alpha=0.175,
            )
            # plot points
            sns.lineplot(**lineplot_kws, **marker_only_kws)

            metric_name = 'correlation'
            # TODO TODO use one of newer strs in al_analysis.py for this (-> move to
            # al_util?)? might this ever be 'Z-scored F' instead of dF/F?
            ax.set_xlabel(f'{metric_name} of raw ORN {dff_latex} (observed)')
            ax.set_ylabel(f'{metric_name} of KCs (observed)')

            metric_max = max(merged_corrs[kc_col].max(), merged_corrs[orn_col].max())
            metric_min = min(merged_corrs[kc_col].min(), merged_corrs[orn_col].min())

            plot_max = 1
            plot_min = -.5
            assert metric_max <= plot_max, f'{metric_max=} > {plot_max=}'
            assert metric_min >= plot_min, f'{metric_min=} < {plot_min=}'

            ax.set_xlim([plot_min, plot_max])
            ax.set_ylim([plot_min, plot_max])

            # should give us an Axes that is of square size in figure coordinates
            ax.set_box_aspect(1)

            spear_text, _, _, _, _ = bootstrapped_corr(merged_corrs, kc_col, orn_col,
                method='spearman',
                # TODO delete (for debugging)
                _plot_dir=panel_plot_dir
            )
            ax.set_title(spear_text)

            # TODO also include errorbars along both x and y here? (across flies whose
            # correlations went into mean corr)

            savefig(fig, panel_plot_dir, 'remy-kc_vs_orn-raw-dff_corrs')
            # (end part to refactor to share w/ copied code)

        # TODO TODO TODO remove all non-used kiwi/control odors before tuning (e.g.
        # binary mixes, solvent, etc)?

        # TODO add assertion below that there are no dupes in this list (exclude things
        # that don't actually affect model outputs)
        model_kw_list = [
            # TODO delete?
            # TODO TODO TODO or restore, replacing multiresponder_APL_boost w/ something
            # similar for other classes of KCs (e.g. based on # of inputs from
            # "community" PNs or # of inputs in core/periphery)
            #
            dict(
                orn_deltas=pebbled_input_df,
                tune_on_hallem=False,
                pn2kc_connections='hemibrain',
                weight_divisor=20,

                use_connectome_APL_weights=True,

                # TODO TODO TODO remove this? (at least for first element of this list,
                # which is the one that will be run w/ -M)
                equalize_kc_type_sparsity=True,

                # TODO TODO need to do as a second call w/ fixed_thr=<vector>
                # (since assertions tripping if only this passed, and may be hard to
                # fix?) (may also need to not do in equalize_kc_type_sparsity=True...)
                # (moving that second call into fit_mb_model now)
                #wAPLKC=4.83,

                # TODO TODO try this boost without equalize_kc_type_sparsity=True?
                multiresponder_APL_boost=10.0,
                #multiresponder_APL_boost=3.0,
                # TODO TODO rename to something more generic, like APL_boost
                # (and _multiresponder_mask to _APL_boost_mask or something)
                #multiresponder_APL_boost=20.0,

                # TODO TODO TODO add other kwargs to control whether wKCAPL
                # also/exclusively gets boosted
                # TODO option to boost this by a different factor? how to choose tho?
                boost_wKCAPL=True,
                # TODO delete
                #boost_wKCAPL='only',

                sensitivity_analysis=True,
                # TODO refactor to use common megamat sens kws by default (share w/
                # below)?
                sens_analysis_kws=dict(
                    n_steps=3,
                    fixed_thr_param_lim_factor=0.5,
                    wAPLKC_param_lim_factor=5.0,
                    drop_nonpositive_fixed_thr=True,
                    drop_negative_wAPLKC=True,
                ),

                comparison_orns=comparison_orns,
                comparison_kc_corrs=comparison_kc_corrs,
            ),
            #

            dict(
                orn_deltas=pebbled_input_df,
                tune_on_hallem=False,
                pn2kc_connections='hemibrain',
                weight_divisor=20,

                use_connectome_APL_weights=True,

                # TODO TODO TODO remove this? (at least for first element of this list,
                # which is the one that will be run w/ -M)
                equalize_kc_type_sparsity=True,

                sensitivity_analysis=True,
                # TODO refactor to use common megamat sens kws by default (share w/
                # below)?
                sens_analysis_kws=dict(
                    n_steps=3,
                    fixed_thr_param_lim_factor=0.5,
                    wAPLKC_param_lim_factor=5.0,
                    drop_nonpositive_fixed_thr=True,
                    drop_negative_wAPLKC=True,
                ),

                comparison_orns=comparison_orns,
                comparison_kc_corrs=comparison_kc_corrs,
            ),
            dict(
                orn_deltas=pebbled_input_df,
                tune_on_hallem=False,
                pn2kc_connections='hemibrain',
                weight_divisor=20,

                use_connectome_APL_weights=True,
                equalize_kc_type_sparsity=True,
                ab_prime_response_rate_target=0.15,
                # TODO delete
                #ab_prime_response_rate_target=0.2,

                sensitivity_analysis=True,
                # TODO refactor to use common megamat sens kws by default (share w/
                # below)?
                sens_analysis_kws=dict(
                    n_steps=3,
                    fixed_thr_param_lim_factor=0.5,
                    wAPLKC_param_lim_factor=5.0,
                    drop_nonpositive_fixed_thr=True,
                    drop_negative_wAPLKC=True,
                ),

                comparison_orns=comparison_orns,
                comparison_kc_corrs=comparison_kc_corrs,
            ),

            dict(
                orn_deltas=pebbled_input_df,
                tune_on_hallem=False,
                pn2kc_connections='hemibrain',
                weight_divisor=20,

                equalize_kc_type_sparsity=True,

                sensitivity_analysis=True,
                # TODO refactor to use common megamat sens kws by default (share w/
                # below)?
                sens_analysis_kws=dict(
                    n_steps=3,
                    fixed_thr_param_lim_factor=0.5,
                    wAPLKC_param_lim_factor=5.0,
                    drop_nonpositive_fixed_thr=True,
                    drop_negative_wAPLKC=True,
                ),

                comparison_orns=comparison_orns,
                comparison_kc_corrs=comparison_kc_corrs,
            ),
            dict(
                orn_deltas=pebbled_input_df,
                tune_on_hallem=False,
                pn2kc_connections='hemibrain',
                weight_divisor=20,

                equalize_kc_type_sparsity=True,
                ab_prime_response_rate_target=0.15,
                # TODO delete
                #ab_prime_response_rate_target=0.2,

                sensitivity_analysis=True,
                # TODO refactor to use common megamat sens kws by default (share w/
                # below)?
                sens_analysis_kws=dict(
                    n_steps=3,
                    fixed_thr_param_lim_factor=0.5,
                    wAPLKC_param_lim_factor=5.0,
                    drop_nonpositive_fixed_thr=True,
                    drop_negative_wAPLKC=True,
                ),

                comparison_orns=comparison_orns,
                comparison_kc_corrs=comparison_kc_corrs,
            ),

            dict(
                orn_deltas=pebbled_input_df,
                tune_on_hallem=False,
                pn2kc_connections='hemibrain',
                weight_divisor=20,

                # TODO TODO restore when analyzing remy-paper data (when panel is
                # megamat/validation2, maybe also checking date range)
                #
                # also including for new weight_divisor=20 entry, just so that i don't
                # have to resend remy new uniform/hemidraw outputs, or update those
                # plots. if i were to start over again, i would still leave this at
                # default True.
                #_drop_glom_with_plus=False,

                use_connectome_APL_weights=True,

                sensitivity_analysis=True,
                sens_analysis_kws=dict(
                    n_steps=3,
                    fixed_thr_param_lim_factor=0.5,
                    wAPLKC_param_lim_factor=5.0,
                    drop_nonpositive_fixed_thr=True,
                    drop_negative_wAPLKC=True,
                ),

                comparison_orns=comparison_orns,
                comparison_kc_corrs=comparison_kc_corrs,
            ),

            # TODO why is DA4m in in these but not in regular hallem input call in
            # separate list below? conform preprocessing to match (+ sort glomeruli in
            # all those internal plots?)

            # weight_divisor=10,5 (and probably 2) didn't improve things, in terms of
            # either obvious impression of correlation (vs real KC corrs) or spearman's
            # corr between them
            #
            # same as in main hemibrain call (w/o weight_divisor), but now increasing
            # wPNKC values in proportion to connectome weight, rather than just counting
            # each unique PN with weight >=4.
            dict(
                orn_deltas=pebbled_input_df,
                tune_on_hallem=False,
                pn2kc_connections='hemibrain',
                weight_divisor=20,

                # TODO TODO restore when analyzing remy-paper data (when panel is
                # megamat/validation2, maybe also checking date range)
                #
                # also including for new weight_divisor=20 entry, just so that i don't
                # have to resend remy new uniform/hemidraw outputs, or update those
                # plots. if i were to start over again, i would still leave this at
                # default True.
                #_drop_glom_with_plus=False,

                # TODO like these steps (in this new context, w/ weight_divisor=20)?
                sensitivity_analysis=True,
                sens_analysis_kws=dict(
                    n_steps=3,
                    fixed_thr_param_lim_factor=0.5,
                    wAPLKC_param_lim_factor=5.0,
                    # TODO TODO why not keeping 0? that not work? actually matter (what
                    # happened?)?
                    drop_nonpositive_fixed_thr=True,
                    drop_negative_wAPLKC=True,
                ),

                comparison_orns=comparison_orns,
                comparison_kc_corrs=comparison_kc_corrs,
            ),

            # would need to uncomment this (and comment other hemibrain entry) to
            # reproduce preprint/paper plots that predated weight_divisor code.
            # initial submission (>= March 2025) should use weight_divisor
            # hemibrain version.
            #dict(
            #    orn_deltas=pebbled_input_df,

            #    tune_on_hallem=False,
            #    pn2kc_connections='hemibrain',

            #    # required to restore the 7 extra no-connection KCs that would be
            #    # dropped with new default behavior here, which slightly but
            #    # mostly-inconsequentially changed old hemibrain model resposnses.
            #    # not planning to use for newer call using weight_divisor=20, whose
            #    # outputs should replace those from these call in the paper.
            #    # the cells are those w/ bodyid: [519206240, 861280857, 943118619,
            #    # 1172713521, 1203779116, 5812979314, 5813081175]
            #    _drop_glom_with_plus=False,

            #    sensitivity_analysis=True,
            #    sens_analysis_kws=dict(
            #        n_steps=3,
            #        fixed_thr_param_lim_factor=0.5,
            #        wAPLKC_param_lim_factor=5.0,
            #        drop_nonpositive_fixed_thr=True,
            #        drop_negative_wAPLKC=True,
            #    ),

            #    comparison_orns=comparison_orns,
            #    comparison_kc_corrs=comparison_kc_corrs,
            #),

            # TODO restore?
            ## TODO TODO this actually make sense to try (w/ tune_on_hallem=True
            ## and drop_receptors_not_in_hallem=False?) does my code even support
            ## currently?
            ##dict(orn_deltas=pebbled_input_df, tune_on_hallem=True,
            ##    pn2kc_connections='hemibrain'
            ##),

            #dict(orn_deltas=pebbled_input_df, tune_on_hallem=True,
            #    drop_receptors_not_in_hallem=True,
            #    pn2kc_connections='hemibrain'
            #),

            #dict(orn_deltas=pebbled_input_df, tune_on_hallem=False,
            #    drop_receptors_not_in_hallem=True,
            #    pn2kc_connections='hemibrain'
            #),

            # NOTE: uniform/hemibrain models currently use # of KCs from hemibrain
            # connectome (1837 if _drop_glom_with_plus=False [= old behavior], or 1830
            # otherwise). model would default to 2000 otherwise. fafb data more cells
            # (2482 in left, probably similar in right).
            dict(
                orn_deltas=pebbled_input_df,
                tune_on_hallem=False,
                pn2kc_connections='uniform', n_claws=7, n_seeds=N_SEEDS,

                # TODO TODO restore when analyzing remy-paper data (when panel is
                # megamat/validation2, maybe also checking date range)
                #
                # NOTE: also need _drop_glom_with_plus=False for this and hemidraw,
                # to reproduce previous outputs (probably just b/c hemibrain KC number
                # is reduced by 7 if this is True, so these models use less cells?)
                #_drop_glom_with_plus=False,

                comparison_orns=comparison_orns,
                comparison_kc_corrs=comparison_kc_corrs,
            ),

            # TODO delete? also try n_claws=5,6 for hemidraw?
            # since mean # connections is 5.44 in connectome='hemibrain' case [and
            # probably similar for fafb inputs]). prob just b/c matt had settled on it,
            # we had been using n_claws=7 for most things.
            # dict(
            #     orn_deltas=pebbled_input_df,
            #     tune_on_hallem=False,
            #     pn2kc_connections='uniform', n_claws=6, n_seeds=N_SEEDS,
            #     comparison_orns=comparison_orns,
            #     comparison_kc_corrs=comparison_kc_corrs,
            # ),
            # dict(
            #     orn_deltas=pebbled_input_df,
            #     tune_on_hallem=False,
            #     pn2kc_connections='uniform', n_claws=5, n_seeds=N_SEEDS,
            #     comparison_orns=comparison_orns,
            #     comparison_kc_corrs=comparison_kc_corrs,
            # ),
            # TODO try hemidraw updated to use weight_divisor hemibrain wPNKC?
            #dict(
            #    orn_deltas=pebbled_input_df,
            #    tune_on_hallem=False,
            #    pn2kc_connections='hemidraw', n_claws=7, n_seeds=N_SEEDS,
            #    # NOTE: also need _drop_glom_with_plus=False for this and hemidraw,
            #    # to reproduce previous outputs (probably just b/c hemibrain KC number
            #    # is reduced by 7 if this is True, so these models use less cells?)
            #    _drop_glom_with_plus=False,
            #    comparison_orns=comparison_orns,
            #    comparison_kc_corrs=comparison_kc_corrs,
            #),

            # TODO TODO TODO version like hemidraw, but by pre-generating wPNKC, to have
            # similar distribution to below (but otherwise keeping draws of each input
            # indep). possible? (should be...). try just taking each cell in real
            # connectome, taking # of connections from that cell, then drawing from
            # whatever distribution up to that number of connections? (in contrast to
            # current hemidraw/uniform cases which both have a fixed number of
            # connections [called "claws" in modelling code, not synapses, but maybe
            # assumed to be somewhat interchangeable?] per model KC)

            # TODO TODO maybe try a version of model where we use connectome weights for
            # either APL->KC or KC->APL, and then we [try to] scale one/both of them
            # up/down to achieve target sparsity? (would have to modify model code
            # somewhat)

            ## TODO TODO this actually make sense to try (w/ tune_on_hallem=True and
            ## drop_receptors_not_in_hallem=False?) does my code even support
            ## currently?
            ##dict(orn_deltas=pebbled_input_df, tune_on_hallem=True,
            ##    pn2kc_connections='uniform', n_claws=7, n_seeds=N_SEEDS
            ##),

            # TODO delete?
            #dict(
            #    orn_deltas=pebbled_input_df,
            #    tune_on_hallem=False,
            #    pn2kc_connections='fafb-left',

            #    # didn't help, unlike in hemibrain case
            #    # NOTE: seems like somewhere around 12-13 will produce similar value for
            #    # avg # of synapses per model KC (as in hemibrain w/ weight_divisor=20:
            #    # ~7.36). despite matching this one value, spearman-of-pearsons [model
            #    # vs real KCs] is still just as bad, or even slightly worse, with
            #    # weight_divisor=12 (compared to both weight_divisor=None|20)
            #    weight_divisor=12,

            #    comparison_orns=comparison_orns,
            #    comparison_kc_corrs=comparison_kc_corrs,
            #),
            #dict(
            #    orn_deltas=pebbled_input_df,
            #    tune_on_hallem=False,
            #    pn2kc_connections='fafb-right',

            #    # didn't help. see comment for fafb-left above.
            #    #weight_divisor=12,

            #    comparison_orns=comparison_orns,
            #    comparison_kc_corrs=comparison_kc_corrs,
            #),
        ]
        if panel == 'megamat':
            # TODO TODO make sure that my derived wPNKC from pratyush's data
            # actually has KCs getting at least some input from all the PN types i have
            # in wPNKC PN labels (and that i'm not subsetting down to "halfmat"
            # unnecessarily, from earlier comparisons to matt's stuff, or whatever)
            # TODO TODO could probably just compare outputs of hallem model w/ and
            # w/o _use_matt_wPNKC...
            # TODO TODO can pass hallem data in explicitly if that makes it
            # easier to get things handled exactly the same

            # NOTE: model responses (including cache) should only include these odors.
            # could `-i model` if wanted to change and regen cache.
            sim_odors = sorted(hallem_for_comparison.index)
            # TODO make work again. need to make corr diff plot for all odors, w/
            # megamat ones pulled out. this seemed the easiest way...
            #sim_odors = None

            # parameter combinations to recreate preprint figures, using same Hallem
            # data as input (that Matt did when making those figures, before we had our
            # own ORN outputs)
            preprint_repro_model_kw_list = [
                dict(pn2kc_connections='hemibrain',

                    # TODO TODO delete/comment
                    # need to fix breakpoint hit in fit_mb_model (currently just
                    # commented it...)
                    _use_matt_wPNKC=True,

                    sim_odors=sim_odors,

                    comparison_orns=hallem_for_comparison,
                    comparison_kc_corrs=comparison_kc_corrs,

                    # TODO TODO don't require this passed in! (do unconditionally)
                    _strip_concs_comparison_kc_corrs=True,
                ),

                dict(pn2kc_connections='uniform', n_claws=7,

                    # TODO TODO TODO delete/comment
                    # need to fix breakpoint hit in fit_mb_model
                    _use_matt_wPNKC=True,

                    # TODO probably also _add_back_methanoic_acid_mistake=True?
                    # shouldn't matter...
                    #_add_back_methanoic_acid_mistake=True,

                    n_seeds=N_SEEDS,

                    sim_odors=sim_odors,

                    comparison_orns=hallem_for_comparison,
                    comparison_kc_corrs=comparison_kc_corrs,

                    # TODO TODO don't require this passed in! (do unconditionally)
                    #
                    # since outputs of model will have ' @ -2' when using Hallem input,
                    # but KC comparison data has ' @ -3'. this will strip conc from all
                    # odor strings, when comparing data from these variables.
                    # NOTE: comparison_orns path currently strips unconditionally...
                    _strip_concs_comparison_kc_corrs=True,
                ),
                dict(pn2kc_connections='hemidraw', n_claws=7,
                    _use_matt_wPNKC=True,
                    n_seeds=N_SEEDS,
                    sim_odors=sim_odors,
                    comparison_orns=hallem_for_comparison,
                    comparison_kc_corrs=comparison_kc_corrs,
                    _strip_concs_comparison_kc_corrs=True,
                ),
            ]
            if not skip_hallem_models:
                # all entries in preprint_repro_model_kw_list use hallem data, and all
                # entries in model_kw_list (before line below) should not use hallem
                # data
                model_kw_list = model_kw_list + preprint_repro_model_kw_list
            else:
                warn('skipping all models using Hallem data (rather than our measured '
                    'ORN data) as input (because `-s model-hallem` CLI option)'
                )

        # hack to skip long running models, if I want to test something on pebbled and
        # hallem cases w/o re-running many seeds before getting an answer on the test.
        if skip_models_with_seeds:
            old_len = len(model_kw_list)
            model_kw_list = [x for x in model_kw_list if 'n_seeds' not in x]

            n_skipped = old_len - len(model_kw_list)
            warn(f'currently skipping {n_skipped} models with seeds! (because '
                '`-s model-seeds` CLI option)'
            )

        for model_kws in model_kw_list:
            if panel not in ('kiwi', 'control'):
                _target_sparsities = target_sparsities
            else:
                # TODO TODO TODO also set _drop_glom_with_plus=False here, and True
                # above (or only True for megamat/validation2/glomeruli_diagnostics?)
                #
                # TODO replace w/ special casing megamat/validation2 instead
                warn('since panel was kiwi/control, using default 0.1 target sparsity')
                _target_sparsities = (0.1,)

            for target_sparsity in _target_sparsities:
                _model_kws = dict(model_kws)
                _model_kws['target_sparsity'] = target_sparsity

                if panel == 'megamat':
                    _model_kws['repro_preprint_s1d'] = True

                do_sensitivity_analysis = False
                if model_kws.get('sensitivity_analysis', False):
                    do_sensitivity_analysis = True

                if skip_sensitivity_analysis or not do_sensitivity_analysis:
                    try:
                        # assumes the default is False. could also set False explicitly,
                        # but not passing that in explicitly for other model_kws
                        # iterated over.
                        del _model_kws['sensitivity_analysis']
                    except KeyError:
                        pass

                else:
                    # TODO TODO also skip anything other than 1 or 2 hemibrain calls for
                    # these panels? move calls to natmix_data/analysis.py itself?
                    if panel in ('kiwi', 'control'):
                        # TODO also check whether sensitivity_analysis=True? or
                        # sens_analysis_kws just ignored anyway, if it's False(/which i
                        # assume is default?)?
                        #
                        # these values were for trying to find better combinations for
                        # use on newer kiwi/control data (for analysis in
                        # natmix_data/analysis.py). not 100% happy with outputs yet.
                        natmix_sens_analysis_kws = dict(
                            n_steps=7,
                            fixed_thr_param_lim_factor=0.75,

                            # TODO just leave these last 3 at default (that's what these
                            # values are)?
                            wAPLKC_param_lim_factor=5.0,
                            drop_nonpositive_fixed_thr=True,
                            drop_negative_wAPLKC=True,
                        )
                        warn('using diff sens_analysis_kws for kiwi/control panels:\n' +
                            pformat(natmix_sens_analysis_kws)
                        )
                        _model_kws['sens_analysis_kws'] = natmix_sens_analysis_kws

                # used to have this like 'dff_scale-<scaling-method>', for pebbled
                # input, but didn't like how it cluttered up dir names (since almost all
                # of them have this part of their name, and I only ever scale my pebbled
                # data one way these days, so it was always 'dff_scale-to-avg-max__')
                param_dir_prefix = ''

                # TODO (delete?) is this loop working as expected? in run on
                # kiwi+control data, i feel like i've seen more progress bars than i
                # expected...
                # (should be 2 * 3, no? i.e. {hemidraw, uniform} X {control-kiwi,
                # control, kiwi}?) none of the duplicate-save-within-run detection
                # seemed to trip tho...

                fixed_thr = None
                wAPLKC = None
                _extra_params = dict(extra_params)

                # checking for orn_deltas because we don't want to ever do this
                # pre-tuning for hallem data (where the ORN data isn't passed here, but
                # loaded inside fit_mb_model)
                if 'orn_deltas' in model_kws and panel in panel2tuning_panels:

                    tuning_panels = panel2tuning_panels[panel]
                    tuning_panels_str = tuning_panel_delim.join(tuning_panels)

                    tuning_panels_plot_dir = plot_dir / tuning_panels_str
                    makedirs(tuning_panels_plot_dir)

                    panel_mask = mean_est_df.columns.get_level_values('panel'
                        ).isin(tuning_panels)

                    if panel_mask.sum() == 0:
                        raise RuntimeError(f'no data from {tuning_panels=}!\n\nedit '
                            'panel2tuning_panels if you do not intended to tune '
                            f'{panel=} data on these panels.\n\nyou may also just need '
                            'to change script CLI args to include this data.'
                        )

                    tuning_df = mean_est_df.loc[:, panel_mask]

                    tuning_model_kws = {k: v for k, v in _model_kws.items()
                        # TODO TODO TODO need to add any of the multiresponder APL boost
                        # stuff here?
                        if k not in (
                            'orn_deltas', 'comparison_kc_corrs', 'comparison_orns',

                            # NOTE: would need to move these APL boost params out of
                            # here, if I were to move boosting to pre-tuning
                            'multiresponder_APL_boost', '_multiresponder_mask',
                            'boost_wKCAPL',
                        )
                    }

                    # NOTE: if i wanted to do this pre-tuning on hallem data (which is
                    # loaded in fit_mb_model if orn_deltas not passed here), i'd need to
                    # not pass this. no real need to use this on hallem data tho.
                    #
                    # TODO (delete) need to drop panel level on tuning_df first
                    # (doesn't seem so...)? (if so, prob also want to prefix panel
                    # to odor names, or otherwise ensure no dupes?)
                    tuning_model_kws['orn_deltas'] = tuning_df

                    param_dict = fit_and_plot_mb_model(tuning_panels_plot_dir,
                        extra_params=extra_params,

                        # NOTE: this is intended to prevent any sensitivity analysis
                        # recursive calls from running, and also skips most/all plotting
                        # TODO still plot clustering (of spike_counts) across both
                        # panels, to get a sense of overlap in multi-responders across
                        # the two (if we want to tune APL within them, which would then
                        # affect both panels, if we were to do it here)
                        _only_return_params=True,

                        **tuning_model_kws
                    )
                    _write_inputs_for_reproducibility(tuning_panels_plot_dir,
                        param_dict
                    )

                    fixed_thr = param_dict['fixed_thr']

                    if model_kws.get('use_connectome_APL_weights', False):
                        assert 'wAPLKC' not in param_dict
                        wAPLKC = param_dict['wAPLKC_scale']
                    else:
                        assert 'wAPLKC_scale' not in param_dict
                        wAPLKC = param_dict['wAPLKC']

                    equalize_kc_type_sparsity = model_kws.get(
                        'equalize_kc_type_sparsity', False
                    )
                    if equalize_kc_type_sparsity:
                        # TODO TODO fixed_thr should be array now. just pass that
                        # directly instead of below? (wrote below when i was returning
                        # fixed_thr=None)

                        # TODO union [some of] this param_dict into one below? (e.g. for
                        # type2thr)

                        # this must be in param_dict if equalize_kc_type_sparsity=True
                        type2thr = param_dict['type2thr']

                        tuning_output_dir = (
                            tuning_panels_plot_dir / param_dict['output_dir']
                        )
                        # TODO assert this has been written since run start?
                        #
                        # using this to get the kc type for each cell (nothing in
                        # param_dict has it, and vector things in there tend to screw up
                        # some outputs, as currently implemented [e.g. the CSVs
                        # summarizing parameters for different runs])
                        wPNKC = pd.read_pickle(tuning_output_dir / 'wPNKC.p')
 
                        # TODO (delete/) refactor this part to share w/
                        # test_fixed_inh_params2 (copied this there)?
                        kc_types = wPNKC.index.get_level_values(KC_TYPE)
                        assert not kc_types.isna().any()
                        assert set(kc_types) == set(type2thr.keys())
                        cell_thrs = kc_types.map(type2thr)
                        fixed_thr = cell_thrs.values.copy()

                        del kc_types, cell_thrs, type2thr, wPNKC

                        # TODO replace recomputed fixed_thr w/ one from param_dict
                        # (-> delete code to recompute)
                        assert np.array_equal(fixed_thr, param_dict['fixed_thr'])
                    else:
                        assert 'type2thr' not in param_dict

                    assert fixed_thr is not None
                    assert wAPLKC is not None

                    # TODO share 'hemibrain' default w/ two other places this defined
                    pn2kc_connections = model_kws.get('pn2kc_connections', 'hemibrain')
                    if pn2kc_connections not in connectome_options:
                        # should be one list element per seed.
                        # all elements should be float (shouldn't need to support vector
                        # fixed_thr there).
                        assert type(fixed_thr) is list and type(wAPLKC) is list
                        assert len(fixed_thr) == len(wAPLKC)

                        # NOTE: currently relying on the pre-tuning + actual modelling
                        # calls using the same sequences of seeds (which they do, b/c
                        # initial seed currently hardcoded, and i always increment
                        # following seeds by one from there), so that applying the
                        # sequence of inh params across the two makes sense

                    _model_kws['title_prefix'] = f'tuning panels: {tuning_panels_str}\n'

                    _extra_params['tuning_panels'] = tuning_panels_str
                    _extra_params['tuning_output_dir'] = param_dict['output_dir']

                    tuning_param_str = ''

                    target_sp = _model_kws.get('target_sparsity')
                    del _model_kws['target_sparsity']
                    if target_sparsity is not None:
                        # TODO skip if it's some default value (0.1?)?
                        # TODO refactor formatting?
                        tuning_param_str += f'_target-sp_{target_sp:.3g}'

                    target_sparsity_factor_pre_APL = _model_kws.get(
                        'target_sparsity_factor_pre_APL'
                    )
                    if target_sparsity_factor_pre_APL is not None:
                        tuning_param_str += (
                            '_target-sp-factor-pre-APL_'
                            f'{target_sparsity_factor_pre_APL:.1f}'
                        )

                    homeostatic_thrs = model_kws.get('homeostatic_thrs', False)
                    if homeostatic_thrs:
                        tuning_param_str += '_hstatic-thrs_True'
                        del _model_kws['homeostatic_thrs']
                        # TODO also assert fixed_thr is a vector that varies across the
                        # cells?

                    if equalize_kc_type_sparsity:
                        tuning_param_str += '_equalize-types_True'

                        # need to remove equalize_kc_type_sparsity=True from calls below
                        # (w/ fixed fixed_thr and wAPLKC), since it operates by tuning
                        # threshold within each KC type (which we already did above.
                        # wouldn't make sense to do again).
                        del _model_kws['equalize_kc_type_sparsity']

                        ab_prime_response_rate_target = _model_kws.get(
                            'ab_prime_response_rate_target'
                        )
                        if ab_prime_response_rate_target is not None:
                            tuning_param_str += (
                                f'_ab-prime_{ab_prime_response_rate_target:.3g}'
                            )
                            # same reason we are removing this one. it's only used
                            # inside the equalize_kc_type_sparsity=True path.
                            del _model_kws['ab_prime_response_rate_target']

                    del equalize_kc_type_sparsity

                    # TODO any other params that influence tuning?

                    tuning_prefix = f'tuned-on_{tuning_panels_str}{tuning_param_str}__'
                    param_dir_prefix = f'{tuning_prefix}{param_dir_prefix}'

                # TODO TODO add comment about how large we should expect these outputs
                # to be + maybe switch back off by default (add CLI arg for this?
                # [default?] skip option?)
                #save_dynamics = True
                save_dynamics = False
                if save_dynamics:
                    _model_kws['return_dynamics'] = True

                params_for_csv = fit_and_plot_mb_model(panel_plot_dir,
                    param_dir_prefix=param_dir_prefix, extra_params=_extra_params,
                    fixed_thr=fixed_thr, wAPLKC=wAPLKC, **_model_kws
                )
                _write_inputs_for_reproducibility(panel_plot_dir, params_for_csv)

                # should only be the case if first_seed_only=True inside fit_and_plot...
                # (just used to regen model internal plots, which are made on first seed
                # for multi-seed runs. no downstream plots/caches are updated by
                # fit_and_plot... in that case).
                if params_for_csv is None:
                    continue

                if skip_models_with_seeds:
                    warn(f'not writing to {model_param_csv} (b/c '
                        'skip_models_with_seeds=True)!'
                    )
                    continue

                # should only be added if wAPLKC/fixed_thr passed, which should not
                # be the case in any of these calls
                assert 'pearson' not in params_for_csv

                if model_params is None:
                    model_params = pd.Series(params_for_csv).to_frame().T
                else:
                    # works (adding NaN) in both cases where appended row has
                    # more/less columns than existing data.
                    model_params = model_params.append(params_for_csv,
                        ignore_index=True
                    )

                # just doing in loop so if i interrupt early i still get this. don't
                # think i mind always overwritting this from past runs.
                #
                # NOTE: can't use wrapper here b/c it asserts output wasn't already
                # saved this run.
                model_params.to_csv(model_param_csv, index=False)

            if first_model_kws_only:
                warn('breaking after first model_kw_list entry, because '
                    f'{first_model_kws_only=}!'
                )
                break

        if skip_models_with_seeds:
            warn('not making across-model plots (S1C/2E) (b/c '
                'skip_models_with_seeds=True)!'
            )
            continue

        # TODO TODO how much of stuff below should i factor out of model_mb_responses
        # (into something al_analysis calls after model_mb_responses is done. would
        # probably want to return something from this fn)?

        if panel != 'megamat':
            # TODO (at least if verbose) warn we warn we are skipping rest?
            continue

        # NOTE: special casing handling of this plot. other plots dealing with errorbars
        # across seeds will NOT subset seeds to first 20 (using global
        # `n_first_seeds_for_errorbar = None` instead)
        fig2e_n_first_seeds = 20
        _, fig2e_seed_err_fname_suffix = _get_seed_err_text_and_fname_suffix(
            n_first_seeds=fig2e_n_first_seeds
        )

        remy_2e_corrs = load_remy_2e_corrs(panel_plot_dir)

        # don't actually care about output data here, but it will save extra a plot
        # showing we can recreate the preprint fig 2E when use_preprint_data=True
        load_remy_2e_corrs(panel_plot_dir, use_preprint_data=True)

        # should already be sorted by mean-pair-correlation in load_remy_2e_corrs,
        # with all entries of each pair grouped together
        remy_2e_pair_order = remy_2e_corrs.odor_pair_str.unique()

        remy_2e_odors = (
            set(remy_2e_corrs.abbrev_row) | set(remy_2e_corrs.abbrev_col)
        )

        remy_pairs = set(list(zip(
            remy_2e_corrs.abbrev_row, remy_2e_corrs.abbrev_col
        )))


        # TODO refactor to share w/ load fn? delete in one or the other?
        pal = sns.color_palette()
        # green: hemibrain, orange: uniform, blue: hemidraw, black: observed
        label2color = {
            # green (but not 'green' exactly)
            'hemibrain': pal[2],
            # orange (but not 'orange' exactly)
            'uniform': pal[0],
            # blue (but not 'blue' exactly)
            'hemidraw': pal[1],
        }
        #

        # TODO try to make error bars only shown outside hollow circles?

        assert not model_params.output_dir.duplicated().any()

        # (fails if first_seed_only=True in fit_and_plot..., but that's only for
        # manual regeneration of fit_mb_model's model_internals/ plots, and should
        # never stay True)
        assert len(model_kw_list) == len(model_params)
        pebbled_mask = np.array(
            [x.get('orn_deltas') is pebbled_input_df for x in model_kw_list]
        )

        pn2kc_order = [
            'hemidraw',
            'uniform',
            'hemibrain',
        ]
        def _sort_pn2kc(x):
            if x in pn2kc_order:
                return pn2kc_order.index(x)
            else:
                return float('inf')

        # TODO i assume these are all in hallem?
        # NOTE: none of these are in Remy's validation2 panel (so I don't have them
        # in any of my pebbled data, as they also aren't in megamat, which is the
        # only other panel of hers I collected)
        #
        # ones not in megamat 17:
        # - 1-penten-3-ol
        # - delta-decalactone
        # - ethyl cinnamate
        # - eugenol
        # - gamma-hexalactone
        # - methyl octanoate
        # - propyl acetate

        # intentionally not dropping any silent/bad cells here. always want all
        # cells included for these type of plots.
        remy_binary_responses = load_remy_megamat_kc_binary_responses()

        # TODO comment explaining what all is done in this loop (/ below)?
        for desc, mask in (('pebbled', pebbled_mask), ('hallem', ~ pebbled_mask)):

            if mask.sum() == 0:
                warn(f'no {desc} data in current model runs. skipping 2E/S1C/etc!')
                continue

            # one row per model run
            curr_model_params = model_params.loc[mask]

            curr_model_params = curr_model_params.sort_values('pn2kc_connections',
                kind='stable', key=lambda x: x.map(_sort_pn2kc)
            )

            try:
                # TODO just drop_duplicates to keep first row for each, and warn we are
                # doing that instead?
                #
                # since we'll use this for line labels (e.g. 'hemibrain', 'uniform')
                assert not curr_model_params.pn2kc_connections.duplicated().any()
            except AssertionError:
                warn(f'duplicate pn2kc_connections values across {desc} models! '
                    'skipping 2E/S1C/etc!\n\ncomment/remove model_kw_list values to '
                    'remove these duplicates, to generate skipped plots.'
                )
                continue

            # e.g. 'hemibrain' -> DataFrame (Series?) with hemibrain model correlations
            pn_kc_cxn2model_corrs = dict()

            # inside the loop, we also make another version that only shows the KC data
            # that also has model data
            remy_2e_facetgrid = _create_2e_plot_with_obs_kc_corrs(remy_2e_corrs,
                remy_2e_pair_order, fill_markers=False
            )

            s1c_fig, s1c_ax = plt.subplots()

            first_model_pairs = None
            remy_2e_modelsubset_facetgrid = None

            # TODO comment explaining what all is done in this loop (/ below)?
            for i, row in enumerate(curr_model_params.itertuples()):
                output_dirname = row.output_dir
                output_dir = panel_plot_dir / output_dirname
                responses_cache = output_dir / model_responses_cache_name
                responses = pd.read_pickle(responses_cache)

                label = row.pn2kc_connections
                assert type(label) is str and label != ''

                color = label2color[label]

                responses.columns = responses.columns.map(olf.parse_odor_name)
                assert not responses.columns.isna().any()
                assert not responses.columns.duplicated().any()

                # at least for now, doing this here so that i don't need to re-run
                # model after abbrev_hallem_odor_index change (currently commented).
                # would also need to figure out how to deal w/ 'moct' if i wanted to
                # remove this (was thinking of changing 'MethOct' -> 'moct' in
                # load_remy_2e...)
                # thought I needed to do before corr_triangular, in order to get same
                # order as remy has for all the pairs, but moving this here didn't fix
                # all of that issue.
                my2remy_odor_names = {
                    'eugenol': 'eug',
                    'ethyl cinnamate': 'ECin',
                    'propyl acetate': 'PropAc',
                    'g-hexalactone': 'g-6lac',
                    'd-decalactone': 'd-dlac',
                    'moct': 'MethOct',
                    # I already had an abbreviation for the 7th
                    # ('1-penten-3-ol' -> '1p3ol'), which is consistent w/ hers.
                }
                ordered_pairs = None
                # thought I needed to do before corr_triangular, in order to get same
                # order as remy has for all the pairs, but moving this here didn't fix
                # all of that issue. still doing before corr_triangular, so my odor
                # names will line up with Remy's when I now pass in new ordered_pairs
                # kwarg to corr_triangular, which I added to manually fix this issue.
                if desc == 'hallem':
                    odor_strs = responses.columns

                    for old, new in my2remy_odor_names.items():
                        assert (odor_strs == new).sum() == 0
                        assert (odor_strs == old).sum() == 1
                        # TODO delete
                        #assert odor_strs.str.contains(f'{new} @').sum() == 0
                        #assert odor_strs.str.contains(f'{old} @').sum() == 1

                        odor_strs = odor_strs.str.replace(old, new)

                        # TODO delete
                        #assert odor_strs.str.contains(f'{new} @').sum() == 1
                        assert (odor_strs == new).sum() == 1

                    responses.columns = odor_strs

                    # any pairs (a, b) seen here will be used over any (b, a)
                    # corr_triangular would otherwise use. OK if not all pairs
                    # represented here (e.g. like how Remy's pairs are not all of the
                    # possible Hallem pairs, but this will at least make sure the
                    # overlap is consistent)
                    ordered_pairs = remy_pairs

                responses_including_silent = responses.copy()

                # TODO or factor corr calc + dropping into one fn, and call that in the
                # 3 places that currently use this?
                if drop_silent_model_kcs:
                    responses = drop_silent_model_cells(responses)

                # TODO refactor to combine dropping -> correlation [->mean across seeds]
                if 'seed' in responses.index.names:
                    # TODO refactor to share w/ internals of mean_of_fly_corrs?
                    # (use new square=False kwarg?)
                    corrs = responses.groupby(level='seed').apply(
                        lambda x: corr_triangular(x.corr(), ordered_pairs=ordered_pairs)
                    )
                    assert len(corrs) == N_SEEDS
                else:
                    corrs = corr_triangular(responses.corr(),
                        ordered_pairs=ordered_pairs
                    )
                    # so shape/type is same as in seed case above.
                    # name shouldn't be important.
                    corrs = corrs.to_frame(name='correlation').T

                del ordered_pairs

                # TODO where are NaN coming from in here?
                # ipdb> corrs.isna().sum().sum()
                # 34773
                # ipdb> corrs.size
                # 599500
                # ipdb> corrs.isna().sum().sum() / corrs.size
                # 0.05800333611342786

                # TODO is this weird? just some seeds have odors w/o cells
                # responding to them?
                #
                # ipdb> responses.shape
                # (163000, 110)
                # ipdb> corrs.shape[1]
                # 5995
                # ipdb> (corrs == 1).sum()
                # odor1              odor2
                # -aPine @ -2        -bCar @ -2          0
                # ...
                # t2h @ -2           terpinolene @ -2    0
                #                    va @ -2             0
                # terpinolene @ -2   va @ -2             0
                # Length: 5995, dtype: int64
                # ipdb> (corrs == 1).sum().sum()
                # 63
                # ipdb> np.isclose(corrs, 1).sum().sum()
                # 63

                pairs = corrs.columns.to_frame(index=False)
                # choosing 2 means none of the pairs are from the diagonal of the
                # correlation matrix (no identity elements. no correlations of odors
                # with themselves.)
                assert not (pairs.odor1 == pairs.odor2).any()

                assert not pairs.duplicated().any()

                # TODO delete. now doing this on responses.columns above
                '''
                # removing the concentration part of each odor str, e.g.
                # 'a @ -3' -> 'a' (since Remy and I format that part slightly diff)
                pairs = pairs.applymap(olf.parse_odor_name)
                # if any odor is presented at >1 conc, this 1st assertion would trip
                assert not pairs.duplicated().any()
                assert not pairs.isna().any().any()
                '''

                # TODO delete. doing before corr_triangular now.
                #pairs = pairs.replace(my2remy_odor_names)

                corrs.columns = pd.MultiIndex.from_frame(pairs)

                model_odors = set(pairs.odor1) | set(pairs.odor2)

                model_pairs = set(list(zip(pairs.odor1, pairs.odor2)))

                # we only ever have one representation of a given pair, and it's
                # always the same one across remy_pairs and model_pairs
                assert not any(
                    (b, a) in model_pairs or (b, a) in remy_pairs
                    for a, b in remy_pairs | model_pairs
                )

                n_odors = responses.shape[1]
                assert corrs.shape[1] == n_choose_2(n_odors)

                if desc == 'hallem':
                    assert n_odors == 110
                    # NOTE: unlike in pebbled cases below, we do sometimes have some
                    # odors without cells responding to them in here, and thus some
                    # NaN correlations

                    assert len(remy_2e_odors - model_odors) == 0

                    # TODO any other assertions in here? maybe something to complement
                    # currently-failing one above? (re: (a,b) vs (b,a))
                    # or will renaming those few odors fix that?
                    #import ipdb; ipdb.set_trace()

                # true as long as we don't also want to use this to plot
                # megamat+validation2 data (or validation2 alone)
                # (currently this code all only runs for megamat panel)
                elif desc == 'pebbled':
                    assert n_odors == len(megamat_odor_names) == len(model_odors)

                    # might also not be true in cases other than megamat
                    assert not corrs.isna().any().any()

                    assert len(model_odors - remy_2e_odors) == 0

                    remy_2e_odors_not_in_model = remy_2e_odors - model_odors
                    if i == 0 and len(remy_2e_odors_not_in_model) > 0:
                        # we are already checking model_odors doesn't change across
                        # iterations of this inner loop, so it's OK to only warn on
                        # first iteration.
                        warn(f'Remy 2e odors not in current ({desc}) model outputs: '
                            f'{remy_2e_odors_not_in_model}'
                        )
                    #

                    # TODO also want something like this in desc='hallem' case?
                    #
                    # seems Remy and I are constructing our pairs in the same way
                    # (so that I don't need to re-construct one or the other to make
                    # sure we never have (a, b) in one and (b, a) in the other)
                    assert len(model_pairs - remy_pairs) == 0

                    # all the other pairs Remy has include at least one non-megamat
                    # odor
                    assert not any([
                        (a in megamat_odor_names) and (b in megamat_odor_names)
                        for a, b in remy_pairs - model_pairs
                    ])


                if i == 0:
                    assert first_model_pairs is None
                    first_model_pairs = model_pairs

                    if desc != 'hallem':
                        remy_2e_corrs_in_model_mask = remy_2e_corrs.apply(lambda x:
                            (x.abbrev_row, x.abbrev_col) in model_pairs, axis=1
                        )
                        # TODO reset_index(drop=True)? prob no real effect on plots...
                        remy_2e_corrs_in_model = remy_2e_corrs[
                            remy_2e_corrs_in_model_mask
                        ]

                        assert 0 == len(
                            # in pebbled+megamat case, the two sets should also be
                            # equal.  in hallem case, model_pairs will have many pairs
                            # not in what Remy gave me (but all of Remy's pairs should
                            # have both odors in Hallem).
                            set(list(zip(
                                remy_2e_corrs_in_model.abbrev_row,
                                remy_2e_corrs_in_model.abbrev_col
                            ))) - model_pairs
                        )

                        # unlike pair sets, elements here are str (e.g. 'a, b')
                        remy_2e_pair_order_in_model = np.array([
                            x for x in remy_2e_pair_order
                            if tuple(x.split(', ')) in model_pairs
                        ])
                        assert (
                            set(remy_2e_corrs_in_model.odor_pair_str) ==
                            set(remy_2e_pair_order_in_model)
                        )

                        # we also make a version of this where we show all KC pairs (and
                        # only model data when we can) before this loop.
                        remy_2e_modelsubset_facetgrid = \
                            _create_2e_plot_with_obs_kc_corrs(
                                remy_2e_corrs_in_model, remy_2e_pair_order_in_model,
                                fill_markers=False
                        )
                else:
                    assert first_model_pairs is not None
                    # checking each iteration of this loop would be plotting the same
                    # subset of data
                    assert first_model_pairs == model_pairs

                corrs.columns.names = ['abbrev_row', 'abbrev_col']

                corr_dists = 1 - corrs

                # ignore_index=False so index (one 'seed' level only) is preserved,
                # so error can be computed across seeds for plot
                corr_dists = corr_dists.melt(ignore_index=False,
                    value_name='correlation_distance').reset_index()

                assert label not in pn_kc_cxn2model_corrs
                # label is str describing pn2kc connections (e.g. 'hemibrain')
                pn_kc_cxn2model_corrs[label] = corrs

                corr_dists['odor_pair_str'] = (
                    corr_dists.abbrev_row + ', ' + corr_dists.abbrev_col
                )

                _2e_plot_model_corrs(remy_2e_facetgrid, corr_dists,
                    remy_2e_pair_order, color=color, label=label,
                    n_first_seeds=fig2e_n_first_seeds
                )

                if desc != 'hallem':
                    assert remy_2e_modelsubset_facetgrid is not None
                    _2e_plot_model_corrs(remy_2e_modelsubset_facetgrid, corr_dists,
                        remy_2e_pair_order_in_model, color=color, label=label,
                        n_first_seeds=fig2e_n_first_seeds
                    )

                # TODO why does the hemibrain line on this seem more like ~0.6 than
                # the ~0.5 in preprint? matter (remy wasn't concerned enough to
                # track down which outputs she originally made plot from)?
                # TODO also, why does tail seem different in pebbled plot? meaningful?
                if desc == 'hallem':
                    responses_including_silent = responses_including_silent.loc[:,
                        # TODO delete (or revert, if plot_n_odors_per_cell doesn't work
                        # w/ concs stripped from responses...)
                        #responses_including_silent.columns.map(odor_is_megamat)
                        #
                        # responses.columns now have concentrations stripped, so
                        # checking this way rather than .map(odor_is_megamat)
                        responses_including_silent.columns.isin(megamat_odor_names)
                    ]

                assert (
                    len(responses_including_silent.columns) == len(megamat_odor_names)
                )
                plot_n_odors_per_cell(responses_including_silent, s1c_ax, label=label,
                    color=color
                )


            _finish_remy_2e_plot(remy_2e_facetgrid, n_first_seeds=fig2e_n_first_seeds)

            if desc != 'hallem':
                # TODO delete
                assert all(
                    '__data_pebbled__' in x.name or x.name == 'megamat'
                    for x, _, _ in _spear_inputs2dfs.keys()
                )

                mc_key = (
                    Path('pebbled_6f/pdf/ijroi/mb_modeling/megamat'),
                    'mean_kc_corr',
                    'mean_orn_corr'
                )
                assert _spear_inputs2dfs[mc_key].equals(merged_corrs)
                del _spear_inputs2dfs[mc_key]

                assert all(
                    (x.endswith('_dist') and y.endswith('_dist')) or
                    not (x.endswith('_dist') or y.endswith('_dist'))
                    for _, x, y in _spear_inputs2dfs.keys()
                )

                len_before = len(_spear_inputs2dfs)
                # would raise error if search didn't work on one (hence del above).
                # replacing Path objects with the relevant str part of their name,
                # for easier accessing.
                _spear_inputs2dfs = {
                    (re.search('pn2kc_([^_]*)__', p.name).group(1), x, y): df
                    # TODO delete. why wasn't this working for uniform/hemidraw
                    # (included extra past '__')?
                    #(re.search('pn2kc_(.*)__', p.name).group(1), x, y): df
                    for (p, x, y), df in _spear_inputs2dfs.items()
                }
                # checking we didn't map any 2 keys before to 1 key now
                assert len(_spear_inputs2dfs) == len_before

                assert orn_col == 'mean_orn_corr'

                model_corrs = []
                prev_model_corr = None
                for (pn2kc, x, y), odf in _spear_inputs2dfs.items():

                    if odf.index.names != ['odor1','odor2']:
                        odf = odf.set_index(['odor1','odor2'], verify_integrity=True)

                    if y == 'orn_corr':
                        s1 = merged_corrs[orn_col]
                        model_corr = odf['model_corr'].copy()
                        model_corr.name = f'{pn2kc}_corr'
                        model_corrs.append(model_corr)
                    else:
                        assert y == 'observed_kc_corr_dist'
                        # converting to correlation DISTANCE, to match `y` here
                        s1 = 1 - merged_corrs[kc_col]

                        model_corr = 1 - odf['model_corr_dist']

                        # these y == 'observed_kc_corr_dist' entries should always
                        # follow a y == 'orn_corr' entry with the same pn2kc value
                        assert prev_model_corr is not None
                        assert pd_allclose(model_corr, prev_model_corr)

                    prev_model_corr = model_corr

                    s2 = odf[y]
                    assert pd_allclose(s1, s2)

                merged_corrs = pd.concat([merged_corrs] + model_corrs, axis='columns',
                    verify_integrity=True
                )

                index_no_concs = merged_corrs.index.map(
                    # takes 2-tuples of ['odor1','odor2'] strs and strips concs
                    lambda x: (x[0].split(' @ ')[0], x[1].split(' @ ')[0])
                )
                assert all(
                    x.columns.equals(index_no_concs)
                    for x in pn_kc_cxn2model_corrs.values()
                )

                model_corrs2 = []
                for pn2kc, corrs in pn_kc_cxn2model_corrs.items():
                    # each `corrs` should be of shape (1|n_seeds, n_odors_choose_2)
                    if len(corrs) > 1:
                        assert corrs.index.name == 'seed'

                    mean_corrs = corrs.mean()
                    mean_corrs.name = f'{pn2kc}_corr'
                    model_corrs2.append(mean_corrs)

                model_corrs2 = pd.concat(model_corrs2, axis='columns',
                    verify_integrity=True
                )
                assert model_corrs2.index.equals(index_no_concs)
                model_corrs2.index = merged_corrs.index

                model_corrs1 = merged_corrs.iloc[:, 2:]
                assert set(model_corrs2.columns) == set(model_corrs1.columns)
                model_corrs2 = model_corrs2.loc[:, model_corrs1.columns]

                # TODO replace all model_corrs1 code w/ model_corrs2? (-> delete _spear*
                # global / etc)? (assertion below passing, so they are equiv now)
                #
                # no NaN in either, else we would want equal_nan=True
                assert pd_allclose(model_corrs1, model_corrs2)

                # checking nothing looks like a correlation DISTANCE (range [0, 2])
                #
                # the .[min|max]() calls returns series w/ index the 2 real (ORN, KC)
                # corrs, and the 3 model corrs, w/ the min|max for each, so we are
                # checking that each corr column has expected range.
                assert (merged_corrs.min() < 0).all()
                assert (merged_corrs.max() < 1).all()

                col_pairs = list(itertools.combinations(merged_corrs.columns, 2))
                # TODO names matter (for invert*)? omit?
                index = pd.MultiIndex.from_tuples(col_pairs, names=['c1', 'c2'])

                # compare mean-ORN / mean-KC / model Pearson's correlations, using
                # Spearman's correlation
                for method in ('spearman', 'pearson'):
                    corr_of_pearsons = merged_corrs.corr(method=method)
                    xlabel = f"{method.title()}s-of-Pearsons"

                    output_name_without_ci = f'{method}_of_pearsons'

                    plot_corr(corr_of_pearsons, panel_plot_dir, output_name_without_ci,
                        overlay_values=True, xlabel=xlabel
                    )

                    for ci in (90, 95):
                        ci_str = f'{ci:.0f}'
                        ci_title_str = f'{ci_str}% CI'
                        # TODO do something other than average over 100 seeds?

                        output_name = f'{output_name_without_ci}_ci{ci_str}'

                        corrs = []
                        lower_cis = []
                        upper_cis = []
                        pvals = []
                        for x, y in col_pairs:
                            # TODO add one extra sigfig (in spear_text, the first
                            # returned arg from bootstrapped_corr) for the correlation
                            # and CI part (from 2 sigfigs -> 3)
                            _, corr, ci_lower, ci_upper, pval = bootstrapped_corr(
                                merged_corrs, x, y, method=method, ci=ci
                            )
                            corrs.append(corr)
                            lower_cis.append(ci_lower)
                            upper_cis.append(ci_upper)
                            pvals.append(pval)

                        corr_df = pd.DataFrame({
                                'corr': corrs, 'lower': lower_cis, 'upper': upper_cis,
                                'pval': pvals
                            }, index=index
                        )
                        to_csv(corr_df, panel_plot_dir / f'{output_name}.csv')

                        square_corr = invert_corr_triangular(corr_df['corr'], name=None)
                        assert pd_allclose(square_corr, corr_of_pearsons)

                        # are CI's symmetric (no) (i.e. can i get one measure of error
                        # for each matrix element, or will it make more sense to have 2
                        # extra matrix plots, one for lower CI and one for upper CI?)
                        square_lower = invert_corr_triangular(corr_df['lower'],
                            name=None
                        )
                        square_upper = invert_corr_triangular(corr_df['upper'],
                            name=None
                        )

                        plot_corr(square_lower, panel_plot_dir,
                            f'{method}_of_pearsons_lower_ci{ci_str}',
                            overlay_values=True,
                            xlabel=f'{xlabel}\nlower side of {ci_title_str}'
                        )
                        plot_corr(square_upper, panel_plot_dir,
                            f'{method}_of_pearsons_upper_ci{ci_str}',
                            overlay_values=True,
                            xlabel=f'{xlabel}\nupper side of {ci_title_str}'
                        )

                assert remy_2e_modelsubset_facetgrid is not None
                _finish_remy_2e_plot(remy_2e_modelsubset_facetgrid,
                    n_first_seeds=fig2e_n_first_seeds
                )

            # seed_errorbar is used internally by plot_n_odors_per_cell
            savefig(remy_2e_facetgrid, panel_plot_dir,
                f'2e_{desc}{fig2e_seed_err_fname_suffix}'
            )

            # model subset same in this case
            if desc != 'hallem':
                savefig(remy_2e_modelsubset_facetgrid, panel_plot_dir,
                    f'2e_{desc}_model-subset{fig2e_seed_err_fname_suffix}'
                )

            # TODO double check error bars are 95% ci. some reason matt's are so much
            # larger? previous remy data really much more noisy here?
            # (pretty sure current errorbars are right. not sure if old ones were, or
            # what spread was like there)
            plot_n_odors_per_cell(remy_binary_responses, s1c_ax, label='observed',
                color='black'
            )

            s1c_ax.legend()
            # errorbars are really small for model here, and can barely see CI's get
            # bigger increasing from 95 to 99
            s1c_ax.set_title(f'model run on {desc}\n{seed_err_text}')

            savefig(s1c_fig, panel_plot_dir,
                f's1c_n_odors_vs_cell_frac_comparison_{desc}'
            )


# TODO try to move all fns below to al_analysis wrapping model_mb_responses output?
# (or otherwise separate out a simplest-possible version of running model code, that
# doesn't involve all the plotting for paper w/ remy)
# (or at least move to al_util, to declutter this file?)

n_megamat_odors = 17
assert len(megamat_odor_names) == n_megamat_odors

# TODO put in docstring which files we are loading from
def _load_remy_megamat_kc_responses(drop_nonmegamat: bool = True, drop_pfo: bool = True
    ) -> pd.DataFrame:

    fly_response_root = remy_data_dir / 'megamat17' / 'per_fly'
    response_file_to_use = 'xrds_suite2p_respvec_mean_peak.nc'
    # Remy confirmed it's this one
    response_calc_to_use = 'Fc_zscore'

    olddata_fly_response_root = remy_data_dir / '2024-11-12'
    olddata_response_file_to_use = 'xrds_responses.nc'

    # TODO is it a problem that we are using peak_amp here and something zscored above?
    # is this actually zscored too? matter?
    #
    # other variables in these Datasets:
    # Data variables:
    #     peak_amp          (trials, cells) float64 ...
    #     peak_response     (trials, cells) float64 ...
    #     bin_response      (trials, cells) int64 ...
    #     baseline_std      (trials, cells) float64 ...
    #     baseline_med      (trials, cells) float64 ...
    #     peak_idx          (trials, cells) int64 ...
    olddata_response_calc_to_use = 'peak_amp'

    verbose = al_util.verbose
    if verbose:
        print()
        print('loading Remy megamat KC responses to compute (odor X odor) corrs:')

    _seen_date_fly_combos = set()
    mean_response_list = []

    for fly_dir in fly_response_root.glob('*/'):

        if not fly_dir.is_dir():
            continue

        # corresponding correlation .nc file in fly_dir / 'RDM_trials' should also be
        # equiv to one element of above `corrs`
        fly_response_dir = fly_dir / 'respvec'
        fly_response_file = fly_response_dir / response_file_to_use

        if verbose:
            print(fly_response_file)

        responses = xr.open_dataset(fly_response_file)

        date = pd.Timestamp(responses.attrs[remy_date_col])
        assert len(remy_fly_cols) == 2 and 'fly_num' == remy_fly_cols[1]
        # should already be an int, just weird numpy.int64 type, and not sure that
        # behaves same in sets (prob does).
        fly_num = int(responses.attrs['fly_num'])
        thorimage = responses.thorimage
        if verbose:
            # NOTE: responses.attrs[x] seems to be equiv to responses.x
            print('/'.join(
                [str(responses.attrs[x]) for x in remy_fly_cols] + [thorimage]
            ))

        # excluding thorimage, b/c also don't want 2 recordings from one fly making it
        # in, like happened w/ her precomputed corrs
        assert (date, fly_num) not in _seen_date_fly_combos
        _seen_date_fly_combos.add( (date, fly_num) )

        n_cells = responses.sizes['cells']
        if verbose:
            print(f'{n_cells=}')

        assert (responses.iscell == 1).all().item()
        assert len(responses.attrs['bad_trials']) == 0

        # TODO move to checks=True?
        all_xid_set = set(responses.xid0.values)
        # TODO factor out this assertion to hong2p.util (probably do something like this
        # in a lot of places. use in those places too.)
        assert all_xid_set == set(range(max(all_xid_set) + 1))

        # NOTE: isin(...) does not work here if input is a Python set()
        # (so keeping good_xid as a DataArray, or whatever type it is)
        good_xid = responses.attrs['good_xid']
        good_cells_mask = responses.xid0.isin(good_xid)

        good_xid_set = set(good_xid)
        # we have some xid0 values other than those in attrs['good_xid']
        # (so Remy did not pre-subset the data, and we should have all the cells)
        assert len(all_xid_set - good_xid_set) > 0
        #

        n_good_cells = good_cells_mask.sum().item()
        assert n_good_cells < n_cells

        n_bad_cells = (~ good_cells_mask).sum().item()
        if verbose:
            print(f'{n_bad_cells=}')

        assert (n_good_cells + n_bad_cells) == responses.sizes['cells']

        checks = True
        if checks:
            single_fly_nc_files = list(remy_binary_response_dir.glob((
                f'{format_date(date)}__fly{fly_num:>02}__*/'
                f'{remy_fly_binary_response_fname}'
            )))
            assert len(single_fly_nc_files) == 1
            fly_binary_response_file = single_fly_nc_files[0]

            binary_responses = load_remy_fly_binary_responses(fly_binary_response_file,
                reset_index=False
            )

            binary_response_xids = set(binary_responses.index.get_level_values('xid0'))
            # binary responses don't have a subset of the XID, they have all of them
            # (i.e. they haven't been subset to just the good_xid cells by Remy)
            assert binary_response_xids == all_xid_set
            # TODO use factored out version of this when i make it
            assert binary_response_xids == set(range(max(binary_response_xids) + 1))

            assert np.array_equal(
                binary_responses.index.to_frame(index=False)[['cells_level_0','xid0']],
                np.array([responses.cells, responses.xid0]).T
            )

            # seems pretty good:
            # responders? False
            # 305 good-XID-cells / 1634 cells (0.187)
            # responders? True
            # 2166 good-XID-cells / 2547 cells (0.850)
            def _print_frac_good_xid(gdf):
                responder_val_set = set(gdf.responder)
                assert len(responder_val_set) == 1
                responder_val = responder_val_set.pop()
                assert responder_val in (False, True)

                if responder_val:
                    print('among responders:')
                else:
                    print('among silent cells:')
                # TODO delete
                #print(f'responders? {responder_val}')

                # this isin DOES (pandas index LHS, not DataArray) work w/ python set
                # arg
                good_xid_mask = gdf.index.get_level_values('xid0').isin(good_xid_set)

                n_good_cells = good_xid_mask.sum()
                n_cells = len(good_xid_mask)
                good_cell_frac = n_good_cells / n_cells
                # TODO actually inspect these outputs -> decide i'm happy with them ->
                # only run this code if verbose (via settings checks flag above in this
                # fn)
                print(f'{n_good_cells} good-XID-cells / {n_cells} cells'
                    f' ({good_cell_frac:.3f})'
                )

            if verbose:
                binary_responses['responder'] = binary_responses.any(axis='columns')
                binary_responses.groupby('responder').apply(_print_frac_good_xid)
                print()

        # another way to do the same thing:
        # responses = responses.where(good_cells_mask, drop=True)
        responses = responses.sel(cells=good_cells_mask)
        assert responses.sizes['cells'] == n_good_cells

        # doing this doesn't seem to preserve attrs (some way to? or are they only for
        # Dataset not DataArray?). seems DataArray support .attrs, but may just need to
        # manually assign from DataSet?
        #
        # (odors X trials) X cells
        responses = responses[response_calc_to_use]

        # odors X cells
        mean_responses = responses.groupby('stim').mean(dim='trials')

        # the reset_index(drop=True) is to remove cell numbers (which currently have
        # missing cells, because of xid-based dropping above, which might be confusing)
        mean_response_df = mean_responses.to_pandas().T.reset_index(drop=True)
        mean_response_df.index.name = 'cell'

        # referring to flies this way should make it simpler to compare to corrs in CSVs
        # Remy gave me for making fig 2E (which have a 'datefly' column, that should be
        # formatted like this)
        datefly = f'{format_date(date)}/{fly_num}'
        mean_response_df = util.addlevel(mean_response_df, 'datefly', datefly)

        # just to conform to format in loop below. only one recording for each of these
        # flies.
        mean_response_df = util.addlevel(mean_response_df, 'thorimage', thorimage)

        mean_response_list.append(mean_response_df)

        if verbose:
            print()

    # TODO delete. just to try to get new concat of new + old data to be in a similar
    # format.
    new_mean_responses = pd.concat(mean_response_list, verify_integrity=True)
    #

    # TODO TODO refactor to share as much of body of loop w/ above (convert to one loop,
    # and just special case a few things based on parent dir?). currently copied from
    # loop above.
    #
    # for this old data, don't have the same set of cells across any of the multiple
    # recordings for any one fly. always gonna be a diff set of cells.
    for fly_dir in olddata_fly_response_root.glob('*/'):

        if not fly_dir.is_dir():
            continue

        # corresponding correlation .nc file in fly_dir / 'RDM_trials' should also be
        # equiv to one element of above `corrs`
        fly_response_dir = fly_dir / 'respvec'
        fly_response_file = fly_response_dir / olddata_response_file_to_use

        if verbose:
            print(fly_response_file)

        responses = xr.open_dataset(fly_response_file)

        date = pd.Timestamp(responses.attrs[remy_date_col])
        assert len(remy_fly_cols) == 2 and 'fly_num' == remy_fly_cols[1]
        # should already be an int, just weird numpy.int64 type, and not sure that
        # behaves same in sets (prob does).
        fly_num = int(responses.attrs['fly_num'])
        thorimage = responses.thorimage
        if verbose:
            # NOTE: responses.attrs[x] seems to be equiv to responses.x
            print('/'.join(
                [str(responses.attrs[x]) for x in remy_fly_cols] + [thorimage]
            ))

        n_cells = responses.sizes['cells']
        if verbose:
            print(f'{n_cells=}')

        # old data doesn't have the attributes iscell or bad_trials

        # from Remy's code snippet she sent on 2024-11-12 via slack
        good_cells_mask = responses['iscell_responder'] == 1

        n_good_cells = good_cells_mask.sum().item()
        assert n_good_cells < n_cells

        n_bad_cells = (~ good_cells_mask).sum().item()
        if verbose:
            print(f'{n_bad_cells=}')

        assert (n_good_cells + n_bad_cells) == responses.sizes['cells']

        # another way to do the same thing:
        # responses = responses.where(good_cells_mask, drop=True)
        responses = responses.sel(cells=good_cells_mask)
        assert responses.sizes['cells'] == n_good_cells

        responses = responses[olddata_response_calc_to_use]

        # odors X cells
        mean_responses = responses.groupby('stim').mean(dim='trials')

        # the reset_index(drop=True) is to remove cell numbers (which currently have
        # missing cells, because of dropping above, which might be confusing)
        mean_response_df = mean_responses.to_pandas().T.reset_index(drop=True)
        mean_response_df.index.name = 'cell'

        # referring to flies this way should make it simpler to compare to corrs in CSVs
        # Remy gave me for making fig 2E (which have a 'datefly' column, that should be
        # formatted like this)
        datefly = f'{format_date(date)}/{fly_num}'
        mean_response_df = util.addlevel(mean_response_df, 'datefly', datefly)

        # multiple recordings for most/all flies, presumably each w/ diff odors
        mean_response_df = util.addlevel(mean_response_df, 'thorimage', thorimage)

        mean_response_list.append(mean_response_df)
        if verbose:
            print()

    # TODO compare format to new_mean_responses (temp debug var)
    mean_responses = pd.concat(mean_response_list, verify_integrity=True)

    odors = [olf.parse_odor(x) for x in mean_responses.columns]

    names = np.array([x['name'] for x in odors])
    assert megamat_odor_names - set(names) == set(), 'missing some megamat odors'

    # cast_int_concs=True to convert '-3.0' to '-3', to be consistent w/ mine
    odor_strs = [olf.format_odor(x, cast_int_concs=True) for x in odors]
    mean_responses.columns = odor_strs

    # so al_util.mean_of_fly_corrs works
    mean_responses.columns.name = 'odor1'

    # when also loading old (prior to final 4 flies) megamat data:
    # (set(names) - megamat_odor_names)={'PropAc', '1p3ol', 'pfo', 'g-6lac', 'eug',
    # 'd-dlac', 'MethOct', 'ECin'}
    if drop_nonmegamat:
        megamat_mask = [x in megamat_odor_names for x in names]
        megamat_mean_responses = mean_responses.loc[:, megamat_mask]

        if verbose:
            nonmegamat_odors = mean_responses.columns.difference(
                megamat_mean_responses.columns
            )
            warn('dropping the following non-megamat odors:\n'
                f'{pformat(list(nonmegamat_odors))}'
            )

        mean_responses = megamat_mean_responses

    # elif because we will have already dropped pfo if drop_nonmegamat=True
    # (pfo is not considered part of megamat)
    elif drop_pfo:
        pfo_mask = names == 'pfo'
        assert pfo_mask.sum() > 0
        mean_responses = mean_responses.loc[:, ~pfo_mask]

    return mean_responses


# TODO rename all of these fns to remove '_megamat' (unless i actually drop down to just
# megamat, but i don't think i want that?)? or just do it anyway to shorten these names?
def _remy_megamat_flymean_kc_corrs(ordered_pairs=None, **kwargs) -> pd.DataFrame:
    mean_responses = _load_remy_megamat_kc_responses(**kwargs)

    # TODO move some functionality like this into al_util.mean_of_fly_corrs (to average within
    # fly across recordings first)?
    recording_corrs = mean_responses.groupby(level=['datefly', 'thorimage'], sort=False
        ).apply(lambda x: corr_triangular(x.corr(), ordered_pairs=ordered_pairs))

    fly_corrs = recording_corrs.groupby(level='datefly', sort=False).mean()

    checks = True
    if checks:
        old_megamat_root = remy_data_dir / '2024-11-12'
        # TODO also load + check against stim_rdms__iscell_good_xid0__correlation.xlsx?
        # (it should have been generated from this .nc, w/ remy providing a script to
        # generate this xlsx file from it, but still...)
        corr_file_for_anoop = (
            old_megamat_root / 'xrda_stim_rdm_concat__iscell_good_xid0__correlation.nc'
        )

        # adapted from the example script Remy emailed (2024-11-07) Anoop alongside this
        # data (demo_megamat_new_and_old_by_fly_17_kc_soma_nls.py, from OdorSpaceShare
        # repo)
        da_stim_rdm_concat = xr.load_dataarray(corr_file_for_anoop)

        # otherwise .to_index() call below doesn't give me what i want
        da_stim_rdm_concat = da_stim_rdm_concat.set_index({
            'acq': remy_fly_cols + ['thorimage_name']
        })

        #            date_imaged  fly_num              thorimage_name
        # 0   2022-10-10        1                    megamat0
        # 1   2022-10-10        2                    megamat0
        # 2   2022-10-11        1                    megamat0
        # 3   2022-11-10        1            megamat0__dsub03
        # 4   2018-10-21        1         _002+_003+_004+_005
        # 5   2019-03-06        3                        _002
        # 6   2019-03-06        4                        _003
        # 7   2019-03-07        2                  _003+_0057
        # 8   2019-04-26        4                     fn_0002
        # 9   2019-05-09        4             fn_0001+fn_0003
        # 10  2019-05-09        5             fn_0001+fn_0002
        # 11  2019-05-23        2                     fn_0001
        # 12  2019-05-24        1                     fn_0003
        # 13  2019-05-24        3                     fn_0001
        # 14  2019-05-24        4             fn_0001+fn_0002
        # 15  2019-07-19        2  movie001+movie002+movie003
        # 16  2019-09-12        1             fn_0002+fn_0003
        # 17  2019-09-12        2             fn_0001+fn_0002
        fly_metadata = da_stim_rdm_concat.coords['acq'].to_index().to_frame(index=False)
        # we already have combined data across recordings (for flies that have multiple.
        # see rows w/ '+' in thorimage_name in comment above)
        assert len(fly_metadata) == len(fly_metadata[remy_fly_cols].drop_duplicates())

        assert fly_corrs.index.name == 'datefly'
        recalced_flies = set(fly_corrs.index)

        datefly_strs = fly_metadata[remy_fly_cols].astype(str).agg('/'.join, axis=1)
        flies_for_anoop = set(datefly_strs)
        assert recalced_flies == flies_for_anoop

        da_stim_rdm_concat = da_stim_rdm_concat.assign_coords(
            {'datefly': ('acq', datefly_strs)}).set_index({'acq': 'datefly'}
        )

        fly_corrs_has_dropped_non_megamat = kwargs.get('drop_nonmegamat', True)

        if fly_corrs_has_dropped_non_megamat:
            # (to compare to the single fly corrs in the .nc file Remy gave Anoop in
            # November 2024, which also included old megamat data, in addition to the
            # final 4 flies we had been using)
            corrs_to_compare_to_anoop_data = fly_corrs
        else:
            megamat_pairs = fly_corrs.columns.to_frame().applymap(odor_is_megamat
                ).all(axis='columns')
            corrs_to_compare_to_anoop_data = fly_corrs.loc[:, megamat_pairs]

            n_megamat_only_pairs = n_choose_2(n_megamat_odors)
            assert len(corrs_to_compare_to_anoop_data.columns) == n_megamat_only_pairs


        for datefly in corrs_to_compare_to_anoop_data.index:
            fly_corr = corrs_to_compare_to_anoop_data.loc[datefly]
            fly_corr = fly_corr.dropna()

            # need to go from '1-5ol @ -3.0' format row/col index odors have here,
            # to '1-5ol @ -3' as in fly_corr index
            fly_da_stim_rdm = da_stim_rdm_concat.sel(acq=datefly).to_pandas()

            odor_strs = [
                # TODO refactor this parsing -> formatting, to a fn just for normalizing
                # repr of conc part of str (to int)?
                olf.format_odor(olf.parse_odor(x), cast_int_concs=True)
                for x in fly_da_stim_rdm.index
            ]
            assert fly_da_stim_rdm.columns.equals(fly_da_stim_rdm.index)
            fly_da_stim_rdm.index = odor_strs
            fly_da_stim_rdm.columns = odor_strs

            # TODO delete if i remove assertion in corr_triangular that index/columns
            # names have to start with 'odor'
            fly_da_stim_rdm.index.name = 'odor'
            fly_da_stim_rdm.columns.name = 'odor'

            anoop_fly_corr = corr_triangular(1 - fly_da_stim_rdm,
                # TODO TODO do we actually need this tho? or was it the other changes
                # that made a diff?
                ordered_pairs=fly_corr.index
            )

            # TODO work? (comment what intention / effect is?)
            anoop_fly_corr = anoop_fly_corr.dropna()

            # seems we don't need to pass particular pairs into corr_triangular
            assert pd_allclose(fly_corr, anoop_fly_corr, equal_nan=True)

    # TODO delete
    # TODO check above equiv to this, at least if we no longer load old data?
    # TODO check this works if there are multiple thorimage level values (i.e.
    # recordings) for one pair (e.g. 1-6ol, 2-but) for any fly. should average the corrs
    # first, then compute average across flies.
    #mean_corr = al_util.mean_of_fly_corrs(mean_responses.T, id_cols=['datefly'])

    return fly_corrs


# don't need ordered_pairs here b/c output of this fn should be square, so it no longer
# matters.
def load_remy_megamat_mean_kc_corrs(**kwargs) -> pd.DataFrame:
    """Returns mean of fly correlations, for Remy's 4 final megamat KC flies.

    Drops cells from bad clusters (as Remy does, using xarray attrs['good_xid'] that she
    sets to good clusters, excluding clusters of bad cells, which should mostly be
    silent cells) before computing correlations. The 3 trials for each odor are
    averaged together into a single odor X cell response matrix before computing each
    fly's correlation. Correlation is computed within each fly, and then the average is
    computed across these correlations. This should all be consistent with how Remy
    computes correlations.
    """
    fly_corrs = _remy_megamat_flymean_kc_corrs(**kwargs)
    mean_corr_ser = fly_corrs.mean()
    mean_corr = invert_corr_triangular(mean_corr_ser)
    return mean_corr


remy_2e_metric = 'correlation_distance'

# TODO TODO try a version of this w/ either hollow points or no points (to show small
# errorbars that would otherwise get subsumed into point)
_fig2e_shared_plot_kws = dict(
    x='odor_pair_str',
    y=remy_2e_metric,

    errorbar=seed_errorbar,
    seed=bootstrap_seed,
    err_kws=dict(linewidth=1.5),

    markersize=7,
    #markeredgewidth=0,
)

def _check_2e_metric_range(df) -> None:
    # TODO cases where i'd want to warn instead?
    """Raises AssertionError if data range seems inconsistent w/ `remy_2e_metric`.
    """
    # TODO TODO assert things seem consistent w/ being correlation distance (or at
    # least, not correlation)
    if remy_2e_metric == 'correlation_distance':
        metric = df[remy_2e_metric]
        # if it were < 0, would suggest it's a correlation, not a correlation DISTANCE
        assert metric.min() >= 0
        # do we actually have values over 1 always tho? can just remove this if need be
        assert metric.max() > 1
    else:
        # could also do similar for 'correlation', but only ever using this one
        raise NotImplementedError("checking range only supported for remy_2e_metric="
            "'correlation_distance'"
        )

# TODO add some kind of module level dict of fig ID -> pair_order, and use to check each
# fig is getting the same pair_order across these two calls? or use so that only first
# call even takes pair_order, but then assert model pairs are a subset in the
# subsequence call(s)?
#
# need @no_constrained_layout since otherwise FacetGrid creation would warn with
# Warning: The figure layout has changed to tight
# (since my MPL config has constrained layout as default)
@no_constrained_layout
def _create_2e_plot_with_obs_kc_corrs(df_obs: pd.DataFrame, pair_order: np.array, *,
    fill_markers=True) -> sns.FacetGrid:

    _check_2e_metric_range(df_obs)

    odor_pair_set = set(pair_order)
    assert odor_pair_set == set(df_obs.odor_pair_str.unique())
    assert len(odor_pair_set) == len(pair_order)

    # don't have any identity correlations (odors correlated with themselves)
    assert not (df_obs.abbrev_row == df_obs.abbrev_col).any()

    color = 'k'

    if fill_markers:
        marker_kws = dict(markeredgewidth=0)
    else:
        # TODO TODO why are lines on these points thinner than in model corr plot call
        # (below)? (was because linewidth)
        marker_kws = dict(markerfacecolor='white', markeredgecolor=color)

    # other types besides array might work for pair_order, but I've only been using
    # arrays (as in Remy's code I adapted from)
    g = sns.catplot(
        data=df_obs,

        # TODO work to omit if input has x='odor_pair_str' values in sorted order i
        # want (and would it matter if subsequent calls had same order, or would it be
        # aligned?)
        # TODO what about if x column is a pd.Categorical(..., ordered=True)
        # (and if there are sometimes cases where data isn't aligned correctly across
        # calls, does this change the situation?)
        order=pair_order,

        kind='point',

        # TODO so it's jittering? can i seed that? not that it really matters, except
        # for running w/ -c flag...  i'm assuming seed= doesn't also seed jitter?
        # (haven't had -c flag trip, so i'm assuming it's not actually jittering [maybe
        # not enough data that there is a need?] or same seed controls that)
        #
        # jitter=False,

        color=color,

        aspect=2.5,
        height=7,
        #linewidth=1,

        **_fig2e_shared_plot_kws,
        **marker_kws
    )

    # test output same whether input is 'correlation' or 'correlation_distance', as
    # expected.
    pair_metrics = []
    for _, gdf in df_obs.groupby('odor_pair_str'):
        pair_metrics.append(gdf[remy_2e_metric].to_numpy())

    # one way ANOVA (null is that groups have same population mean. groups can be diff
    # sizes)
    result = f_oneway(*pair_metrics)
    # from scipy docs:
    # result.statistic: "The computed F statistic of the test."
    # result.pvalue: "The associated p-value from the F distribution."

    g.ax.set_title(
        f'{len(odor_pair_set)} non-identity odor pairs\n'
        # .2E will show 2 places after decimal w/ exponent (scientific notation)
        f'(one way ANOVA) F-statistic: {result.statistic:.2f}, p={result.pvalue:.2E}'
    )

    return g


@no_constrained_layout
def _2e_plot_model_corrs(g: sns.FacetGrid, df: pd.DataFrame, pair_order: np.ndarray,
    n_first_seeds: Optional[int] = n_first_seeds_for_errorbar, **kwargs) -> None:

    _check_2e_metric_range(df)

    if n_first_seeds is not None and 'seed' in df.columns:
        df = select_first_n_seeds(df, n_first_seeds=n_first_seeds)

    # TODO some way to get hue/palette to work w/ markeredgecolor? i assume not
    if 'hue' not in kwargs:
        assert 'color' in kwargs
        # TODO like? factor to share w/ other seed_errorbar plots?
        marker_kws = dict(markerfacecolor='None', markeredgecolor=kwargs['color'])
    else:
        # TODO keep? remy had before, but obviously prevents markeredgecolor working in
        # above case. not sure i care about this in hue/palette case.
        marker_kws = dict(markeredgewidth=0)

    sns.pointplot(data=df, order=pair_order, linestyle='none', ax=g.ax,
        **_fig2e_shared_plot_kws, **kwargs, **marker_kws
    )


# TODO move this (and related) to mb_model.py?
@no_constrained_layout
def _finish_remy_2e_plot(g: sns.FacetGrid, *, n_first_seeds=n_first_seeds_for_errorbar
    ) -> None:

    g.set_axis_labels('odor pairs', remy_2e_metric)
    # 0.9 wasn't enough to have axes title and suptitle not overlap
    g.fig.subplots_adjust(bottom=0.2, top=0.85)

    # TODO use paper's 1.2 instead? or just leave unset? just set min to 0?
    # TODO TODO why does it seem to be showing as 1.2 w/ this at 1.4 anyway?
    g.ax.set_ylim(0, 1.4)

    seed_err_text, _ = _get_seed_err_text_and_fname_suffix(n_first_seeds=n_first_seeds)

    g.fig.suptitle(f'odor-odor {remy_2e_metric}\n{seed_err_text}')

    sns.despine(fig=g.fig, trim=True, offset=2)
    g.ax.xaxis.set_tick_params(rotation=90, labelsize=8)

    # TODO move legend to bottom left (in top right now)?


# TODO rename to ...corr_dists or something?
def load_remy_2e_corrs(plot_dir=None, *, use_preprint_data=False) -> pd.DataFrame:

    # just for some debug outputs (currently 1 CSV w/ flies listed for each odor pair,
    # and recreation of Remy's old 2E plot). nothing hugely important.
    if plot_dir is not None:
        output_root = plot_dir
    else:
        output_root = Path('.')

    # TODO move relevant data to my own path in this repo (to pin version, independent
    # of what remy pushes to this repo) (-> use those files below)
    _repo_root = Path.home() / 'src/OdorSpaceShare'
    assert _repo_root.is_dir()

    preprint_data_folder = _repo_root / 'preprint/data/figure-02/02e'

    # TODO roughly compare old vs new data? or just make plots w/ both (after settling
    # on error repr...)
    if use_preprint_data:
        warn('using pre-print data for 2E (set use_preprint_data=False to use newer '
            'data)!'
        )
        data_folder = preprint_data_folder
        csv_name = 'df_obs_plot_trialavg.csv'
    else:
        # TODO TODO TODO which flies are in this but not in old megamat data i'm now
        # loading for a lot of things? any?
        data_folder = _repo_root / 'manuscript/data/figure-02/02e'
        # df_obs.csv in the same folder was one of her earlier attempts to get me a
        # newer version of this data, but was not completely consistent w/ format of old
        # CSV (and also had 'correlation' col that was actually correlation distance).
        # df_obs.csv should not be used.
        csv_name = 'df_obs_for_tom.csv'

    assert data_folder.is_dir()

    csv_path = data_folder.joinpath(csv_name)
    if al_util.verbose:
        print(f'loading Remy correlations for 2E from {csv_path}')

    df_obs = pd.read_csv(csv_path)

    assert not df_obs.isna().any().any()

    df_obs[['abbrev_row','abbrev_col']] = df_obs['odor_pair_str'].str.split(pat=', ',
        expand=True
    )
    assert (
        len(df_obs[['abbrev_row','abbrev_col']].drop_duplicates()) ==
        len(df_obs.odor_pair_str.drop_duplicates())
    )

    # (currently renaming my model output odors to match remy's, during creation of my
    # 2E plots, so no need for now)
    # TODO rename 'MethOct' -> 'moct', to be consistent w/ mine

    # TODO refactor to share def of these 2 odor cols w/ elsewhere?
    #
    # within each fly, expect each pair to only be reported once
    assert not df_obs.duplicated(subset=['datefly','abbrev_row','abbrev_col']).any()

    identity = df_obs.abbrev_col == df_obs.abbrev_row
    assert (df_obs[identity].correlation == 1).all()

    # we don't want to include these on plots, and the repeated 1.0 values also
    # interfere with some of the checks on my sorting.
    df_obs = df_obs[~identity].reset_index(drop=True)
    assert not (df_obs.correlation == 1).any()

    # plot ordering of odor pairs (ascending observed correlations)
    mean_pair_corrs = df_obs.groupby('odor_pair_str').correlation.mean()
    df_obs['mean_pair_corr'] = df_obs.odor_pair_str.map(mean_pair_corrs)

    # will start with low correlations, and end w/ the high ones (currently identity 1.0
    # corrs), as in preprint order.
    #
    # NOTE: if we ever really care to *exactly* recreate preprint 2E, we may need to use
    # Remy's order from:
    # np.load(data_folder.joinpath('odor_pair_ord_trialavg.npy'), allow_pickle=True)
    #
    # (previously committed code to use this order, but deleted now that I have my own
    # replacement for all new versions [which also either almost/exactly matches
    # preprint fig too])
    df_obs = df_obs.sort_values('mean_pair_corr', kind='stable').reset_index(drop=True)

    # TODO factor this into some check fn? haven't i done something similar elsewhere?
    #
    # checking all rows with a given pairs are adjacent after above sorting.
    # should be True since we are now dropping identity rows before sorting.
    # allows us to more easily derive order from output, for plotting against my own
    # model runs.
    last_seen_index = None
    for _, gdf in df_obs.groupby('odor_pair_str', sort=False):
        if last_seen_index is not None:
            assert last_seen_index + 1 == gdf.index.min()
        else:
            assert gdf.index.min() == 0

        last_seen_index = gdf.index.max()
        assert set(gdf.index) == set(range(gdf.index.min(), gdf.index.max() + 1))

    # .unique() has output in order first-seen, which (given check above), should be
    # same as sorting all pairs by mean correlation
    pair_order = df_obs.odor_pair_str.unique()
    assert np.array_equal(pair_order, mean_pair_corrs.sort_values().index)

    # TODO does it make sense that there is such a diversity of N counts for specific
    # pairs?  inspect pairs / flies + talk to remy.
    #
    # ipdb> df_obs.odor_pair_str.value_counts()
    # 1-6ol, 1-6ol    22
    # 2-but, 2-but    21
    # 1-6ol, 2-but    21
    # benz, benz      20
    # 1-6ol, benz     20
    #                 ..
    # aa, benz         4
    # ep, eug          3
    # PropAc, va       3
    # eug, ECin        3
    # 2h, MethOct      3
    # Name: odor_pair_str, Length: 205, dtype: int64
    # ipdb> set(df_obs.odor_pair_str.value_counts())
    # {3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22}
    s1 = df_obs.groupby('odor_pair_str').size()
    assert s1.equals(df_obs.groupby('odor_pair_str').nunique().datefly)

    # TODO delete (replacing w/ just 'datefly')?
    assert (df_obs.datefly.map(lambda x: x[:2]) == '20').all()
    df_obs['datefly_abbrev'] = df_obs.datefly.map(lambda x: x[2:])
    #

    unique_datefly_per_pair = df_obs.groupby('odor_pair_str', sort=False
        ).datefly_abbrev.unique()

    assert s1.equals(unique_datefly_per_pair.str.len().sort_index())
    del s1

    # TODO delete?
    n_summary = pd.concat([
            df_obs.groupby('odor_pair_str', sort=False).size(),
            unique_datefly_per_pair
        ], axis='columns'
    )
    n_summary.columns = ['n', 'datefly']

    assert np.array_equal(n_summary.index, pair_order)

    n_summary.datefly = n_summary.datefly.map(lambda x: ', '.join(x))

    if use_preprint_data:
        suffix = '_OLD-PREPRINT-DATA'
    else:
        suffix = ''

    # TODO TODO inspect with remy
    to_csv(n_summary, output_root / f'remy_2e_n_per_pair{suffix}.csv')
    #

    df_obs['correlation_distance'] = 1 - df_obs.correlation
    assert df_obs['correlation_distance'].max() <= 2.0
    # excluding equality b/c we already dropped identity
    assert df_obs['correlation_distance'].min() > 0

    # TODO check whether order in plots is same w/ and w/o passing order explicitly to
    # sns calls below (now that we are sorting df_obs to put pairs in same order).
    # (unclear from docs how categorical order is inferred...)

    # TODO want to subset before returning? any actual need to?
    # affect plots (no, right?)?
    #
    # RY: "reorder columns"
    df_obs = df_obs.loc[:, [
        # not sure any of these 3 needed for (/affect) plots, but could be useful at
        # output for comparing to other correlations i load / compute from remy's data.
        'datefly',
        # TODO refactor to share def of these 2 cols?
        'abbrev_row',
        'abbrev_col',

        'odor_pair_str',

        # TODO delete
        #'correlation',

        'correlation_distance',
        # TODO how does this differ from odor_pair_str? del?
        # not referenced anywhere else in this file...
        #'odor_pair',
    ]]

    # only want to make this plot (to show we can recreate preprint figure), when data
    # we are loading is same as in preprint. currently i'm only ever using that data to
    # show we can recreate this plot.
    plot = use_preprint_data

    if plot:
        # TODO fix so i can pass new errorbar into plotting fns, so that i can force
        # that seed_errorbar value for reproducing this plot?
        if seed_errorbar != ('ci', 95):
            warn("set seed_errorbar=('ci', 95) if you want to reproduce preprint 2E. "
                "returning!"
            )
            return

        g = _create_2e_plot_with_obs_kc_corrs(df_obs, pair_order)

        # seems to already have abbrev_[row|col]
        df_mdl = pd.read_csv(preprint_data_folder.joinpath('df_mdl_plot_trialavg.csv'))

        # df_mdl also contains uniform_4 and hemidraw_4
        model_types_to_plot = ['uniform_7', 'hemidraw_7', 'hemimatrix']

        pal = sns.color_palette()
        palette = {
            'hemidraw_7': pal[0],
            'uniform_7': pal[1],
            'hemimatrix': pal[2],
        }

        # TODO refactor? (to also check observed KC corrs in _create_..., and to move
        # this into _2e_plot...?)
        identity = df_mdl.abbrev_col == df_mdl.abbrev_row
        assert (df_mdl[identity].correlation == 1).all()

        df_mdl = df_mdl[~identity].copy()
        assert not (df_mdl.correlation == 1).any()

        df_mdl['correlation_distance'] = 1 - df_mdl.correlation
        assert df_mdl['correlation_distance'].max() <= 2.0
        assert df_mdl['correlation_distance'].min() > 0
        #

        _2e_plot_model_corrs(g, df_mdl.query('model in @model_types_to_plot'),
            pair_order, hue='model', palette=palette
        )

        _finish_remy_2e_plot(g)

        # NOTE: no seed_errorbar part in filename here, as only saving this if it's same
        # as preprints ('ci', 95)
        savefig(g, output_root, '2e_preprint-repro_old_data')


    checks = True
    if checks and not use_preprint_data:
        # TODO refactor w/ place copied from in model_mb...?
        remy_pairs = set(list(zip(df_obs.abbrev_row, df_obs.abbrev_col)))

        # TODO does it actually matter? does df_obs have all the corrs i would compute
        # for old flies anyway? maybe just expand checks below to also check those
        # flies?
        #
        # TODO TODO can i switch things to using corrs from
        # _load_remy_megamat_kc_responses? cause otherwise would prob need to have Remy
        # regen this file, including older megamat data betty now wants us to include...
        #
        # TODO TODO use -c check to verify i 2e outputs not changed by switching this
        # fn? add option to -c to pass substrs of outputs to check (ignoring rest)?
        #
        # TODO update comment. no longer just final 4.
        # data from best 4 "final" flies, which are the only megamat odor correlations
        # used anywhere in the paper except for figure 2E.
        #
        # TODO delete
        #mean_responses = _load_remy_megamat_kc_responses(drop_nonmegamat=False)
        #
        flymean_corrs = _remy_megamat_flymean_kc_corrs(ordered_pairs=remy_pairs,
            drop_nonmegamat=False
        )

        final_megamat_datefly = set(flymean_corrs.index.get_level_values('datefly'))
        # TODO delete (or update to include final 4 + however many old megamat flies i'm
        # now supposed to include)
        assert n_final_megamat_kc_flies <= len(final_megamat_datefly)

        flymean_corrs.columns = pd.MultiIndex.from_frame(
            flymean_corrs.columns.to_frame(index=False).applymap(olf.parse_odor_name)
        )
        assert not flymean_corrs.columns.duplicated().any()
        # TODO delete
        #mean_responses.columns = mean_responses.columns.map(olf.parse_odor_name)
        #assert not mean_responses.columns.duplicated().any()

        # TODO relax to include other pairs? or just drop? i assume we still won't have
        # all the data in df_obs if we just don't drop from latest set of (the old)
        # flies i'm loading?
        #assert set(mean_responses.columns) == megamat_odor_names

        # TODO delete? (replace w/ flymean_corrs)
        #corrs = mean_responses.groupby(level='datefly').apply(
        #    lambda x: corr_triangular(x.corr(), ordered_pairs=remy_pairs)
        #)
        #assert not corrs.isna().any().any()
        #

        # TODO move this dropna into above fn? this even doing anything? why would a
        # column be all NaN (and is that the right interpretation of axis='columns'?)?
        flymean_corrs = flymean_corrs.dropna(how='all', axis='columns')
        corrs = flymean_corrs

        n_megamat_only_pairs = n_choose_2(n_megamat_odors)
        # TODO delete? already relaxed from == to >=
        assert len(corrs.columns) >= n_megamat_only_pairs

        for datefly in corrs.index:
            fly_df = df_obs[df_obs.datefly == datefly]

            remy_2e_csv_ser = fly_df[['abbrev_row', 'abbrev_col',
                'correlation_distance']].set_index(['abbrev_row', 'abbrev_col'])

            # just to convert from shape (n, 1) to (n,)
            remy_2e_csv_ser = remy_2e_csv_ser.iloc[:, 0]

            remy_2e_csv_ser.index.names = ['odor1', 'odor2']

            # convert from correlation distance to correlation (to match what we have in
            # corrs)
            remy_2e_csv_ser = 1 - remy_2e_csv_ser
            remy_2e_csv_ser.name = 'correlation'

            recalced_ser = corrs.loc[datefly]

            # since corrs is of shape (<n_flies>, <n_total_odor_pairs>), this will drop
            # the pairs down to those actually measured in this fly
            recalced_ser = recalced_ser.dropna()
            assert not remy_2e_csv_ser.isna().any()

            recalced_pair_set = set(recalced_ser.index)
            # neither index should have any duplicate pairs
            assert len(recalced_pair_set) == len(recalced_ser)
            assert len(recalced_pair_set) == len(remy_2e_csv_ser)

            assert recalced_pair_set == set(remy_2e_csv_ser.index)

            # above assertion justifies indexing one by the other, as it's just the
            # order that is different, not that either series has any different pairs
            assert pd_allclose(recalced_ser, remy_2e_csv_ser.loc[recalced_ser.index])

        df_megamat = df_obs[
            df_obs.abbrev_row.isin(megamat_odor_names) &
            df_obs.abbrev_col.isin(megamat_odor_names)
        ]

        # TODO (delete? satisfied?) are all of the old megamat flies that i'm now
        # supposed to use a subset of these? do the correlations match what i would
        # compute?
        #
        # ipdb> len(set(df_megamat.datefly) - final_megamat_datefly)
        # 18
        # ipdb> pp (set(df_megamat.datefly) - final_megamat_datefly)
        # {'2018-10-21/1',
        #  '2019-03-06/3',
        #  '2019-03-06/4',
        #  '2019-03-07/2',
        #  '2019-04-26/4',
        #  '2019-05-09/4',
        #  '2019-05-09/5',
        #  '2019-05-23/2',
        #  '2019-05-24/1',
        #  '2019-05-24/3',
        #  '2019-05-24/4',
        #  '2019-07-19/2',
        #  '2019-09-12/1',
        #  '2019-09-12/2',
        #  '2022-09-21/1',
        #  '2022-09-22/2',o
        #  '2022-09-26/1',
        #  '2022-09-26/3'}
        assert final_megamat_datefly - set(df_megamat.datefly) == set()
        df_megamat_nonfinal = df_megamat[
            ~df_megamat.datefly.isin(final_megamat_datefly)
        ]

        # TODO delete (/update) (no longer just using final 4 flies)
        #
        # only the 4 "final" flies have all 17 odors measured (-> all 136 non-identity
        # pairs)
        #
        # ipdb> [len(x) for _, x in df_megamat_nonfinal.groupby('datefly')]
        # [47, 10, 28, 30, 21, 38, 38, 36, 36, 36, 57, 79, 71, 71, 3, 3, 3, 3]
        #assert all(len(x) < n_megamat_only_pairs
        #    for _, x in df_megamat_nonfinal.groupby('datefly')
        #)

        assert remy_2e_metric == 'correlation_distance'
        mean_nonfinal_corrdist = df_megamat_nonfinal.groupby(['abbrev_row','abbrev_col']
            )[remy_2e_metric].mean()

        mean_nonfinal_corrdist.index.names = ['odor1', 'odor2']

        # TODO better check than this try/except
        try:
            square_nonfinal_corrdist = invert_corr_triangular(mean_nonfinal_corrdist,
                diag_value=0, _index=corrs.columns
            )

            square_nonfinal_corrs = 1 - square_nonfinal_corrdist

            # since sorting expects concentrations apparently...
            square_nonfinal_corrs.columns = square_nonfinal_corrs.columns + ' @ -3'
            square_nonfinal_corrs.index = square_nonfinal_corrs.index + ' @ -3'

            square_nonfinal_corrs = sort_odors(util.addlevel(
                    util.addlevel(square_nonfinal_corrs, 'panel', 'megamat').T,
                'panel', 'megamat'
                ), warn=False
            )

            square_nonfinal_corrs = square_nonfinal_corrs.droplevel('panel',
                axis='columns'
            ).droplevel('panel', axis='index')

            plot_corr(square_nonfinal_corrs, output_root,
                '2e_remy_nonfinal-flies-only_corr', xlabel='non-final flies only'
            )

            # TODO actually plot this / delete
            '''
            nonfinal_pair_n = df_megamat_nonfinal.groupby(['abbrev_row','abbrev_col']
                ).size()
            # TODO just rename these cols in dataframe before (so we don't have to do
            # this here and for mean)
            nonfinal_pair_n.index.names = ['odor1', 'odor2']
            nonfinal_pair_n = invert_corr_triangular(nonfinal_pair_n, diag_value=np.nan,
                _index=corrs.columns
            )
            '''
        # ...
        #   File "./al_analysis.py", line 1208, in invert_corr_triangular
        #     assert all(odor2[:-1] == odor1[1:])
        except AssertionError:
            # TODO elaborate on why?
            warn('could not plot 2e square matrix corr plots')
    #

    return df_obs


def main():
    # TODO print names of plots we are saving (by default, and prob unconditionally),
    # as if -v/--verbose were passed to al_analysis.py

    model_output_dir1 = Path('data/sent_to_remy/2025-03-18/'
        'dff_scale-to-avg-max__data_pebbled__hallem-tune_False__pn2kc_hemibrain__'
        'weight-divisor_20__drop-plusgloms_False__target-sp_0.0915'
    ).resolve()

    # TODO TODO commit + use kiwi/control data for one? (could just temporarily change
    # this path to one for kiwi/control data) (might be more complicated, since i
    # typically tune on both panels there, but i could skip that?)
    #
    # panel          megamat   ...
    # odor           2h @ -3   ...   benz @ -3    ms @ -3
    # glomerulus               ...
    # D            40.363954   ...   42.445274  41.550370
    # DA2          15.144943   ...   12.363544   3.856004
    # ...
    # VM7d        108.535394   ...   58.686294  20.230297
    # VM7v         59.896953   ...   13.250292   8.446418
    # orn_deltas = pd.read_csv(model_output_dir1 / 'orn_deltas.csv', header=[0,1],
    #     index_col=0
    # )

    # df = pd.read_csv('mean_est_spike_deltas.csv', header=[0, 1], index_col=0)
    # orn_deltas = df.loc[:, df.columns.get_level_values('panel') == 'control']
    orn_deltas = pd.read_csv(model_output_dir1 / 'orn_deltas.csv', header=[0,1],
        index_col=0
    )

    assert orn_deltas.columns.names == ['panel', 'odor']
    assert orn_deltas.index.names == ['glomerulus']

    # currently only way to enable olfsysm log prints
    al_util.verbose = True

    # TODO also include equalize_kc_type_sparsity=False for all below
    # TODO TODO pick from kwargs described in comments below
    #
    # TODO why do gamma KCs have a LOWER than average response rate after this?
    #
    # use_connectome_APL_weights=True
    # equalize_kc_type_sparsity=True
    # ab_prime_response_rate_target=None
    # retune_apl_post_equalized_thrs=False
    # mean response rate: 0.1158. by KC type:
    #          avg_response_rate  n_kcs_of_type
    # a'b'              0.124475            336
    # ab                0.121534            802
    # g                 0.092561            612
    # unknown           0.200000             80
    #
    # use_connectome_APL_weights=True
    # equalize_kc_type_sparsity=True
    # ab_prime_response_rate_target=0.2
    # retune_apl_post_equalized_thrs=False
    # mean response rate: 0.1377. by KC type:
    #          avg_response_rate  n_kcs_of_type
    # a'b'              0.294293            336
    # ab                0.111706            802
    # g                 0.077566            612
    # unknown           0.200000             80
    #
    # use_connectome_APL_weights=True
    # equalize_kc_type_sparsity=True
    # ab_prime_response_rate_target=0.15
    # retune_apl_post_equalized_thrs=False
    # mean response rate: 0.1279. by KC type:
    #          avg_response_rate  n_kcs_of_type
    # a'b'              0.212885            336
    # ab                0.117207            802
    # g                 0.085736            612
    # unknown           0.200000             80
    #
    #
    # use_connectome_APL_weights=False
    # equalize_kc_type_sparsity=True
    # ab_prime_response_rate_target=None
    # retune_apl_post_equalized_thrs=False
    # mean response rate: 0.0951. by KC type:
    #          avg_response_rate  n_kcs_of_type
    # a'b'              0.101716            336
    # ab                0.087355            802
    # g                 0.099097            612
    # unknown           0.114706             80
    #
    # use_connectome_APL_weights=False
    # equalize_kc_type_sparsity=True
    # ab_prime_response_rate_target=0.2
    # retune_apl_post_equalized_thrs=False
    # mean response rate: 0.1024. by KC type:
    #          avg_response_rate  n_kcs_of_type
    # a'b'              0.239146            336
    # ab                0.065645            802
    # g                 0.077278            612
    # unknown           0.089706             80
    #
    # use_connectome_APL_weights=False
    # equalize_kc_type_sparsity=True
    # ab_prime_response_rate_target=0.15
    # retune_apl_post_equalized_thrs=False
    # mean response rate: 0.1004. by KC type:
    #          avg_response_rate  n_kcs_of_type
    # a'b'              0.174020            336
    # ab                0.077527            802
    # g                 0.089869            612
    # unknown           0.101471             80
    #
    #
    # use_connectome_APL_weights=False
    # equalize_kc_type_sparsity=True
    # ab_prime_response_rate_target=None
    # retune_apl_post_equalized_thrs=True
    # mean response rate: 0.1096. by KC type:
    #          avg_response_rate  n_kcs_of_type
    # a'b'              0.113270            336
    # ab                0.103125            802
    # g                 0.114379            612
    # unknown           0.123529             80
    #
    # use_connectome_APL_weights=False
    # equalize_kc_type_sparsity=True
    # ab_prime_response_rate_target=0.2
    # retune_apl_post_equalized_thrs=True
    # mean response rate: 0.0930. by KC type:
    #          avg_response_rate  n_kcs_of_type
    # a'b'              0.223389            336
    # ab                0.058163            802
    # g                 0.068627            612
    # unknown           0.080147             80
    #
    # use_connectome_APL_weights=False
    # equalize_kc_type_sparsity=True
    # ab_prime_response_rate_target=0.15
    # retune_apl_post_equalized_thrs=True
    # mean response rate: 0.0961. by KC type:
    #          avg_response_rate  n_kcs_of_type
    # a'b'              0.168242            336
    # ab                0.074153            802
    # g                 0.085160            612
    # unknown           0.097794             80
    #
    #
    # use_connectome_APL_weights=True
    # equalize_kc_type_sparsity=True
    # ab_prime_response_rate_target=None
    # retune_apl_post_equalized_thrs=True
    # mean response rate: 0.0996. by KC type:
    #          avg_response_rate  n_kcs_of_type
    # a'b'              0.109769            336
    # ab                0.105252            802
    # g                 0.073626            612
    # unknown           0.200000             80
    #
    # use_connectome_APL_weights=True
    # equalize_kc_type_sparsity=True
    # ab_prime_response_rate_target=0.2
    # retune_apl_post_equalized_thrs=True
    # mean response rate: 0.0984. by KC type:
    #          avg_response_rate  n_kcs_of_type
    # a'b'              0.241772            336
    # ab                0.071586            802
    # g                 0.041619            612
    # unknown           0.200000             80
    #
    # use_connectome_APL_weights=True
    # equalize_kc_type_sparsity=True
    # ab_prime_response_rate_target=0.15
    # retune_apl_post_equalized_thrs=True
    # mean response rate: 0.0996. by KC type:
    #          avg_response_rate  n_kcs_of_type
    # a'b'              0.178046            336
    # ab                0.087575            802
    # g                 0.059208            612
    # unknown           0.200000             80

    kws = dict(
        weight_divisor=20,
        # TODO just make this default?
        use_connectome_APL_weights=True,
    )

    # TODO TODO try dropping all kc_type == 'unknown' cells before running
    # (in fit_mb_model)?

    plot_root = Path('model_mb_example').resolve()
    # updated to keep things clean;
    #plot_root = Path("model_mb_example") / f"data_pebbled_target-sp_{target_sparsity:.4f}"

    # TODO modify this fn so dirname includes all same params by default (rather than
    # just e.g. param_dir='data_pebbled'), as the ones i'm currently manually creating
    # by calls in model_mb_... (prob behaving diff b/c e.g.
    # pn2kc_connections='hemibrain' is explicitly passed there)
    # param_dict = fit_and_plot_mb_model(plot_root, orn_deltas=orn_deltas,
    #    try_cache=False, print_olfsysm_log = True, **kws
    # )

    # TODO delete this product thing, and just switch to a kws_list?
    '''
    try_each_with_kws = [
        # TODO TODO (still relevant?) make sure output dirs have something in name
        # for use_vector_thr=True case (i.e. case where fixed_thr vector here)
        # (just pass via suffix? or extra params? might need to restore the code for
        # that...) (param_dir_prefix? still also add something to extra params to
        # include in plot titles hopefully (or those not used that way?)?)
        # TODO maybe mean response rate per subtype? or thr for each?
        # TODO TODO at least include thr multiplier for each as a parameter?
        # (and maybe include in titles?)
        #
        # probably always want `kws` unmodified too. that's what this empty dict is for.
        dict(),

        dict(use_connectome_APL_weights=True),
    ]
    '''
    try_each_with_kws = [
        dict(_wPNKC_one_row_per_claw=False, claw_sparsity=False)
    ]

    for extra_kws in try_each_with_kws:
        # extra_kws will override kws without warning, if they have common keys
        param_dict = fit_and_plot_mb_model(plot_root, orn_deltas=orn_deltas,
            # TODO disable _plot_example_dynamics (resource intensive)?
            try_cache=False, _plot_example_dynamics=True, **{**kws, **extra_kws}
        )
        output_dir = (plot_root / param_dict['output_dir']).resolve()
        assert output_dir.is_dir()
        assert output_dir.parent == plot_root

        #           2h @ -3  IaA @ -3  pa @ -3  ...  1-6ol @ -3  benz @ -3  ms @ -3
        # kc_id         ...
        # 0             0.0       0.0      0.0  ...         0.0        0.0      0.0
        # 1             0.0       0.0      0.0  ...             0.0        0.0      0.0
        # ...           ...       ...      ...  ...         ...        ...      ...
        # 1835          1.0       1.0      2.0  ...         1.0        0.0      0.0
        # 1836          0.0       0.0      0.0  ...         0.0        0.0      0.0
        df = pd.read_csv(output_dir / 'spike_counts.csv', index_col=KC_ID)

    # TODO TODO also include an example w/ kiwi/control data (as used by natmix_data)
    # (either committing data in al_analysis too, or moving this whole example to
    # another repo)
    # TODO + add test i can reproduce those outputs (use outputs i already sent someone
    # from my kiwi/control data? sent to ruoyi? or someone else?)
    import ipdb; ipdb.set_trace()


if __name__ == '__main__':
    main()

